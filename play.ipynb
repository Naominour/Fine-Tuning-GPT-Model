{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17828,
     "status": "ok",
     "timestamp": 1731490649235,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "lg-UnAkPz2hL",
    "outputId": "13d8bd00-db34-4542-8dda-ebdb9f3696ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slUCyZAYyK4v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tn1tUBD2yK1_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EK1L4GIVyKzH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F62RFWhsyKv_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yezAKYHZyKq_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1E1QmwdYyKj_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 567,
     "status": "ok",
     "timestamp": 1728397801876,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": -60
    },
    "id": "hDsl5OMuUFMX",
    "outputId": "3e83a6ea-faab-4b42-ae64-3d65d15df822"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight torch.Size([50257, 768])\n",
      "transformer.wpe.weight torch.Size([1024, 768])\n",
      "transformer.h.0.ln_1.weight torch.Size([768])\n",
      "transformer.h.0.ln_1.bias torch.Size([768])\n",
      "transformer.h.0.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.0.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.0.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.0.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.0.ln_2.weight torch.Size([768])\n",
      "transformer.h.0.ln_2.bias torch.Size([768])\n",
      "transformer.h.0.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.0.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.0.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.0.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.1.ln_1.weight torch.Size([768])\n",
      "transformer.h.1.ln_1.bias torch.Size([768])\n",
      "transformer.h.1.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.1.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.1.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.1.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.1.ln_2.weight torch.Size([768])\n",
      "transformer.h.1.ln_2.bias torch.Size([768])\n",
      "transformer.h.1.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.1.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.1.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.1.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.2.ln_1.weight torch.Size([768])\n",
      "transformer.h.2.ln_1.bias torch.Size([768])\n",
      "transformer.h.2.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.2.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.2.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.2.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.2.ln_2.weight torch.Size([768])\n",
      "transformer.h.2.ln_2.bias torch.Size([768])\n",
      "transformer.h.2.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.2.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.2.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.2.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.3.ln_1.weight torch.Size([768])\n",
      "transformer.h.3.ln_1.bias torch.Size([768])\n",
      "transformer.h.3.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.3.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.3.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.3.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.3.ln_2.weight torch.Size([768])\n",
      "transformer.h.3.ln_2.bias torch.Size([768])\n",
      "transformer.h.3.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.3.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.3.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.3.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.4.ln_1.weight torch.Size([768])\n",
      "transformer.h.4.ln_1.bias torch.Size([768])\n",
      "transformer.h.4.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.4.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.4.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.4.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.4.ln_2.weight torch.Size([768])\n",
      "transformer.h.4.ln_2.bias torch.Size([768])\n",
      "transformer.h.4.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.4.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.4.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.4.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.5.ln_1.weight torch.Size([768])\n",
      "transformer.h.5.ln_1.bias torch.Size([768])\n",
      "transformer.h.5.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.5.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.5.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.5.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.5.ln_2.weight torch.Size([768])\n",
      "transformer.h.5.ln_2.bias torch.Size([768])\n",
      "transformer.h.5.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.5.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.5.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.5.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.6.ln_1.weight torch.Size([768])\n",
      "transformer.h.6.ln_1.bias torch.Size([768])\n",
      "transformer.h.6.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.6.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.6.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.6.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.6.ln_2.weight torch.Size([768])\n",
      "transformer.h.6.ln_2.bias torch.Size([768])\n",
      "transformer.h.6.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.6.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.6.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.6.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.7.ln_1.weight torch.Size([768])\n",
      "transformer.h.7.ln_1.bias torch.Size([768])\n",
      "transformer.h.7.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.7.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.7.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.7.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.7.ln_2.weight torch.Size([768])\n",
      "transformer.h.7.ln_2.bias torch.Size([768])\n",
      "transformer.h.7.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.7.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.7.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.7.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.8.ln_1.weight torch.Size([768])\n",
      "transformer.h.8.ln_1.bias torch.Size([768])\n",
      "transformer.h.8.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.8.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.8.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.8.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.8.ln_2.weight torch.Size([768])\n",
      "transformer.h.8.ln_2.bias torch.Size([768])\n",
      "transformer.h.8.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.8.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.8.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.8.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.9.ln_1.weight torch.Size([768])\n",
      "transformer.h.9.ln_1.bias torch.Size([768])\n",
      "transformer.h.9.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.9.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.9.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.9.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.9.ln_2.weight torch.Size([768])\n",
      "transformer.h.9.ln_2.bias torch.Size([768])\n",
      "transformer.h.9.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.9.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.9.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.9.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.10.ln_1.weight torch.Size([768])\n",
      "transformer.h.10.ln_1.bias torch.Size([768])\n",
      "transformer.h.10.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.10.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.10.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.10.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.10.ln_2.weight torch.Size([768])\n",
      "transformer.h.10.ln_2.bias torch.Size([768])\n",
      "transformer.h.10.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.10.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.10.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.10.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.h.11.ln_1.weight torch.Size([768])\n",
      "transformer.h.11.ln_1.bias torch.Size([768])\n",
      "transformer.h.11.attn.c_attn.weight torch.Size([768, 2304])\n",
      "transformer.h.11.attn.c_attn.bias torch.Size([2304])\n",
      "transformer.h.11.attn.c_proj.weight torch.Size([768, 768])\n",
      "transformer.h.11.attn.c_proj.bias torch.Size([768])\n",
      "transformer.h.11.ln_2.weight torch.Size([768])\n",
      "transformer.h.11.ln_2.bias torch.Size([768])\n",
      "transformer.h.11.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "transformer.h.11.mlp.c_fc.bias torch.Size([3072])\n",
      "transformer.h.11.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "transformer.h.11.mlp.c_proj.bias torch.Size([768])\n",
      "transformer.ln_f.weight torch.Size([768])\n",
      "transformer.ln_f.bias torch.Size([768])\n",
      "lm_head.weight torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "model_hf = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "sd_hf = model_hf.state_dict()\n",
    "\n",
    "for k,v in sd_hf.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1728397276227,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": -60
    },
    "id": "IYX0nTLpedrB",
    "outputId": "f2180d81-a9ca-4a6f-a61d-1fe739b949ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1101, -0.0393,  0.0331,  0.1338, -0.0485, -0.0789, -0.2398, -0.0895,\n",
       "         0.0253, -0.1074, -0.1811, -0.0672,  0.0739, -0.0161,  0.0117,  0.1245,\n",
       "        -0.0020, -0.0815,  0.0338,  0.2365])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the entire embedding matrix to a flat vector and display the first 20 values\n",
    "sd_hf[\"transformer.wte.weight\"].view(-1)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1728397889064,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": -60
    },
    "id": "mceT8AAmisEe",
    "outputId": "94926862-0753-4fbb-8860-397f66245398"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(sd_hf[\"transformer.wte.weight\"].shape) #(Vocabulary size:unique tokens,  Embedding dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "executionInfo": {
     "elapsed": 1527,
     "status": "ok",
     "timestamp": 1728398218535,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": -60
    },
    "id": "CwnKyOJuenL0",
    "outputId": "bb13ef58-24e8-4351-b74f-6b1ed4888d6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x78f00c15b190>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFoAAAGiCAYAAABnHtHCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAVXUlEQVR4nO2de1BU5RvHv7ssuwspC95AFFBHxfGeEgyV3WQkhxrNZmIcUjKVQJzxNpb+keg/4WjTlA6ZmkXTNJE2Y02lFHnB8YaKkHfGCykViKgsYHJx9/n9IedwDhd/LPK+7G7PZ2Zn2D2ve85+e3ve571+DUREYIRj7OkH+K/AQkuChZYECy0JFloSLLQkWGhJsNCSYKElwUJLwuOFzsrKwpAhQ2C1WhETE4MTJ0709CO1D3kwOTk5ZDab6YsvvqDz58/TwoULKTAwkG7evNnTj9YGjxY6Ojqa0tPT1fcOh4NCQ0MpMzOzB5+qfUw9/X9UV2lsbERhYSFWr16tfmY0GhEXF4djx461+28aGhrQ0NCgvnc6nbhz5w769u0Lg8EAACAi1NbWIjQ0FEZj90VWjxW6qqoKDocDwcHBus+Dg4Nx6dKldv9NZmYm1q1b16nvLysrw+DBgx/7ORU8VuiusHr1aixfvlx9b7fbER4ejrfeegtWqxUGgwF1dXX4+uuv0bt37269t8cK3a9fP/j4+ODmzZu6z2/evImQkJB2/43FYoHFYmn3c6vVigcPHsBsNgOAGkq6C49N78xmMyZPnox9+/apnzmdTuzbtw+xsbEuf5/BYAAJnGzy2BoNAMuXL0dycjKioqIQHR2Njz/+GPfu3cO8efO69H1Op1OY2B4tdGJiIm7duoU1a9agoqICEydORG5ubpsGsjOIrM2AhwsNAIsXL8bixYu75buIqNtjs4LHxujuRptHi4CFbsbpdALo/mxDgYVuRpTACiw0xIcNgIWWBgvdDIcOSSiNoShYaHCMlobT6eTQIQODwcBCy0L0WAcL3QzXaAnQw0lqbgy9ARZaEiw0Hi5T4MZQAiIH/BVYaLSkdtwYCkbpsIis1Sx0MxyjvQQWGuJ7hQALDaBl9I4bQ8FwjZYIN4aS4A6LBLgLLgllYpaX7UpAdO+Qa7QkWOhmOEZLQBsuRC2kYaGb4Z6hBESHDYCFBtASOkSuv2Oh0SKw0Wjs1m3JWlhocGMoHZ7KkgCvVPISWGhweicNZTCJ0zvBaHuFnN4JRFkSZjQaOb0TDRFx6JABzxl6CSw0eF2HNERnHAALrYMbQ8GIrMnqPYTfwQPg0CEZDh2C4UElL4KFBtdoaWg7LDx6JwkevROIthZzjRaINkZzjRYMryaVAG+67wHcJkYfOnQIr776KkJDQ2EwGPDDDz/orhMR1qxZg4EDB8LPzw9xcXG4fPmyrsydO3eQlJSEgIAABAYGYv78+airq9OVOXPmDKZMmQKr1YqwsDBs2LChzbPs2rULo0aNgtVqxbhx47Bnzx5Xf47uuQE3itH37t3DhAkTkJWV1e71DRs2YNOmTfjss89QUFCAJ554AvHx8aivr1fLJCUl4fz588jLy8PPP/+MQ4cOISUlRb1eU1ODadOmISIiAoWFhdi4cSPWrl2Lbdu2qWWOHj2K2bNnY/78+SgqKsLMmTMxc+ZMnDt3ztWfpNu7Imxg6XHccgDQ7t271fdOp5NCQkJo48aN6mfV1dVksVjo22+/JSKiCxcuEAA6efKkWmbv3r1kMBjo77//JiKiTz/9lIKCgqihoUEt895771FkZKT6/o033qCEhATd88TExNA777zT4fPW19eT3W5XX2VlZQSA0tLSaNmyZTRv3jyaP38+ASC73d41UTqgW//zlZaWoqKiAnFxcepnNpsNMTExqtvPsWPHEBgYiKioKLVMXFwcjEYjCgoK1DLPPfecatUBAPHx8SgpKcHdu3fVMtr7KGU6chUCHhre2Gw29RUWFtamjNvE6EdRUVEBAO26/SjXKioqMGDAAN11k8mEPn366Mq09x3ae3RURrneHqtXr4bdbldfZWVlbcqIitH/qX2GHRneyKBba7Ti6PMot5+QkBBUVlbqrj948AB37tzRlWnvO7T36KhMR65CPU23Cj106FCEhITo3H5qampQUFCguv3ExsaiuroahYWFapn9+/fD6XQiJiZGLXPo0CE0NTWpZfLy8hAZGYmgoCC1jPY+SpmuuApJwdXWs7a2loqKiqioqIgA0EcffURFRUV0/fp1IiJav349BQYG0o8//khnzpyhGTNm0NChQ+n+/fvqd7z88sv05JNPUkFBAR0+fJhGjBhBs2fPVq9XV1dTcHAwzZkzh86dO0c5OTnk7+9PW7duVcscOXKETCYTffjhh3Tx4kXKyMggX19fOnv2bKd/i91ul5Z1uCz0gQMHCECbV3JyMhE9TPHef/99Cg4OJovFQlOnTqWSkhLdd9y+fZtmz55NvXr1ooCAAJo3bx7V1tbqyvzxxx/07LPPksVioUGDBtH69evbPMvOnTtp5MiRZDabacyYMfTLL7+49FsUoVNTU4ULbSCSML3gptTU1MBmsyEtLQ1WqxXV1dUwmUzYvn077HY7AgICuu1ePNYBnsqShvaMf7cZ6/BGlBrN298Ew6tJJaGN0R4x1uGpcIyWBGcdkuHG0AtgoTWIDCEstAYOHZIgIvj4+Aj5bhYa+prscDiE3IOFlgQL3QruGUqAe4aS4KxDMNwFlwQPk3oRLHQrOOuQAGcdklAOsBIBC61B5Nl3LDTYOFIa2jlDUbDQaBGae4YS4cZQINwF9yJYaOizDk7vBMKDSpLhrEMw3GGRhJLScY0WDNfoHoA7LB4OCw0+vKpH4NDh4bDQ4J5hj8AxWhIcoyXBNVoCvNxAAkajkcejvQEWuhmtZbUIWGjw6J00eF2HZLhGC4bXdUhCGzI4vRMIn6kkCTa86QE4dAhEuz6aa7RAeM5QMtwYCobzaEm4XdaRmZmJp556Cr1798aAAQMwc+ZMlJSU6MrU19cjPT0dffv2Ra9evfD666+3OSL+xo0bSEhIgL+/PwYMGICVK1fiwYMHujIHDx7EpEmTYLFYMHz4cGRnZ7d5nqysLAwZMgRWqxUxMTE4ceKEKz9Hxe06LPn5+UhPT8fx48eRl5eHpqYmTJs2Dffu3VPLLFu2DD/99BN27dqF/Px8/PPPP5g1a5Z63eFwICEhAY2NjTh69Ci++uorZGdnY82aNWqZ0tJSJCQk4MUXX0RxcTGWLl2KBQsW4Ndff1XLfPfdd1i+fDkyMjJw+vRpTJgwAfHx8W38AzqDkm0IDSGPc8p3ZWUlAaD8/HwienhkvK+vL+3atUstc/HiRQJAx44dIyKiPXv2kNFopIqKCrXMli1bKCAgQDW4effdd2nMmDG6eyUmJlJ8fLz6Pjo6mtLT09X3DoeDQkNDKTMzs9PP3/ro+eTkZFq4cKH7Gd7Y7XYAQJ8+fQAAhYWFaGpq0hnRjBo1CuHh4TrDm3Hjxuk8VOLj41FTU4Pz58+rZR5lZtPY2IjCwkJdGaPRiLi4uEca3jQ0NKCmpkb3ao1bhA4tTqcTS5cuxTPPPIOxY8cCeGhCYzabERgYqCvb2vCmq2Y2NTU1uH//PqqqquBwOFw2vOnIWcitN3Smp6fj3LlzyMnJ6c7nEUpHzkIk4VjjLjkLLV68WHVtGzx4sPp5SEgIGhsbUV1dravVrQ1vWmcHnTWzCQgIgJ+fH3x8fODj4+Oy4U1HzkKkGb1zi9BBRFi8eDF2796N/fv3Y+jQobrrkydPhq+vr86IpqSkBDdu3NAZ3pw9e1aXHeTl5SEgIACjR49WyzzKzMZsNmPy5Mm6Mk6nE/v27euS4Y2MsQ6Xso60tDSy2Wx08OBBKi8vV1///vuvWiY1NZXCw8Np//79dOrUKYqNjaXY2Fj1+oMHD2js2LE0bdo0Ki4uptzcXOrfvz+tXr1aLXPt2jXy9/enlStX0sWLFykrK4t8fHwoNzdXLZOTk0MWi4Wys7PpwoULlJKSQoGBgbps5v/ROuuYO3cupaSk9LzhDdoxugFAX375pVrm/v37tGjRIgoKCiJ/f3967bXXqLy8XPc9f/75J02fPp38/PyoX79+tGLFCmpqatKVOXDgAE2cOJHMZjMNGzZMdw+FzZs3U3h4OJnNZoqOjqbjx4+78nPaFVpUeseGNzYbUlNT4efnh9u3b8NisbDhjUiMRqP7NIbejCiBFVhotOTOIqMoCw0ej/YqWGjwZiHp8JyhYJSMgxtDwfCy3R7ALSZnvR3izULiETY8qny/0G/3ELRjHBw6BEK89k4OJHJmpRkWWgPn0RLgYVKJ8KZ7wbjdIkdvhhtDSXAeLQEej5YEd1gkwXOGkhCZ1imw0K3gxlAw3DOUCE9lSYJnWLwAFhpy9rCw0OBBJWlwF1wS3DOUDKd3EhC96Z6FbobHoyXBNVoCykol3pUlGM46JMF5tCS4C94DcIyWgMjFjiw0eM5QGiIH/BVYaEmw0JJgoVvBWYcEeJhUEk6nk9M7GfCgkkS4RguEB5Ukw6FDMDweLRkeVBIMx2hJcOjwIlhotIxHcxdcMEro4IXoghGZPyu4JPSWLVswfvx4BAQEICAgALGxsdi7d6963RNdhQB9WucW6d3gwYOxfv16FBYW4tSpU3jppZcwY8YM1T/FE12FFETX6MdyFiIiCgoKos8//9wjXIXq6+vJbrerr7KyMt3R83PmzHE/ZyGHw4GcnBzcu3cPsbGxbu8qBHRseCMDl4U+e/YsevXqBYvFgtTUVOzevRujR492e1choGPDG0D8eR0uG95ERkaiuLgYdrsd33//PZKTk5Gfny/i2bqdjgxvAPEx2mWhzWYzhg8fDuChwc3JkyfxySefIDEx0a1dhR6F8IYQ3ZBHO51ONDQ0eKyrECA+bABwLetYtWoV5efnU2lpKZ05c4ZWrVpFBoOBfvvtNyLyLFchohbDm0WLFgnPOlwS+u2336aIiAgym83Uv39/mjp1qioykWe5ChG1dRYSKTQ7C9lsSEtLg9VqRVVVFcxmM3bs2MHOQiLhAwYlwLuyJKCM3hEPk4qHB/4lQjwLLhYlXPACGsEYjUbeCy4bUXGahUZLbKaHPWUh92ChJcFCQ3+6AYcOgShbKgwGAxwOh5B7sNDQO937+PgIuQcL3YxoT0MWGvoeIXdYBKK1q+YOi4fDQjfjVoscvRUlZPCgkiQ4RkuAQ4cE2K5aEsTOQnLhWXAJKFkHN4YS4BotCc6jJcKhQyDa8Wiu0QJRBObGUALKLDjPGQpEyTYMBgPPsIhEGy44RgtE2whyjBaMIjDHaMEoNZrXdQhEm0eLgoVuhgeVJEB81I8ctINJXKM9HBYa+p6hKFjoZnjtnQS0NZljtAQ46xAMj3VIgs8mlYS2wyIKFroZZSpLFCy0Bq7REuAYLQntCQciYKGbYYdOifCme8G43Yno3gpvFpIEDypJQtsz5KxDAnyMhCR4n6FEuDEUiNs3huvXr4fBYMDSpUvVzzzR9Mat9xmePHkSW7duxfjx43Wfe6LpjYyjfrpkeFNbW0sjRoygvLw8ev7552nJkiVERB5heqOl9dHzSUlJ7mV4k56ejoSEhDbGNO5uetPQ0ICamhrdS4vIYVKX7UFycnJw+vRpnDx5ss01WaY3d+/e7dD05tKlSx0+e2ZmJtatW9fuNbcajy4rK8OSJUvwzTffwGq1inomYTzKWQgQe5SES0IXFhaisrISkyZNgslkgslkQn5+PjZt2gSTyYTg4GDV9EZLa9Ob9sxqlGuPKqOY3vTr169LpjcWi0W1CFRegL7r7RZd8KlTp+Ls2bMoLi5WX1FRUUhKSlL/9kTTG2U3lshdWY9ts6fNOog8y/RGm3WsWLGC3nzzTfcwvGmP1kJ7kulNe0KnpKSw4U13oxjeLFq0CBaLBbdu3YKfnx+2b9/OhjciID4yUx48ZygB7W4stxy98yaUtXccOgSixGjiGRaxaGuyW/QMvRVtTRaV7bLQreAY7eGw0Bp4070kRI5GsNDQZx0cowWizTo4dAhE5FyhAgvdDIcOyXDoEIjIMQ4FFroZ3jkrAaWjwnm0F8BCS4KFbobTOwlosw62QpUE78oSiHbFP3dYJMC+4ILRNoAcOgTi9tvfvAWt0JzeCYQEnuCowEI3wzMskuAaLQHtMgNO7yTBS8IEojSGvGxXAtwYSkA71sExWhIcowVC7nwwirfCMVogvCRMEjI2D7PQYLtq6YhcFsZCQ382KTeGguHROwlwYygRHiaVAOfRktAKzWMdghFdq1noZhwOB3dYZMFblCWgbK3gGi0Q7ZyhKFjoZnghukSIvbLEw2MdknCrg7q9Hd7QKRiRWyoUWGi0NIK8JEwwbrcra+3ater/Zspr1KhR6nVPdBUC3HTF/5gxY1BeXq6+Dh8+rF7zRFchQOwYh4orx6dnZGTQhAkT2r3mCa5C9fX1ZLfb1VdZWZnu6PmkpCSaP3++ezgLXb58GaGhoRg2bBiSkpJw48YNAO7vKgQ8NLyx2WzqKywszNWf32VcEjomJgbZ2dnIzc3Fli1bUFpaiilTpqC2tlaaq1BVVVWHrkLKd3REa8MbpZI0NDSgoaEBTU1NantB3ZxTu2ThNH36dPXv8ePHIyYmBhEREdi5cyf8/Py69cFEYLFYYLFY1PdVVVUAgB07drQpW1tbC5vN1m33fqwWIDAwECNHjsSVK1cQEhLi1q5C7dGnTx8ADzMhxc5J+Ts0NNSl7/p/PJbQdXV1uHr1KgYOHIjJkyd7nKuQkmnYbDbVCsRms2Hw4MHdn4W40nKuWLGCDh48SKWlpXTkyBGKi4ujfv36UWVlJRF5lqsQUYvhjZKFQEC2oeCS0ImJiTRw4EAym800aNAgSkxMpCtXrqjXPclViMiNhfY26uvrKSMjg+rr63V/i+A/beEkEx5UkgQLLQkWWhIstCRYaEl4tdCPmqjIyspCREQEfHx8YDKZ4O/v3+WJis7gsi+4pzFmzBj8/vvv6nuTyaROHDz99NNobGzEpEmTcOjQIVy/fh2zZs3CkSNHALRMVISEhODo0aMoLy/H3Llz4evriw8++MC1BxGSnbsJHU1UREdH04IFC9SJCmXiYNmyZS5PVHQWrw4dQNuJiitXrqCwsBBhYWHqRIUycXD16lWXJyo6i1eHDmWiIjIyEuXl5Vi3bh1eeOEFddG5dqIiODgYly5dcnmiorN4tdDtTVSEh4f3yLN4fejQokxUKBmIdqJCmThwdaKis/ynhK6rq8O1a9cQFhaGv/76S52oUCYOhg8f7vJERad5nFbd3eloomLbtm1ksVjoxRdfpIEDB9Irr7xCvXr1oqioKJcnKjqLVwv9qImKzZs3U1hYGBmNRvLx8SGr1drliYrOwOPRkvhPxeiehIWWBAstCRZaEiy0JFhoSbDQkmChJcFCS4KFlgQLLYn/AX0/gi0ktFA0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Toke embedding visualization\n",
    "plt.imshow(sd_hf[\"transformer.wte.weight\"], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 4859,
     "status": "ok",
     "timestamp": 1728399272090,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": -60
    },
    "id": "LYx6S7Eig0aS",
    "outputId": "6fa8570f-5f49-413b-837d-c2f80e86c4c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x78f00c116950>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization of 150th dimension(150th colum) of all token embedding\n",
    "plt.plot(sd_hf[\"transformer.wte.weight\"][:,150])\n",
    "plt.plot(sd_hf[\"transformer.wte.weight\"][:,200])\n",
    "plt.plot(sd_hf[\"transformer.wte.weight\"][:,250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328,
     "referenced_widgets": [
      "f80c9cc1f00c48f8b6567455c778c61a",
      "94787369b0a34adc9f10222da3c86bcc",
      "dd85d32387284cebbd39b4f53b5b95b9",
      "c3d1acd056be42a4b5db596d8d25e062",
      "0010aea8a4724193a88934f98808c164",
      "bc7ef5421d3b45f794da62ba739fff80",
      "35d8f6a5d5d24deba70463e5f3b0d59e",
      "d9d84509a04e4d888c2ecf66510b5c1a",
      "c08a4f306f724c77b9ecf31b4e84ad64",
      "5b686a76e40a46c58f406f92d0714ba1",
      "ce3d061b31b34cd2b3f12d6bbb8b3d13",
      "fb43b0ef8dca47bab78a8948f72db8a7",
      "9d4bd4b3eb9e44fc8ff796739525a12b",
      "0297148a4b0a492c834bc3eeec6208cd",
      "1411fe49438c4076b001876637572ddc",
      "ea8d74d64a8d4b3fa6c9582977c20c72",
      "55d2c41870e1425e974ec6d20f04ffe5",
      "bc833a24ced64691886b60483f388350",
      "223ee77299944edca398704431af9fbc",
      "0472e1487364460ea9921b63a5ac35ad",
      "d283c332b3304e8184ccaf7ddcdcea6d",
      "99ea36b13f20468ab6600deb2ba79308",
      "d7e0d8d65e7546e8851dc2d84709029a",
      "bb549ee1da74449284b34c371b152efc",
      "215bd024b5784711be6fda92ff6189c5",
      "8cf98ca329164363aa2784842c1414f5",
      "916d40cef053485c8d15a1960f79ba01",
      "ce20f5a3370147a5a371a6a48286c5b1",
      "4d68cd6dcac441a69795fbf54d534123",
      "a5fdaa63f06849f38a8326faf6c223e1",
      "2759d4feecd04ae5b8dc4ea3faa02922",
      "665f6198e0f64e81a3e2c12b15c8e4be",
      "7a4955deac344b328d15b252daa4e5e1",
      "29f3789f5ed54d4f93c9dfbc47cd6978",
      "520e1453adb545d89456cf6811828077",
      "0c29373473c04f4d9bc9b1740a707715",
      "9337f2cd834c410b8841bdcb31184ef5",
      "dd22711b1a9647fe8e1a7a8f47bf0a4e",
      "63bf349390604881a3888f719a3cd3b8",
      "9795a91ab3cb47038dc6c01d726847e7",
      "1984d60ed4044f08af91a59e5d0f93b9",
      "de0836a2fc7a4716a1298d5dfbd80809",
      "27286e49ff64436094d37a7e75860b9f",
      "07f4cfcd15fc48f09123a50185daac6e"
     ]
    },
    "executionInfo": {
     "elapsed": 6756,
     "status": "ok",
     "timestamp": 1728399437533,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": -60
    },
    "id": "jSvDJr0Anak4",
    "outputId": "419b10a8-08fc-45fe-c092-fe6c2aaf363a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80c9cc1f00c48f8b6567455c778c61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb43b0ef8dca47bab78a8948f72db8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e0d8d65e7546e8851dc2d84709029a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f3789f5ed54d4f93c9dfbc47cd6978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, I'm a language model, but what I'm really doing is making a human-readable document. There are other languages, but those are\"},\n",
       " {'generated_text': \"Hello, I'm a language model, not a syntax model. That's why I like it. I've done a lot of programming projects.\\n\"},\n",
       " {'generated_text': \"Hello, I'm a language model, and I'll do it in no time!\\n\\nOne of the things we learned from talking to my friend\"},\n",
       " {'generated_text': \"Hello, I'm a language model, not a command line tool.\\n\\nIf my code is simple enough:\\n\\nif (use (string\"},\n",
       " {'generated_text': \"Hello, I'm a language model, I've been using Language in all my work. Just a small example, let's see a simplified example.\"}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RoeeZ6KIpEPI"
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = MultiHeadAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3CDd_Svm73hf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVkRuds573eZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xFKQpfU73bi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20630,
     "status": "ok",
     "timestamp": 1731012080307,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "M32fompH73Yg",
    "outputId": "e035e227-8e15-4690-a5f6-cfaa47aa6a3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9059,
     "status": "ok",
     "timestamp": 1731012089700,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "L83MdVXK7_ZF",
    "outputId": "283de892-607d-476a-e11d-bdc97c477825"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting mlflow\n",
      "  Downloading mlflow-2.17.2-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
      "Collecting mlflow-skinny==2.17.2 (from mlflow)\n",
      "  Downloading mlflow_skinny-2.17.2-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Downloading graphene-3.4.1-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.8.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.2)\n",
      "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.36)\n",
      "Collecting gunicorn<24 (from mlflow)\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (3.1.0)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.17.2->mlflow)\n",
      "  Downloading databricks_sdk-0.36.0-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (3.1.43)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (1.16.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (3.20.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (0.5.1)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.6)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (2.27.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.2->mlflow) (4.0.11)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.2->mlflow) (3.20.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow) (1.2.14)\n",
      "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow) (75.1.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow) (0.37b0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.2->mlflow) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (0.6.1)\n",
      "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mlflow-2.17.2-py3-none-any.whl (26.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-2.17.2-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m126.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphene-3.4.1-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading databricks_sdk-0.36.0-py3-none-any.whl (569 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m569.1/569.1 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, Mako, gunicorn, graphql-core, fsspec, dill, tiktoken, multiprocess, graphql-relay, docker, alembic, graphene, databricks-sdk, mlflow-skinny, mlflow, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.6 alembic-1.14.0 databricks-sdk-0.36.0 datasets-3.1.0 dill-0.3.8 docker-7.1.0 fsspec-2024.9.0 graphene-3.4.1 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.17.2 mlflow-skinny-2.17.2 multiprocess-0.70.16 tiktoken-0.8.0 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio transformers tiktoken datasets mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 95472,
     "status": "ok",
     "timestamp": 1731011940067,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "eAe5SmSHV6HM",
    "outputId": "14edbf42-0b40-4d05-fd54-5834b29b9dd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Enter your token (input will not be visible): \n",
      "Add token as git credential? (Y/n) Y\n",
      "Token is valid (permission: fineGrained).\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub\n",
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "rSWN70HoG9rX",
    "outputId": "905211ab-59db-4f37-f53b-76ff374eec6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n",
      "total desired batch size: 16384\n",
      "=> calculated gradient accumulation steps: 1\n",
      "found 11 shards for split train\n",
      "found 1 shards for split val\n",
      "data is ready....\n",
      "config.json: 100% 614/614 [00:00<00:00, 3.31MB/s]\n",
      "model.safetensors.index.json: 100% 26.8k/26.8k [00:00<00:00, 108MB/s]\n",
      "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
      "model-00001-of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   0% 10.5M/9.98G [00:00<02:22, 69.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   0% 41.9M/9.98G [00:00<01:01, 160MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:   1% 73.4M/9.98G [00:00<00:51, 193MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1% 105M/9.98G [00:00<00:47, 207MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:   1% 136M/9.98G [00:00<00:45, 216MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2% 168M/9.98G [00:00<00:49, 199MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2% 199M/9.98G [00:01<00:49, 199MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2% 231M/9.98G [00:01<00:47, 206MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3% 262M/9.98G [00:01<00:45, 212MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3% 294M/9.98G [00:01<00:42, 226MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3% 325M/9.98G [00:01<00:42, 228MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4% 357M/9.98G [00:01<00:41, 234MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4% 388M/9.98G [00:01<00:40, 239MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4% 419M/9.98G [00:01<00:43, 219MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5% 451M/9.98G [00:02<00:42, 223MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5% 482M/9.98G [00:02<00:41, 231MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5% 514M/9.98G [00:02<00:42, 225MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5% 545M/9.98G [00:02<00:45, 209MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6% 577M/9.98G [00:02<00:45, 205MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6% 608M/9.98G [00:02<00:45, 205MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6% 629M/9.98G [00:03<00:47, 195MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7% 650M/9.98G [00:03<00:47, 196MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7% 671M/9.98G [00:03<00:47, 195MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7% 703M/9.98G [00:03<00:45, 206MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7% 734M/9.98G [00:03<00:42, 218MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8% 765M/9.98G [00:03<00:40, 227MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8% 797M/9.98G [00:03<00:39, 234MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8% 828M/9.98G [00:03<00:41, 222MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9% 860M/9.98G [00:04<00:44, 203MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9% 881M/9.98G [00:04<00:46, 197MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9% 902M/9.98G [00:04<00:47, 193MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9% 933M/9.98G [00:04<00:43, 207MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10% 965M/9.98G [00:04<00:41, 217MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10% 996M/9.98G [00:04<00:39, 225MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10% 1.03G/9.98G [00:04<00:39, 228MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11% 1.06G/9.98G [00:05<00:43, 203MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11% 1.09G/9.98G [00:05<00:41, 212MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11% 1.12G/9.98G [00:05<00:40, 216MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12% 1.15G/9.98G [00:05<00:40, 218MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12% 1.18G/9.98G [00:05<00:40, 219MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12% 1.22G/9.98G [00:05<00:39, 224MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13% 1.25G/9.98G [00:05<00:41, 211MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13% 1.28G/9.98G [00:06<00:43, 198MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13% 1.31G/9.98G [00:06<00:42, 205MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13% 1.34G/9.98G [00:06<00:41, 208MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14% 1.37G/9.98G [00:06<00:45, 191MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14% 1.41G/9.98G [00:06<00:43, 198MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14% 1.44G/9.98G [00:06<00:40, 210MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15% 1.47G/9.98G [00:06<00:40, 208MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15% 1.50G/9.98G [00:07<00:38, 221MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15% 1.53G/9.98G [00:07<00:42, 197MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16% 1.55G/9.98G [00:07<00:45, 187MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16% 1.57G/9.98G [00:07<00:44, 188MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16% 1.59G/9.98G [00:07<00:44, 190MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16% 1.61G/9.98G [00:07<00:45, 185MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17% 1.65G/9.98G [00:07<00:40, 207MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17% 1.68G/9.98G [00:08<00:37, 219MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17% 1.71G/9.98G [00:08<00:37, 221MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17% 1.74G/9.98G [00:08<00:36, 225MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18% 1.77G/9.98G [00:08<00:35, 229MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18% 1.80G/9.98G [00:08<00:35, 229MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18% 1.84G/9.98G [00:08<00:36, 226MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19% 1.87G/9.98G [00:08<00:34, 233MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19% 1.90G/9.98G [00:09<00:39, 206MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19% 1.93G/9.98G [00:09<00:38, 211MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20% 1.96G/9.98G [00:09<00:38, 210MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20% 1.99G/9.98G [00:09<00:40, 197MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20% 2.01G/9.98G [00:09<00:40, 196MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20% 2.03G/9.98G [00:09<00:40, 197MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21% 2.07G/9.98G [00:09<00:37, 210MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21% 2.10G/9.98G [00:10<00:38, 207MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21% 2.12G/9.98G [00:10<00:44, 177MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21% 2.14G/9.98G [00:10<00:44, 175MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22% 2.16G/9.98G [00:10<00:47, 166MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22% 2.18G/9.98G [00:10<00:58, 132MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22% 2.20G/9.98G [00:10<01:07, 114MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22% 2.23G/9.98G [00:11<00:55, 140MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23% 2.25G/9.98G [00:11<01:00, 128MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23% 2.28G/9.98G [00:11<00:56, 136MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23% 2.30G/9.98G [00:11<00:55, 139MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23% 2.32G/9.98G [00:11<01:00, 127MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23% 2.34G/9.98G [00:12<01:15, 101MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24% 2.36G/9.98G [00:12<01:20, 94.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24% 2.38G/9.98G [00:12<01:11, 106MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  24% 2.40G/9.98G [00:12<01:19, 95.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24% 2.42G/9.98G [00:13<01:29, 84.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25% 2.45G/9.98G [00:13<01:09, 109MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  25% 2.47G/9.98G [00:13<01:17, 97.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25% 2.50G/9.98G [00:13<01:08, 109MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  25% 2.52G/9.98G [00:13<01:11, 104MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25% 2.54G/9.98G [00:14<01:14, 99.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26% 2.56G/9.98G [00:14<01:24, 87.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26% 2.57G/9.98G [00:14<01:35, 77.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26% 2.59G/9.98G [00:14<01:16, 96.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26% 2.62G/9.98G [00:14<00:57, 128MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  27% 2.65G/9.98G [00:14<00:47, 154MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27% 2.68G/9.98G [00:15<00:42, 173MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27% 2.72G/9.98G [00:15<00:40, 181MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27% 2.74G/9.98G [00:15<00:39, 185MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28% 2.77G/9.98G [00:15<00:36, 199MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28% 2.80G/9.98G [00:15<00:34, 209MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28% 2.83G/9.98G [00:15<00:32, 217MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29% 2.86G/9.98G [00:15<00:31, 226MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29% 2.89G/9.98G [00:16<00:32, 216MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29% 2.93G/9.98G [00:16<00:31, 221MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30% 2.96G/9.98G [00:16<00:32, 219MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30% 2.99G/9.98G [00:16<00:31, 220MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30% 3.02G/9.98G [00:16<00:32, 216MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  31% 3.05G/9.98G [00:16<00:32, 215MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  31% 3.08G/9.98G [00:16<00:32, 214MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  31% 3.11G/9.98G [00:17<00:31, 215MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  32% 3.15G/9.98G [00:17<00:31, 218MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  32% 3.18G/9.98G [00:17<00:30, 224MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  32% 3.21G/9.98G [00:17<00:29, 230MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  32% 3.24G/9.98G [00:17<00:29, 229MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  33% 3.27G/9.98G [00:17<00:30, 219MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  33% 3.30G/9.98G [00:17<00:29, 230MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  33% 3.33G/9.98G [00:18<00:29, 228MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34% 3.37G/9.98G [00:18<00:27, 240MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34% 3.40G/9.98G [00:18<00:26, 245MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34% 3.43G/9.98G [00:18<00:26, 243MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  35% 3.46G/9.98G [00:18<00:27, 239MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  35% 3.49G/9.98G [00:18<00:26, 240MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  35% 3.52G/9.98G [00:18<00:38, 169MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36% 3.55G/9.98G [00:19<00:34, 186MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36% 3.59G/9.98G [00:19<00:32, 198MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36% 3.62G/9.98G [00:19<00:31, 199MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37% 3.65G/9.98G [00:19<00:30, 206MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37% 3.68G/9.98G [00:19<00:29, 214MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37% 3.71G/9.98G [00:19<00:28, 223MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38% 3.74G/9.98G [00:19<00:27, 227MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38% 3.77G/9.98G [00:20<00:26, 231MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38% 3.81G/9.98G [00:20<00:26, 233MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38% 3.84G/9.98G [00:20<00:26, 235MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39% 3.87G/9.98G [00:20<00:26, 235MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39% 3.90G/9.98G [00:20<00:25, 237MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39% 3.93G/9.98G [00:20<00:25, 237MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40% 3.96G/9.98G [00:20<00:25, 234MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40% 4.00G/9.98G [00:21<00:26, 222MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40% 4.03G/9.98G [00:21<00:26, 226MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41% 4.06G/9.98G [00:21<00:25, 229MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41% 4.09G/9.98G [00:21<00:25, 232MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41% 4.12G/9.98G [00:21<00:26, 224MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42% 4.15G/9.98G [00:21<00:25, 230MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42% 4.18G/9.98G [00:21<00:24, 233MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42% 4.22G/9.98G [00:21<00:25, 230MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  43% 4.25G/9.98G [00:22<00:25, 223MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  43% 4.28G/9.98G [00:22<00:25, 227MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  43% 4.31G/9.98G [00:22<00:24, 231MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44% 4.34G/9.98G [00:22<00:24, 228MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44% 4.37G/9.98G [00:22<00:25, 223MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44% 4.40G/9.98G [00:22<00:27, 199MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44% 4.44G/9.98G [00:23<00:26, 211MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45% 4.47G/9.98G [00:23<00:25, 215MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45% 4.50G/9.98G [00:23<00:25, 211MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45% 4.53G/9.98G [00:23<00:24, 221MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46% 4.56G/9.98G [00:23<00:25, 215MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46% 4.59G/9.98G [00:23<00:24, 220MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46% 4.62G/9.98G [00:23<00:24, 220MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47% 4.66G/9.98G [00:24<00:24, 221MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47% 4.69G/9.98G [00:24<00:23, 223MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47% 4.72G/9.98G [00:24<00:23, 222MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48% 4.75G/9.98G [00:24<00:22, 230MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48% 4.78G/9.98G [00:24<00:22, 233MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48% 4.81G/9.98G [00:24<00:22, 232MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49% 4.84G/9.98G [00:25<00:32, 156MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49% 4.87G/9.98G [00:25<00:35, 142MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49% 4.89G/9.98G [00:25<00:39, 128MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49% 4.91G/9.98G [00:25<00:37, 134MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49% 4.93G/9.98G [00:25<00:47, 107MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50% 4.95G/9.98G [00:26<00:53, 93.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50% 4.97G/9.98G [00:26<00:58, 86.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50% 4.98G/9.98G [00:26<00:58, 85.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50% 5.00G/9.98G [00:26<00:51, 97.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50% 5.02G/9.98G [00:26<00:48, 101MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  51% 5.04G/9.98G [00:27<00:51, 96.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51% 5.05G/9.98G [00:27<00:52, 92.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51% 5.08G/9.98G [00:27<00:44, 109MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  51% 5.10G/9.98G [00:27<00:37, 129MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51% 5.13G/9.98G [00:27<00:30, 157MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52% 5.16G/9.98G [00:27<00:27, 178MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52% 5.19G/9.98G [00:27<00:24, 195MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52% 5.21G/9.98G [00:28<00:24, 196MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52% 5.23G/9.98G [00:28<00:27, 170MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53% 5.25G/9.98G [00:28<00:39, 120MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53% 5.27G/9.98G [00:28<00:39, 119MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53% 5.30G/9.98G [00:28<00:43, 107MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53% 5.32G/9.98G [00:29<00:44, 104MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53% 5.34G/9.98G [00:29<00:48, 95.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54% 5.35G/9.98G [00:29<00:48, 95.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54% 5.36G/9.98G [00:29<00:48, 96.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54% 5.39G/9.98G [00:29<00:34, 133MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  54% 5.42G/9.98G [00:29<00:28, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55% 5.45G/9.98G [00:30<00:24, 182MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55% 5.48G/9.98G [00:30<00:23, 191MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55% 5.52G/9.98G [00:30<00:22, 199MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56% 5.55G/9.98G [00:30<00:21, 211MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56% 5.58G/9.98G [00:30<00:20, 217MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56% 5.61G/9.98G [00:30<00:19, 220MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57% 5.64G/9.98G [00:30<00:20, 216MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57% 5.67G/9.98G [00:31<00:19, 224MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57% 5.70G/9.98G [00:31<00:18, 230MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57% 5.74G/9.98G [00:31<00:18, 234MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58% 5.77G/9.98G [00:31<00:18, 233MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58% 5.80G/9.98G [00:31<00:19, 214MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58% 5.83G/9.98G [00:31<00:18, 223MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  59% 5.86G/9.98G [00:31<00:18, 224MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  59% 5.89G/9.98G [00:32<00:18, 220MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  59% 5.92G/9.98G [00:32<00:18, 224MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60% 5.96G/9.98G [00:32<00:17, 226MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60% 5.99G/9.98G [00:32<00:17, 229MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60% 6.02G/9.98G [00:32<00:16, 235MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61% 6.05G/9.98G [00:32<00:16, 232MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61% 6.08G/9.98G [00:32<00:16, 233MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61% 6.11G/9.98G [00:32<00:16, 240MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62% 6.14G/9.98G [00:33<00:16, 233MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62% 6.18G/9.98G [00:33<00:16, 231MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62% 6.21G/9.98G [00:33<00:16, 234MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63% 6.24G/9.98G [00:33<00:16, 234MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63% 6.27G/9.98G [00:33<00:15, 234MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63% 6.30G/9.98G [00:33<00:15, 230MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63% 6.33G/9.98G [00:33<00:15, 240MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64% 6.36G/9.98G [00:34<00:14, 242MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64% 6.40G/9.98G [00:34<00:15, 237MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64% 6.43G/9.98G [00:34<00:15, 227MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65% 6.46G/9.98G [00:34<00:16, 220MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65% 6.49G/9.98G [00:34<00:15, 228MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65% 6.52G/9.98G [00:34<00:15, 218MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66% 6.55G/9.98G [00:34<00:15, 223MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66% 6.59G/9.98G [00:35<00:15, 219MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66% 6.62G/9.98G [00:35<00:15, 214MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67% 6.65G/9.98G [00:35<00:15, 218MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67% 6.68G/9.98G [00:35<00:14, 223MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67% 6.71G/9.98G [00:35<00:14, 226MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  68% 6.74G/9.98G [00:35<00:14, 222MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  68% 6.77G/9.98G [00:35<00:14, 227MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  68% 6.81G/9.98G [00:36<00:13, 228MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69% 6.84G/9.98G [00:36<00:13, 230MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69% 6.87G/9.98G [00:36<00:13, 236MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69% 6.90G/9.98G [00:36<00:13, 237MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69% 6.93G/9.98G [00:36<00:12, 236MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  70% 6.96G/9.98G [00:36<00:12, 238MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  70% 6.99G/9.98G [00:36<00:12, 238MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  70% 7.03G/9.98G [00:36<00:12, 238MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71% 7.06G/9.98G [00:37<00:12, 231MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71% 7.09G/9.98G [00:37<00:12, 226MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71% 7.12G/9.98G [00:37<00:12, 229MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  72% 7.15G/9.98G [00:37<00:12, 220MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  72% 7.18G/9.98G [00:37<00:12, 225MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  72% 7.21G/9.98G [00:37<00:12, 222MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73% 7.25G/9.98G [00:37<00:12, 221MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73% 7.28G/9.98G [00:38<00:12, 223MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73% 7.31G/9.98G [00:38<00:11, 226MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  74% 7.34G/9.98G [00:38<00:11, 233MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  74% 7.37G/9.98G [00:38<00:11, 233MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  74% 7.40G/9.98G [00:38<00:10, 234MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75% 7.43G/9.98G [00:38<00:10, 236MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75% 7.47G/9.98G [00:38<00:10, 234MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75% 7.50G/9.98G [00:38<00:10, 237MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75% 7.53G/9.98G [00:39<00:10, 240MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  76% 7.56G/9.98G [00:39<00:10, 239MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  76% 7.59G/9.98G [00:39<00:10, 235MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  76% 7.62G/9.98G [00:39<00:10, 223MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77% 7.65G/9.98G [00:39<00:11, 200MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77% 7.68G/9.98G [00:40<00:15, 150MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77% 7.70G/9.98G [00:40<00:16, 138MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77% 7.72G/9.98G [00:40<00:15, 142MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78% 7.74G/9.98G [00:40<00:22, 101MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78% 7.76G/9.98G [00:40<00:21, 105MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78% 7.78G/9.98G [00:41<00:27, 80.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78% 7.79G/9.98G [00:41<00:26, 83.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78% 7.81G/9.98G [00:41<00:23, 91.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79% 7.83G/9.98G [00:41<00:22, 96.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79% 7.85G/9.98G [00:42<00:26, 81.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79% 7.86G/9.98G [00:42<00:29, 72.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79% 7.87G/9.98G [00:42<00:27, 75.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79% 7.90G/9.98G [00:42<00:25, 81.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79% 7.92G/9.98G [00:42<00:22, 93.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80% 7.94G/9.98G [00:42<00:18, 112MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  80% 7.96G/9.98G [00:43<00:18, 108MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80% 7.98G/9.98G [00:43<00:17, 114MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80% 8.01G/9.98G [00:43<00:17, 110MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81% 8.03G/9.98G [00:43<00:18, 102MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81% 8.05G/9.98G [00:44<00:19, 97.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81% 8.06G/9.98G [00:44<00:20, 94.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81% 8.07G/9.98G [00:44<00:23, 82.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81% 8.10G/9.98G [00:44<00:19, 98.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81% 8.13G/9.98G [00:44<00:13, 134MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  82% 8.16G/9.98G [00:44<00:11, 160MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82% 8.19G/9.98G [00:44<00:09, 180MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82% 8.22G/9.98G [00:45<00:08, 197MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83% 8.24G/9.98G [00:45<00:12, 140MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83% 8.28G/9.98G [00:45<00:09, 179MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83% 8.32G/9.98G [00:45<00:08, 192MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  84% 8.35G/9.98G [00:45<00:08, 201MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  84% 8.38G/9.98G [00:45<00:07, 212MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  84% 8.41G/9.98G [00:46<00:07, 216MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  85% 8.44G/9.98G [00:46<00:06, 221MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  85% 8.47G/9.98G [00:46<00:06, 222MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  85% 8.50G/9.98G [00:46<00:06, 227MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86% 8.54G/9.98G [00:46<00:06, 229MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86% 8.57G/9.98G [00:46<00:06, 233MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86% 8.60G/9.98G [00:46<00:05, 233MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  87% 8.63G/9.98G [00:46<00:05, 234MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  87% 8.66G/9.98G [00:47<00:05, 234MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  87% 8.69G/9.98G [00:47<00:05, 238MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  87% 8.72G/9.98G [00:47<00:05, 239MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  88% 8.76G/9.98G [00:47<00:05, 235MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  88% 8.79G/9.98G [00:47<00:05, 234MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  88% 8.82G/9.98G [00:47<00:04, 235MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89% 8.85G/9.98G [00:47<00:04, 236MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89% 8.88G/9.98G [00:48<00:04, 229MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89% 8.91G/9.98G [00:48<00:04, 233MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  90% 8.94G/9.98G [00:48<00:04, 240MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  90% 8.98G/9.98G [00:48<00:04, 240MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  90% 9.01G/9.98G [00:48<00:04, 225MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91% 9.04G/9.98G [00:48<00:04, 231MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91% 9.07G/9.98G [00:48<00:03, 237MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91% 9.10G/9.98G [00:49<00:03, 239MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92% 9.13G/9.98G [00:49<00:03, 235MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92% 9.16G/9.98G [00:49<00:03, 237MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92% 9.20G/9.98G [00:49<00:03, 239MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92% 9.23G/9.98G [00:49<00:03, 241MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  93% 9.26G/9.98G [00:49<00:02, 244MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  93% 9.29G/9.98G [00:49<00:02, 245MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  93% 9.32G/9.98G [00:49<00:02, 243MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94% 9.35G/9.98G [00:50<00:02, 239MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94% 9.38G/9.98G [00:50<00:02, 232MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94% 9.42G/9.98G [00:50<00:02, 238MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95% 9.45G/9.98G [00:50<00:02, 237MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95% 9.48G/9.98G [00:50<00:02, 229MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95% 9.51G/9.98G [00:50<00:01, 236MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  96% 9.54G/9.98G [00:50<00:01, 236MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  96% 9.57G/9.98G [00:50<00:01, 234MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  96% 9.60G/9.98G [00:51<00:01, 243MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97% 9.64G/9.98G [00:51<00:01, 233MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97% 9.67G/9.98G [00:51<00:01, 227MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97% 9.70G/9.98G [00:51<00:01, 222MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98% 9.73G/9.98G [00:51<00:01, 222MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98% 9.76G/9.98G [00:51<00:00, 219MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98% 9.79G/9.98G [00:51<00:00, 221MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98% 9.83G/9.98G [00:52<00:00, 224MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99% 9.86G/9.98G [00:52<00:00, 226MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99% 9.89G/9.98G [00:52<00:00, 217MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99% 9.92G/9.98G [00:52<00:00, 219MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors: 100% 9.95G/9.98G [00:52<00:00, 225MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors: 100% 9.98G/9.98G [00:52<00:00, 189MB/s]\n",
      "Downloading shards:  50% 1/2 [00:53<00:53, 53.11s/it]\n",
      "model-00002-of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   1% 21.0M/3.50G [00:00<00:28, 124MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   1% 52.4M/3.50G [00:00<00:19, 176MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   2% 83.9M/3.50G [00:00<00:16, 204MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   3% 115M/3.50G [00:00<00:15, 217MB/s] \u001b[A\n",
      "model-00002-of-00002.safetensors:   4% 147M/3.50G [00:00<00:14, 234MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   5% 178M/3.50G [00:00<00:14, 225MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   6% 210M/3.50G [00:00<00:15, 219MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   7% 241M/3.50G [00:01<00:14, 225MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   8% 273M/3.50G [00:01<00:13, 233MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   9% 304M/3.50G [00:01<00:13, 231MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  10% 336M/3.50G [00:01<00:13, 229MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  10% 367M/3.50G [00:01<00:13, 233MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  11% 398M/3.50G [00:01<00:13, 233MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  12% 430M/3.50G [00:02<00:15, 198MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  13% 451M/3.50G [00:02<00:15, 198MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  14% 482M/3.50G [00:02<00:14, 209MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  15% 514M/3.50G [00:02<00:13, 219MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  16% 545M/3.50G [00:02<00:13, 225MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  16% 577M/3.50G [00:02<00:13, 224MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  17% 608M/3.50G [00:02<00:12, 225MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  18% 640M/3.50G [00:03<00:14, 192MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  19% 671M/3.50G [00:03<00:14, 201MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  20% 703M/3.50G [00:03<00:13, 205MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  21% 734M/3.50G [00:03<00:13, 212MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  22% 765M/3.50G [00:03<00:12, 223MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  23% 797M/3.50G [00:03<00:11, 226MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  24% 828M/3.50G [00:03<00:11, 228MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  25% 860M/3.50G [00:04<00:13, 193MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  25% 891M/3.50G [00:04<00:12, 204MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  26% 923M/3.50G [00:04<00:11, 215MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  27% 954M/3.50G [00:04<00:11, 219MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  28% 986M/3.50G [00:04<00:11, 224MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  29% 1.02G/3.50G [00:04<00:11, 214MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  30% 1.05G/3.50G [00:05<00:16, 148MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  31% 1.08G/3.50G [00:05<00:14, 168MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  31% 1.10G/3.50G [00:05<00:13, 173MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  32% 1.12G/3.50G [00:05<00:13, 179MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  33% 1.15G/3.50G [00:05<00:12, 189MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  34% 1.18G/3.50G [00:05<00:11, 196MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  35% 1.22G/3.50G [00:05<00:11, 205MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  36% 1.25G/3.50G [00:06<00:10, 219MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  37% 1.28G/3.50G [00:06<00:09, 235MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  37% 1.31G/3.50G [00:06<00:09, 235MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  38% 1.34G/3.50G [00:06<00:09, 238MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  39% 1.37G/3.50G [00:06<00:08, 238MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  40% 1.41G/3.50G [00:06<00:08, 241MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  41% 1.44G/3.50G [00:06<00:08, 237MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  42% 1.47G/3.50G [00:06<00:09, 210MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  43% 1.50G/3.50G [00:07<00:09, 215MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  44% 1.53G/3.50G [00:07<00:08, 219MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  45% 1.56G/3.50G [00:07<00:08, 221MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  46% 1.59G/3.50G [00:07<00:08, 225MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  46% 1.63G/3.50G [00:07<00:08, 227MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  47% 1.66G/3.50G [00:07<00:07, 233MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  48% 1.69G/3.50G [00:08<00:09, 192MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  49% 1.72G/3.50G [00:08<00:08, 204MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  50% 1.75G/3.50G [00:08<00:08, 214MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  51% 1.78G/3.50G [00:08<00:07, 223MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  52% 1.81G/3.50G [00:08<00:07, 232MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  53% 1.85G/3.50G [00:08<00:07, 234MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  54% 1.88G/3.50G [00:08<00:06, 232MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  55% 1.91G/3.50G [00:09<00:08, 179MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  55% 1.94G/3.50G [00:09<00:08, 194MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  56% 1.97G/3.50G [00:09<00:07, 200MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  57% 2.00G/3.50G [00:09<00:07, 214MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  58% 2.03G/3.50G [00:09<00:06, 216MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  59% 2.07G/3.50G [00:09<00:06, 222MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  60% 2.10G/3.50G [00:09<00:07, 186MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  61% 2.12G/3.50G [00:10<00:08, 164MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  61% 2.14G/3.50G [00:10<00:09, 138MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  62% 2.16G/3.50G [00:10<00:09, 140MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  63% 2.19G/3.50G [00:10<00:08, 158MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  63% 2.21G/3.50G [00:10<00:08, 152MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  64% 2.24G/3.50G [00:10<00:07, 173MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  65% 2.28G/3.50G [00:11<00:06, 190MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  66% 2.31G/3.50G [00:11<00:06, 196MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  67% 2.34G/3.50G [00:11<00:05, 201MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  68% 2.37G/3.50G [00:11<00:05, 209MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  69% 2.40G/3.50G [00:11<00:05, 195MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  69% 2.43G/3.50G [00:11<00:05, 206MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  70% 2.46G/3.50G [00:12<00:06, 149MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  71% 2.49G/3.50G [00:12<00:07, 142MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  72% 2.52G/3.50G [00:12<00:06, 161MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  73% 2.55G/3.50G [00:12<00:05, 178MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  73% 2.57G/3.50G [00:12<00:05, 180MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  74% 2.60G/3.50G [00:12<00:04, 193MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  75% 2.63G/3.50G [00:13<00:04, 205MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  76% 2.66G/3.50G [00:13<00:03, 220MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  77% 2.69G/3.50G [00:13<00:03, 220MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  78% 2.73G/3.50G [00:13<00:04, 191MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  78% 2.75G/3.50G [00:13<00:04, 179MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  79% 2.78G/3.50G [00:13<00:03, 195MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  80% 2.81G/3.50G [00:13<00:03, 208MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  81% 2.84G/3.50G [00:14<00:03, 170MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  82% 2.87G/3.50G [00:14<00:03, 184MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  83% 2.89G/3.50G [00:14<00:03, 159MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  83% 2.92G/3.50G [00:14<00:03, 150MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  84% 2.94G/3.50G [00:14<00:03, 146MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  84% 2.96G/3.50G [00:15<00:04, 121MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  85% 2.98G/3.50G [00:15<00:04, 108MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  86% 3.00G/3.50G [00:15<00:04, 101MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  86% 3.02G/3.50G [00:15<00:04, 119MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  87% 3.04G/3.50G [00:15<00:04, 110MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  87% 3.06G/3.50G [00:16<00:04, 92.3MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  88% 3.08G/3.50G [00:16<00:04, 83.7MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  89% 3.11G/3.50G [00:16<00:03, 112MB/s] \u001b[A\n",
      "model-00002-of-00002.safetensors:  90% 3.15G/3.50G [00:16<00:02, 137MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  91% 3.18G/3.50G [00:17<00:02, 119MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  92% 3.21G/3.50G [00:17<00:01, 147MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  93% 3.24G/3.50G [00:17<00:01, 171MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  93% 3.27G/3.50G [00:17<00:01, 186MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  94% 3.30G/3.50G [00:17<00:00, 201MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  95% 3.33G/3.50G [00:17<00:00, 215MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  96% 3.37G/3.50G [00:17<00:00, 218MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  97% 3.40G/3.50G [00:17<00:00, 227MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  98% 3.43G/3.50G [00:18<00:00, 229MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  99% 3.46G/3.50G [00:18<00:00, 236MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors: 100% 3.50G/3.50G [00:18<00:00, 190MB/s]\n",
      "Downloading shards: 100% 2/2 [01:11<00:00, 35.88s/it]\n",
      "Loading checkpoint shards: 100% 2/2 [00:40<00:00, 20.37s/it]\n",
      "generation_config.json: 100% 188/188 [00:00<00:00, 1.46MB/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/Llama_Medical_LLM/train_llama.py\", line 429, in <module>\n",
      "    optimizer = raw_model.configure_optimizers(weight_decay=0.1, learning_rate=6e-4, device_type=device_type)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1931, in __getattr__\n",
      "    raise AttributeError(\n",
      "AttributeError: 'LlamaForCausalLM' object has no attribute 'configure_optimizers'\n"
     ]
    }
   ],
   "source": [
    "!python /content/drive/MyDrive/Llama_Medical_LLM/train_llama.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swMxjdf4cMYn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1729890560437,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": -60
    },
    "id": "afwbVYFNeFCc",
    "outputId": "4f1b4aa8-14c5-428b-8479-34b12c0b7363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max token ID in medical_val_000000.npy: 50256\n",
      "Max token ID in medical_train_000001.npy: 50256\n",
      "Max token ID in medical_train_000002.npy: 50256\n",
      "Max token ID in medical_train_000003.npy: 50256\n",
      "Max token ID in medical_train_000004.npy: 50256\n",
      "Max token ID in medical_train_000005.npy: 50256\n",
      "Max token ID in medical_train_000006.npy: 50256\n",
      "Max token ID in medical_train_000007.npy: 50256\n",
      "Max token ID in medical_train_000008.npy: 50256\n",
      "Max token ID in medical_train_000009.npy: 50256\n",
      "Max token ID in medical_train_000010.npy: 50256\n",
      "Overall maximum token ID in the dataset: 50256\n",
      "Warning: Maximum token ID 50256 exceeds the vocab size 22731.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Define the data root and tokenizer\n",
    "data_root = \"/content/drive/MyDrive/Medical_LLM/medical_dataset_cache\"\n",
    "\n",
    "# Initialize variables to track the maximum token ID\n",
    "max_token_id = 0\n",
    "\n",
    "# Loop over all data shards\n",
    "for shard_filename in os.listdir(data_root):\n",
    "    if shard_filename.endswith('.npy'):  # assuming tokens are stored in .npy format\n",
    "        # Load token shard\n",
    "        shard_path = os.path.join(data_root, shard_filename)\n",
    "        tokens = np.load(shard_path)\n",
    "\n",
    "        # Find the maximum token ID in this shard\n",
    "        shard_max_token_id = tokens.max()\n",
    "        print(f\"Max token ID in {shard_filename}: {shard_max_token_id}\")\n",
    "\n",
    "        # Update the overall maximum token ID if this shard has a higher value\n",
    "        if shard_max_token_id > max_token_id:\n",
    "            max_token_id = shard_max_token_id\n",
    "\n",
    "print(f\"Overall maximum token ID in the dataset: {max_token_id}\")\n",
    "\n",
    "# Check if it exceeds the vocab size\n",
    "vocab_size = 22731  # set this to the vocab size defined in GPTConfig\n",
    "if max_token_id >= vocab_size:\n",
    "    print(f\"Warning: Maximum token ID {max_token_id} exceeds the vocab size {vocab_size}.\")\n",
    "else:\n",
    "    print(\"All token IDs are within the vocabulary range.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7252,
     "status": "ok",
     "timestamp": 1730902178851,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "P0l80TYUBLd2",
    "outputId": "b36126f3-32e4-4320-b22f-ef0e542353ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-2.17.2-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting mlflow-skinny==2.17.2 (from mlflow)\n",
      "  Downloading mlflow_skinny-2.17.2-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Downloading graphene-3.4.1-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.26.4)\n",
      "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.2)\n",
      "Requirement already satisfied: pyarrow<18,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (17.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.2)\n",
      "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.36)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
      "Collecting gunicorn<24 (from mlflow)\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (3.1.0)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.17.2->mlflow)\n",
      "  Downloading databricks_sdk-0.36.0-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (3.1.43)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (1.16.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (1.16.0)\n",
      "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (24.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (3.20.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (2.32.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.2->mlflow) (0.5.1)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.6)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (2.27.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.2->mlflow) (4.0.11)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.2->mlflow) (3.20.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow) (1.2.14)\n",
      "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow) (75.1.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow) (0.37b0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.2->mlflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.2->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.2->mlflow) (2024.8.30)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.2->mlflow) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow) (0.6.1)\n",
      "Downloading mlflow-2.17.2-py3-none-any.whl (26.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-2.17.2-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphene-3.4.1-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading databricks_sdk-0.36.0-py3-none-any.whl (569 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m569.1/569.1 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Mako, gunicorn, graphql-core, graphql-relay, docker, alembic, graphene, databricks-sdk, mlflow-skinny, mlflow\n",
      "Successfully installed Mako-1.3.6 alembic-1.14.0 databricks-sdk-0.36.0 docker-7.1.0 graphene-3.4.1 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.17.2 mlflow-skinny-2.17.2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6CJWPB7fCQ-m"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1650749,
     "status": "ok",
     "timestamp": 1730222262738,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "JN4hoJHR8Kr9",
    "outputId": "8204b5bf-986c-4a31-8976-87244be298f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "step 17422 | loss: 0.008090 | lr 7.0705e-05 | norm: 0.1008 | dt: 178.51ms | tok/sec: 91781.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17423 | loss: 0.005475 | lr 7.0692e-05 | norm: 0.0935 | dt: 181.25ms | tok/sec: 90394.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17424 | loss: 0.005372 | lr 7.0679e-05 | norm: 0.0914 | dt: 178.64ms | tok/sec: 91712.91\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17425 | loss: 0.005326 | lr 7.0666e-05 | norm: 0.0698 | dt: 178.42ms | tok/sec: 91830.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17426 | loss: 0.006384 | lr 7.0654e-05 | norm: 0.1127 | dt: 178.73ms | tok/sec: 91670.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17427 | loss: 0.007071 | lr 7.0641e-05 | norm: 0.1248 | dt: 182.23ms | tok/sec: 89906.01\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17428 | loss: 0.006308 | lr 7.0628e-05 | norm: 0.0883 | dt: 180.06ms | tok/sec: 90993.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17429 | loss: 0.008127 | lr 7.0615e-05 | norm: 0.1235 | dt: 179.23ms | tok/sec: 91411.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17430 | loss: 0.007731 | lr 7.0602e-05 | norm: 0.0980 | dt: 179.13ms | tok/sec: 91462.56\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17431 | loss: 0.006541 | lr 7.0589e-05 | norm: 0.0988 | dt: 178.98ms | tok/sec: 91539.92\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17432 | loss: 0.004909 | lr 7.0577e-05 | norm: 0.0760 | dt: 178.46ms | tok/sec: 91806.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17433 | loss: 0.006884 | lr 7.0564e-05 | norm: 0.0845 | dt: 178.51ms | tok/sec: 91781.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17434 | loss: 0.007496 | lr 7.0551e-05 | norm: 0.1023 | dt: 179.91ms | tok/sec: 91068.51\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17435 | loss: 0.005087 | lr 7.0538e-05 | norm: 0.0776 | dt: 186.05ms | tok/sec: 88063.62\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17436 | loss: 0.007295 | lr 7.0525e-05 | norm: 0.0850 | dt: 178.60ms | tok/sec: 91734.95\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17437 | loss: 0.006051 | lr 7.0513e-05 | norm: 0.0837 | dt: 178.36ms | tok/sec: 91856.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17438 | loss: 0.006517 | lr 7.0500e-05 | norm: 0.0837 | dt: 180.11ms | tok/sec: 90966.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17439 | loss: 0.005173 | lr 7.0487e-05 | norm: 0.0805 | dt: 179.48ms | tok/sec: 91287.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17440 | loss: 0.005066 | lr 7.0474e-05 | norm: 0.0707 | dt: 179.73ms | tok/sec: 91159.60\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17441 | loss: 0.005411 | lr 7.0462e-05 | norm: 0.0740 | dt: 179.66ms | tok/sec: 91194.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17442 | loss: 0.007598 | lr 7.0449e-05 | norm: 0.0787 | dt: 179.58ms | tok/sec: 91237.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17443 | loss: 0.007719 | lr 7.0436e-05 | norm: 0.1151 | dt: 178.82ms | tok/sec: 91621.20\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17444 | loss: 0.007094 | lr 7.0423e-05 | norm: 0.0929 | dt: 179.19ms | tok/sec: 91434.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17445 | loss: 0.005952 | lr 7.0411e-05 | norm: 0.0781 | dt: 181.75ms | tok/sec: 90146.25\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17446 | loss: 0.007119 | lr 7.0398e-05 | norm: 0.1060 | dt: 179.91ms | tok/sec: 91065.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17447 | loss: 0.007701 | lr 7.0385e-05 | norm: 0.0974 | dt: 179.25ms | tok/sec: 91403.43\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17448 | loss: 0.004797 | lr 7.0373e-05 | norm: 0.0767 | dt: 179.26ms | tok/sec: 91396.14\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17449 | loss: 0.005836 | lr 7.0360e-05 | norm: 0.0787 | dt: 180.13ms | tok/sec: 90956.77\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17450 | loss: 0.006674 | lr 7.0347e-05 | norm: 0.0747 | dt: 179.84ms | tok/sec: 91101.23\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17451 | loss: 0.005824 | lr 7.0335e-05 | norm: 0.0630 | dt: 180.67ms | tok/sec: 90685.26\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17452 | loss: 0.006154 | lr 7.0322e-05 | norm: 0.0897 | dt: 179.20ms | tok/sec: 91428.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17453 | loss: 0.006215 | lr 7.0309e-05 | norm: 0.0871 | dt: 178.64ms | tok/sec: 91716.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17454 | loss: 0.004775 | lr 7.0297e-05 | norm: 0.0840 | dt: 179.11ms | tok/sec: 91475.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17455 | loss: 0.006451 | lr 7.0284e-05 | norm: 0.0888 | dt: 178.65ms | tok/sec: 91707.77\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17456 | loss: 0.005979 | lr 7.0271e-05 | norm: 0.0783 | dt: 180.54ms | tok/sec: 90750.29\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17457 | loss: 0.006200 | lr 7.0259e-05 | norm: 0.1053 | dt: 179.13ms | tok/sec: 91461.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17458 | loss: 0.006804 | lr 7.0246e-05 | norm: 0.0980 | dt: 178.77ms | tok/sec: 91647.60\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17459 | loss: 0.006000 | lr 7.0234e-05 | norm: 0.0762 | dt: 178.92ms | tok/sec: 91570.90\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17460 | loss: 0.005700 | lr 7.0221e-05 | norm: 0.0895 | dt: 178.77ms | tok/sec: 91649.19\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17461 | loss: 0.006923 | lr 7.0208e-05 | norm: 0.0934 | dt: 178.28ms | tok/sec: 91898.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17462 | loss: 0.004245 | lr 7.0196e-05 | norm: 0.0710 | dt: 179.89ms | tok/sec: 91076.72\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17463 | loss: 0.003767 | lr 7.0183e-05 | norm: 0.0591 | dt: 179.37ms | tok/sec: 91344.14\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17464 | loss: 0.006747 | lr 7.0171e-05 | norm: 0.0857 | dt: 179.20ms | tok/sec: 91427.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17465 | loss: 0.004327 | lr 7.0158e-05 | norm: 0.0630 | dt: 178.49ms | tok/sec: 91791.56\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17466 | loss: 0.006484 | lr 7.0146e-05 | norm: 0.0805 | dt: 179.37ms | tok/sec: 91341.71\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17467 | loss: 0.007278 | lr 7.0133e-05 | norm: 0.0701 | dt: 181.02ms | tok/sec: 90507.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17468 | loss: 0.007004 | lr 7.0120e-05 | norm: 0.0867 | dt: 180.49ms | tok/sec: 90773.07\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17469 | loss: 0.007079 | lr 7.0108e-05 | norm: 0.0842 | dt: 179.34ms | tok/sec: 91356.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17470 | loss: 0.005097 | lr 7.0095e-05 | norm: 0.0670 | dt: 180.21ms | tok/sec: 90916.58\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17471 | loss: 0.005736 | lr 7.0083e-05 | norm: 0.0885 | dt: 182.44ms | tok/sec: 89804.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17472 | loss: 0.005074 | lr 7.0070e-05 | norm: 0.0763 | dt: 180.01ms | tok/sec: 91018.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17473 | loss: 0.009665 | lr 7.0058e-05 | norm: 0.0920 | dt: 179.70ms | tok/sec: 91171.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17474 | loss: 0.008342 | lr 7.0045e-05 | norm: 0.0749 | dt: 180.39ms | tok/sec: 90826.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17475 | loss: 0.004903 | lr 7.0033e-05 | norm: 0.0814 | dt: 183.73ms | tok/sec: 89174.04\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17476 | loss: 0.008933 | lr 7.0020e-05 | norm: 0.1212 | dt: 182.75ms | tok/sec: 89650.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17477 | loss: 0.009485 | lr 7.0008e-05 | norm: 0.1015 | dt: 185.14ms | tok/sec: 88493.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17478 | loss: 0.007602 | lr 6.9996e-05 | norm: 0.0837 | dt: 179.92ms | tok/sec: 91062.11\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17479 | loss: 0.006512 | lr 6.9983e-05 | norm: 0.0814 | dt: 179.97ms | tok/sec: 91035.45\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17480 | loss: 0.007124 | lr 6.9971e-05 | norm: 0.0924 | dt: 178.99ms | tok/sec: 91533.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17481 | loss: 0.007744 | lr 6.9958e-05 | norm: 0.0966 | dt: 179.91ms | tok/sec: 91069.35\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17482 | loss: 0.009226 | lr 6.9946e-05 | norm: 0.1162 | dt: 179.64ms | tok/sec: 91203.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17483 | loss: 0.007950 | lr 6.9933e-05 | norm: 0.1116 | dt: 180.08ms | tok/sec: 90983.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17484 | loss: 0.008455 | lr 6.9921e-05 | norm: 0.1042 | dt: 180.28ms | tok/sec: 90881.11\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17485 | loss: 0.006756 | lr 6.9909e-05 | norm: 0.0744 | dt: 179.25ms | tok/sec: 91401.12\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17486 | loss: 0.010946 | lr 6.9896e-05 | norm: 0.1205 | dt: 179.41ms | tok/sec: 91321.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17487 | loss: 0.010534 | lr 6.9884e-05 | norm: 0.1054 | dt: 178.91ms | tok/sec: 91578.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17488 | loss: 0.008312 | lr 6.9871e-05 | norm: 0.1057 | dt: 178.73ms | tok/sec: 91667.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17489 | loss: 0.010879 | lr 6.9859e-05 | norm: 0.1038 | dt: 181.27ms | tok/sec: 90386.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17490 | loss: 0.012745 | lr 6.9847e-05 | norm: 0.1376 | dt: 180.21ms | tok/sec: 90918.14\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17491 | loss: 0.017015 | lr 6.9834e-05 | norm: 0.1552 | dt: 179.01ms | tok/sec: 91524.93\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17492 | loss: 0.014098 | lr 6.9822e-05 | norm: 0.1432 | dt: 178.13ms | tok/sec: 91978.68\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17493 | loss: 0.015772 | lr 6.9810e-05 | norm: 0.1571 | dt: 183.81ms | tok/sec: 89137.72\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17494 | loss: 0.016490 | lr 6.9797e-05 | norm: 0.1430 | dt: 178.44ms | tok/sec: 91815.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17495 | loss: 0.014784 | lr 6.9785e-05 | norm: 0.1377 | dt: 178.68ms | tok/sec: 91692.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17496 | loss: 0.014742 | lr 6.9773e-05 | norm: 0.1520 | dt: 183.43ms | tok/sec: 89321.24\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17497 | loss: 0.018479 | lr 6.9760e-05 | norm: 0.1704 | dt: 177.96ms | tok/sec: 92063.21\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17498 | loss: 0.015094 | lr 6.9748e-05 | norm: 0.1669 | dt: 179.63ms | tok/sec: 91211.14\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17499 | loss: 0.015063 | lr 6.9736e-05 | norm: 0.1263 | dt: 183.73ms | tok/sec: 89172.42\n",
      "validation loss: 0.1539\n",
      "rank 0 sample 0: Smoking is the major risk factor for most<|endoftext|>. Your risk of oral<|endoftext|> doesn't mean you'll. However, if you smoke, have more risk factors, such as smoking or drinking.      Quitting smoking    Before you stop, your risk for cancer, know your doctor about how\n",
      "rank 0 sample 1: Smoking is the major risk factor for heart disease.\n",
      "                \n",
      "Having a heart attack or injury to the chest or surrounding heart muscle is a problem with the number of risk factors for heart disease. Most heart attacks occur when a blood clot suddenly\n",
      "rank 0 sample 2: Smoking is the major risk factor for heart disease.<|endoftext|> with the high blood pressure may also contribute to high blood pressure. By age 55, the risk of stroke isn't high for a person's risk of developing stroke.<|endoftext|>Q: What are the symptoms of Di<|endoftext|> Heart Disease ? A: Some people who have\n",
      "rank 0 sample 3: Smoking is the major risk factor for most<|endoftext|>. Your risk of getting a disease increases as you get older. You Get tips for advice about risk factors and<|endoftext|> Prevention. To get the videos, click on average, QUaxoma-hand smokeline -- A personal history of<|endoftext|> smoking is available. To reduce the\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17500 | loss: 0.012318 | lr 6.9723e-05 | norm: 0.1347 | dt: 3792.03ms | tok/sec: 4320.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17501 | loss: 0.018842 | lr 6.9711e-05 | norm: 0.2830 | dt: 180.64ms | tok/sec: 90698.31\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17502 | loss: 0.013419 | lr 6.9699e-05 | norm: 0.1316 | dt: 179.19ms | tok/sec: 91435.90\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17503 | loss: 0.013938 | lr 6.9687e-05 | norm: 0.1324 | dt: 179.60ms | tok/sec: 91226.16\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17504 | loss: 0.014069 | lr 6.9674e-05 | norm: 0.1386 | dt: 179.36ms | tok/sec: 91348.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17505 | loss: 0.015929 | lr 6.9662e-05 | norm: 0.1411 | dt: 179.39ms | tok/sec: 91332.97\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17506 | loss: 0.013099 | lr 6.9650e-05 | norm: 0.1539 | dt: 180.75ms | tok/sec: 90645.91\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17507 | loss: 0.018269 | lr 6.9638e-05 | norm: 0.1473 | dt: 178.91ms | tok/sec: 91579.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17508 | loss: 0.016908 | lr 6.9625e-05 | norm: 0.1393 | dt: 179.20ms | tok/sec: 91428.12\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17509 | loss: 0.014786 | lr 6.9613e-05 | norm: 0.1605 | dt: 178.74ms | tok/sec: 91665.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17510 | loss: 0.017713 | lr 6.9601e-05 | norm: 0.1793 | dt: 181.89ms | tok/sec: 90077.12\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17511 | loss: 0.016995 | lr 6.9589e-05 | norm: 0.1629 | dt: 181.17ms | tok/sec: 90435.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17512 | loss: 0.015521 | lr 6.9576e-05 | norm: 0.1578 | dt: 180.20ms | tok/sec: 90923.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17513 | loss: 0.017047 | lr 6.9564e-05 | norm: 0.1469 | dt: 180.42ms | tok/sec: 90809.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17514 | loss: 0.009136 | lr 6.9552e-05 | norm: 0.0975 | dt: 180.10ms | tok/sec: 90972.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17515 | loss: 0.009842 | lr 6.9540e-05 | norm: 0.1103 | dt: 184.19ms | tok/sec: 88949.31\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17516 | loss: 0.011393 | lr 6.9528e-05 | norm: 0.1079 | dt: 180.96ms | tok/sec: 90537.35\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17517 | loss: 0.013003 | lr 6.9516e-05 | norm: 0.1244 | dt: 180.51ms | tok/sec: 90766.11\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17518 | loss: 0.013021 | lr 6.9503e-05 | norm: 0.1391 | dt: 179.68ms | tok/sec: 91185.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17519 | loss: 0.008408 | lr 6.9491e-05 | norm: 0.0947 | dt: 178.85ms | tok/sec: 91605.45\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17520 | loss: 0.009065 | lr 6.9479e-05 | norm: 0.1155 | dt: 178.75ms | tok/sec: 91659.94\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17521 | loss: 0.009518 | lr 6.9467e-05 | norm: 0.1117 | dt: 179.73ms | tok/sec: 91160.93\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17522 | loss: 0.009424 | lr 6.9455e-05 | norm: 0.1116 | dt: 181.01ms | tok/sec: 90513.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17523 | loss: 0.010205 | lr 6.9443e-05 | norm: 0.1559 | dt: 179.93ms | tok/sec: 91056.68\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17524 | loss: 0.013059 | lr 6.9431e-05 | norm: 0.1311 | dt: 179.70ms | tok/sec: 91174.11\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17525 | loss: 0.008228 | lr 6.9419e-05 | norm: 0.0919 | dt: 178.66ms | tok/sec: 91703.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17526 | loss: 0.009304 | lr 6.9406e-05 | norm: 0.1057 | dt: 178.42ms | tok/sec: 91826.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17527 | loss: 0.015441 | lr 6.9394e-05 | norm: 0.1536 | dt: 180.20ms | tok/sec: 90918.98\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17528 | loss: 0.008329 | lr 6.9382e-05 | norm: 0.0935 | dt: 178.09ms | tok/sec: 92000.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17529 | loss: 0.008562 | lr 6.9370e-05 | norm: 0.0952 | dt: 179.50ms | tok/sec: 91273.90\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17530 | loss: 0.009801 | lr 6.9358e-05 | norm: 0.1187 | dt: 179.82ms | tok/sec: 91111.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17531 | loss: 0.010428 | lr 6.9346e-05 | norm: 0.1238 | dt: 178.92ms | tok/sec: 91569.93\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17532 | loss: 0.007839 | lr 6.9334e-05 | norm: 0.0788 | dt: 183.86ms | tok/sec: 89111.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17533 | loss: 0.010128 | lr 6.9322e-05 | norm: 0.1097 | dt: 178.46ms | tok/sec: 91809.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17534 | loss: 0.010701 | lr 6.9310e-05 | norm: 0.1310 | dt: 179.85ms | tok/sec: 91099.05\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17535 | loss: 0.008199 | lr 6.9298e-05 | norm: 0.0937 | dt: 178.23ms | tok/sec: 91925.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17536 | loss: 0.007491 | lr 6.9286e-05 | norm: 0.0721 | dt: 178.58ms | tok/sec: 91748.42\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17537 | loss: 0.014916 | lr 6.9274e-05 | norm: 0.1762 | dt: 179.04ms | tok/sec: 91511.40\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17538 | loss: 0.008936 | lr 6.9262e-05 | norm: 0.0903 | dt: 187.31ms | tok/sec: 87467.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17539 | loss: 0.012916 | lr 6.9250e-05 | norm: 0.1356 | dt: 180.07ms | tok/sec: 90984.71\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17540 | loss: 0.014876 | lr 6.9238e-05 | norm: 0.1737 | dt: 186.90ms | tok/sec: 87664.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17541 | loss: 0.012058 | lr 6.9226e-05 | norm: 0.1253 | dt: 182.35ms | tok/sec: 89849.82\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17542 | loss: 0.018757 | lr 6.9214e-05 | norm: 0.1754 | dt: 181.22ms | tok/sec: 90409.78\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17543 | loss: 0.010401 | lr 6.9202e-05 | norm: 0.0977 | dt: 185.69ms | tok/sec: 88235.04\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17544 | loss: 0.008520 | lr 6.9190e-05 | norm: 0.0923 | dt: 180.36ms | tok/sec: 90842.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17545 | loss: 0.007585 | lr 6.9178e-05 | norm: 0.0964 | dt: 182.86ms | tok/sec: 89597.25\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17546 | loss: 0.007868 | lr 6.9166e-05 | norm: 0.0860 | dt: 181.01ms | tok/sec: 90516.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17547 | loss: 0.013577 | lr 6.9154e-05 | norm: 0.1450 | dt: 186.75ms | tok/sec: 87730.28\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17548 | loss: 0.009195 | lr 6.9142e-05 | norm: 0.1068 | dt: 182.23ms | tok/sec: 89909.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17549 | loss: 0.005344 | lr 6.9130e-05 | norm: 0.0802 | dt: 178.72ms | tok/sec: 91675.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17550 | loss: 0.008752 | lr 6.9118e-05 | norm: 0.1124 | dt: 195.03ms | tok/sec: 84007.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17551 | loss: 0.009830 | lr 6.9107e-05 | norm: 0.1235 | dt: 184.67ms | tok/sec: 88719.06\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17552 | loss: 0.009397 | lr 6.9095e-05 | norm: 0.1010 | dt: 181.49ms | tok/sec: 90275.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17553 | loss: 0.006619 | lr 6.9083e-05 | norm: 0.0835 | dt: 189.44ms | tok/sec: 86486.70\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17554 | loss: 0.006505 | lr 6.9071e-05 | norm: 0.0756 | dt: 185.50ms | tok/sec: 88321.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17555 | loss: 0.007929 | lr 6.9059e-05 | norm: 0.0929 | dt: 179.98ms | tok/sec: 91030.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17556 | loss: 0.009226 | lr 6.9047e-05 | norm: 0.0969 | dt: 182.15ms | tok/sec: 89947.55\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17557 | loss: 0.008023 | lr 6.9035e-05 | norm: 0.1103 | dt: 190.47ms | tok/sec: 86019.77\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17558 | loss: 0.009705 | lr 6.9023e-05 | norm: 0.1115 | dt: 182.07ms | tok/sec: 89988.42\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17559 | loss: 0.009065 | lr 6.9012e-05 | norm: 0.1144 | dt: 181.58ms | tok/sec: 90231.71\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17560 | loss: 0.008761 | lr 6.9000e-05 | norm: 0.0924 | dt: 184.81ms | tok/sec: 88654.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17561 | loss: 0.006747 | lr 6.8988e-05 | norm: 0.0895 | dt: 180.68ms | tok/sec: 90681.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17562 | loss: 0.007362 | lr 6.8976e-05 | norm: 0.0930 | dt: 182.11ms | tok/sec: 89969.80\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17563 | loss: 0.007915 | lr 6.8964e-05 | norm: 0.0947 | dt: 182.38ms | tok/sec: 89833.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17564 | loss: 0.008225 | lr 6.8953e-05 | norm: 0.0866 | dt: 189.89ms | tok/sec: 86279.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17565 | loss: 0.007376 | lr 6.8941e-05 | norm: 0.0935 | dt: 181.41ms | tok/sec: 90316.97\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17566 | loss: 0.006528 | lr 6.8929e-05 | norm: 0.0775 | dt: 180.23ms | tok/sec: 90905.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17567 | loss: 0.007444 | lr 6.8917e-05 | norm: 0.1079 | dt: 186.89ms | tok/sec: 87666.93\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17568 | loss: 0.010236 | lr 6.8905e-05 | norm: 0.1176 | dt: 179.61ms | tok/sec: 91219.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17569 | loss: 0.004844 | lr 6.8894e-05 | norm: 0.0640 | dt: 181.24ms | tok/sec: 90401.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17570 | loss: 0.006348 | lr 6.8882e-05 | norm: 0.0734 | dt: 189.82ms | tok/sec: 86311.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17571 | loss: 0.007016 | lr 6.8870e-05 | norm: 0.0881 | dt: 183.63ms | tok/sec: 89224.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17572 | loss: 0.006113 | lr 6.8858e-05 | norm: 0.1001 | dt: 180.18ms | tok/sec: 90933.78\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17573 | loss: 0.006666 | lr 6.8847e-05 | norm: 0.0715 | dt: 189.75ms | tok/sec: 86346.30\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17574 | loss: 0.009410 | lr 6.8835e-05 | norm: 0.0875 | dt: 183.34ms | tok/sec: 89362.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17575 | loss: 0.005186 | lr 6.8823e-05 | norm: 0.0818 | dt: 182.36ms | tok/sec: 89846.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17576 | loss: 0.005734 | lr 6.8812e-05 | norm: 0.0770 | dt: 182.69ms | tok/sec: 89682.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17577 | loss: 0.006517 | lr 6.8800e-05 | norm: 0.0819 | dt: 184.38ms | tok/sec: 88858.56\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17578 | loss: 0.004727 | lr 6.8788e-05 | norm: 0.0661 | dt: 180.75ms | tok/sec: 90644.23\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17579 | loss: 0.005311 | lr 6.8776e-05 | norm: 0.0759 | dt: 187.37ms | tok/sec: 87441.26\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17580 | loss: 0.004811 | lr 6.8765e-05 | norm: 0.0705 | dt: 188.00ms | tok/sec: 87150.72\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17581 | loss: 0.007797 | lr 6.8753e-05 | norm: 0.0856 | dt: 183.33ms | tok/sec: 89368.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17582 | loss: 0.004963 | lr 6.8741e-05 | norm: 0.0749 | dt: 181.46ms | tok/sec: 90291.70\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17583 | loss: 0.006812 | lr 6.8730e-05 | norm: 0.0840 | dt: 189.74ms | tok/sec: 86349.23\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17584 | loss: 0.006706 | lr 6.8718e-05 | norm: 0.0826 | dt: 179.74ms | tok/sec: 91153.31\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17585 | loss: 0.006008 | lr 6.8706e-05 | norm: 0.0846 | dt: 179.97ms | tok/sec: 91036.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17586 | loss: 0.005908 | lr 6.8695e-05 | norm: 0.0832 | dt: 193.70ms | tok/sec: 84584.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17587 | loss: 0.007051 | lr 6.8683e-05 | norm: 0.0816 | dt: 180.21ms | tok/sec: 90915.49\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17588 | loss: 0.004897 | lr 6.8672e-05 | norm: 0.0667 | dt: 180.78ms | tok/sec: 90629.41\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17589 | loss: 0.003910 | lr 6.8660e-05 | norm: 0.0701 | dt: 179.84ms | tok/sec: 91105.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17590 | loss: 0.005554 | lr 6.8648e-05 | norm: 0.0947 | dt: 180.36ms | tok/sec: 90840.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17591 | loss: 0.004255 | lr 6.8637e-05 | norm: 0.0764 | dt: 180.53ms | tok/sec: 90756.76\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17592 | loss: 0.006366 | lr 6.8625e-05 | norm: 0.0841 | dt: 179.79ms | tok/sec: 91130.82\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17593 | loss: 0.004817 | lr 6.8614e-05 | norm: 0.0833 | dt: 180.14ms | tok/sec: 90953.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17594 | loss: 0.005834 | lr 6.8602e-05 | norm: 0.0714 | dt: 181.35ms | tok/sec: 90345.23\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17595 | loss: 0.006098 | lr 6.8590e-05 | norm: 0.0949 | dt: 179.44ms | tok/sec: 91307.73\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17596 | loss: 0.005839 | lr 6.8579e-05 | norm: 0.0785 | dt: 182.70ms | tok/sec: 89675.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17597 | loss: 0.005313 | lr 6.8567e-05 | norm: 0.0877 | dt: 181.11ms | tok/sec: 90464.29\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17598 | loss: 0.005032 | lr 6.8556e-05 | norm: 0.0758 | dt: 180.30ms | tok/sec: 90869.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17599 | loss: 0.007253 | lr 6.8544e-05 | norm: 0.0950 | dt: 180.11ms | tok/sec: 90966.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17600 | loss: 0.006704 | lr 6.8533e-05 | norm: 0.0859 | dt: 180.36ms | tok/sec: 90839.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17601 | loss: 0.005737 | lr 6.8521e-05 | norm: 0.0991 | dt: 180.76ms | tok/sec: 90640.29\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17602 | loss: 0.006503 | lr 6.8510e-05 | norm: 0.0883 | dt: 180.93ms | tok/sec: 90554.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17603 | loss: 0.005277 | lr 6.8498e-05 | norm: 0.0856 | dt: 178.95ms | tok/sec: 91555.04\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17604 | loss: 0.005752 | lr 6.8487e-05 | norm: 0.0818 | dt: 179.08ms | tok/sec: 91490.68\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17605 | loss: 0.006362 | lr 6.8475e-05 | norm: 0.0820 | dt: 178.90ms | tok/sec: 91580.91\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17606 | loss: 0.007008 | lr 6.8464e-05 | norm: 0.0949 | dt: 178.65ms | tok/sec: 91709.49\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17607 | loss: 0.006299 | lr 6.8452e-05 | norm: 0.0901 | dt: 182.85ms | tok/sec: 89605.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17608 | loss: 0.006924 | lr 6.8441e-05 | norm: 0.0858 | dt: 179.58ms | tok/sec: 91234.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17609 | loss: 0.006356 | lr 6.8429e-05 | norm: 0.0905 | dt: 179.63ms | tok/sec: 91209.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17610 | loss: 0.004739 | lr 6.8418e-05 | norm: 0.0743 | dt: 179.75ms | tok/sec: 91149.80\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17611 | loss: 0.006342 | lr 6.8406e-05 | norm: 0.0807 | dt: 178.92ms | tok/sec: 91570.78\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17612 | loss: 0.005541 | lr 6.8395e-05 | norm: 0.0780 | dt: 180.31ms | tok/sec: 90866.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17613 | loss: 0.004301 | lr 6.8384e-05 | norm: 0.0770 | dt: 180.68ms | tok/sec: 90680.00\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17614 | loss: 0.004995 | lr 6.8372e-05 | norm: 0.0854 | dt: 179.29ms | tok/sec: 91384.35\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17615 | loss: 0.006583 | lr 6.8361e-05 | norm: 0.0789 | dt: 179.37ms | tok/sec: 91341.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17616 | loss: 0.005650 | lr 6.8349e-05 | norm: 0.0832 | dt: 180.09ms | tok/sec: 90975.19\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17617 | loss: 0.005784 | lr 6.8338e-05 | norm: 0.0777 | dt: 179.62ms | tok/sec: 91217.07\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17618 | loss: 0.007663 | lr 6.8327e-05 | norm: 0.0917 | dt: 186.29ms | tok/sec: 87950.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17619 | loss: 0.007708 | lr 6.8315e-05 | norm: 0.0772 | dt: 179.59ms | tok/sec: 91228.46\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17620 | loss: 0.006500 | lr 6.8304e-05 | norm: 0.0934 | dt: 180.26ms | tok/sec: 90889.28\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17621 | loss: 0.004681 | lr 6.8292e-05 | norm: 0.0649 | dt: 180.04ms | tok/sec: 91000.01\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17622 | loss: 0.004826 | lr 6.8281e-05 | norm: 0.0718 | dt: 179.64ms | tok/sec: 91205.94\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17623 | loss: 0.003691 | lr 6.8270e-05 | norm: 0.0592 | dt: 181.79ms | tok/sec: 90124.73\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17624 | loss: 0.006134 | lr 6.8258e-05 | norm: 0.0734 | dt: 180.04ms | tok/sec: 91003.26\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17625 | loss: 0.003832 | lr 6.8247e-05 | norm: 0.0656 | dt: 180.10ms | tok/sec: 90969.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17626 | loss: 0.005829 | lr 6.8236e-05 | norm: 0.0661 | dt: 180.15ms | tok/sec: 90944.01\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17627 | loss: 0.005917 | lr 6.8224e-05 | norm: 0.0652 | dt: 179.13ms | tok/sec: 91465.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17628 | loss: 0.005490 | lr 6.8213e-05 | norm: 0.0785 | dt: 179.56ms | tok/sec: 91246.14\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17629 | loss: 0.004621 | lr 6.8202e-05 | norm: 0.0619 | dt: 179.11ms | tok/sec: 91473.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17630 | loss: 0.007013 | lr 6.8190e-05 | norm: 0.0753 | dt: 179.64ms | tok/sec: 91206.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17631 | loss: 0.006620 | lr 6.8179e-05 | norm: 0.1102 | dt: 179.63ms | tok/sec: 91209.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17632 | loss: 0.005330 | lr 6.8168e-05 | norm: 0.0732 | dt: 180.02ms | tok/sec: 91013.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17633 | loss: 0.007019 | lr 6.8157e-05 | norm: 0.0931 | dt: 178.91ms | tok/sec: 91575.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17634 | loss: 0.005425 | lr 6.8145e-05 | norm: 0.0625 | dt: 182.19ms | tok/sec: 89926.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17635 | loss: 0.003853 | lr 6.8134e-05 | norm: 0.0479 | dt: 180.21ms | tok/sec: 90915.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17636 | loss: 0.008114 | lr 6.8123e-05 | norm: 0.0694 | dt: 182.49ms | tok/sec: 89782.20\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17637 | loss: 0.004628 | lr 6.8112e-05 | norm: 0.0582 | dt: 181.31ms | tok/sec: 90362.46\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17638 | loss: 0.006435 | lr 6.8100e-05 | norm: 0.0629 | dt: 180.18ms | tok/sec: 90931.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17639 | loss: 0.006348 | lr 6.8089e-05 | norm: 0.0802 | dt: 180.14ms | tok/sec: 90953.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17640 | loss: 0.004582 | lr 6.8078e-05 | norm: 0.0694 | dt: 182.29ms | tok/sec: 89876.73\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17641 | loss: 0.003927 | lr 6.8067e-05 | norm: 0.0524 | dt: 180.96ms | tok/sec: 90541.40\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17642 | loss: 0.007654 | lr 6.8055e-05 | norm: 0.0911 | dt: 180.21ms | tok/sec: 90914.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17643 | loss: 0.005924 | lr 6.8044e-05 | norm: 0.0606 | dt: 179.66ms | tok/sec: 91195.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17644 | loss: 0.004803 | lr 6.8033e-05 | norm: 0.0709 | dt: 180.71ms | tok/sec: 90666.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17645 | loss: 0.006041 | lr 6.8022e-05 | norm: 0.0709 | dt: 181.63ms | tok/sec: 90207.78\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17646 | loss: 0.005172 | lr 6.8011e-05 | norm: 0.0681 | dt: 180.71ms | tok/sec: 90662.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17647 | loss: 0.006731 | lr 6.8000e-05 | norm: 0.0896 | dt: 180.34ms | tok/sec: 90849.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17648 | loss: 0.005777 | lr 6.7988e-05 | norm: 0.0745 | dt: 180.56ms | tok/sec: 90740.94\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17649 | loss: 0.007992 | lr 6.7977e-05 | norm: 0.0853 | dt: 180.23ms | tok/sec: 90907.20\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17650 | loss: 0.005052 | lr 6.7966e-05 | norm: 0.0771 | dt: 180.90ms | tok/sec: 90570.16\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17651 | loss: 0.005435 | lr 6.7955e-05 | norm: 0.0640 | dt: 180.03ms | tok/sec: 91007.00\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17652 | loss: 0.004266 | lr 6.7944e-05 | norm: 0.0650 | dt: 179.28ms | tok/sec: 91390.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17653 | loss: 0.006410 | lr 6.7933e-05 | norm: 0.1123 | dt: 179.83ms | tok/sec: 91107.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17654 | loss: 0.007001 | lr 6.7922e-05 | norm: 0.0613 | dt: 180.25ms | tok/sec: 90895.41\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17655 | loss: 0.004149 | lr 6.7910e-05 | norm: 0.0514 | dt: 179.19ms | tok/sec: 91431.40\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17656 | loss: 0.003713 | lr 6.7899e-05 | norm: 0.0454 | dt: 179.06ms | tok/sec: 91502.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17657 | loss: 0.005080 | lr 6.7888e-05 | norm: 0.0649 | dt: 178.97ms | tok/sec: 91547.97\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17658 | loss: 0.005966 | lr 6.7877e-05 | norm: 0.0758 | dt: 179.10ms | tok/sec: 91478.14\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17659 | loss: 0.005629 | lr 6.7866e-05 | norm: 0.0669 | dt: 179.48ms | tok/sec: 91284.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17660 | loss: 0.006135 | lr 6.7855e-05 | norm: 0.0883 | dt: 179.18ms | tok/sec: 91438.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17661 | loss: 0.005587 | lr 6.7844e-05 | norm: 0.0718 | dt: 178.89ms | tok/sec: 91589.33\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17662 | loss: 0.006554 | lr 6.7833e-05 | norm: 0.0907 | dt: 179.85ms | tok/sec: 91096.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17663 | loss: 0.004940 | lr 6.7822e-05 | norm: 0.0673 | dt: 178.83ms | tok/sec: 91618.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17664 | loss: 0.005533 | lr 6.7811e-05 | norm: 0.0857 | dt: 180.60ms | tok/sec: 90722.01\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17665 | loss: 0.006221 | lr 6.7800e-05 | norm: 0.0837 | dt: 179.43ms | tok/sec: 91310.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17666 | loss: 0.018880 | lr 6.7789e-05 | norm: 0.2126 | dt: 184.24ms | tok/sec: 88926.40\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17667 | loss: 0.013405 | lr 6.7778e-05 | norm: 0.2227 | dt: 179.09ms | tok/sec: 91485.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17668 | loss: 0.013838 | lr 6.7767e-05 | norm: 0.1816 | dt: 178.83ms | tok/sec: 91615.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17669 | loss: 0.013028 | lr 6.7756e-05 | norm: 0.1878 | dt: 178.65ms | tok/sec: 91712.42\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17670 | loss: 0.013595 | lr 6.7745e-05 | norm: 0.1774 | dt: 179.61ms | tok/sec: 91217.68\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17671 | loss: 0.012929 | lr 6.7734e-05 | norm: 0.1613 | dt: 178.73ms | tok/sec: 91669.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17672 | loss: 0.012166 | lr 6.7723e-05 | norm: 0.1775 | dt: 179.80ms | tok/sec: 91124.42\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17673 | loss: 0.013723 | lr 6.7712e-05 | norm: 0.2035 | dt: 180.12ms | tok/sec: 90960.98\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17674 | loss: 0.010401 | lr 6.7701e-05 | norm: 0.1298 | dt: 179.64ms | tok/sec: 91205.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17675 | loss: 0.008318 | lr 6.7690e-05 | norm: 0.1021 | dt: 180.07ms | tok/sec: 90986.15\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17676 | loss: 0.012901 | lr 6.7679e-05 | norm: 0.1645 | dt: 179.90ms | tok/sec: 91072.97\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17677 | loss: 0.010734 | lr 6.7668e-05 | norm: 0.1310 | dt: 179.65ms | tok/sec: 91200.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17678 | loss: 0.013405 | lr 6.7657e-05 | norm: 0.1397 | dt: 180.03ms | tok/sec: 91005.07\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17679 | loss: 0.020954 | lr 6.7646e-05 | norm: 0.2050 | dt: 184.61ms | tok/sec: 88748.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17680 | loss: 0.010705 | lr 6.7635e-05 | norm: 0.1633 | dt: 179.48ms | tok/sec: 91284.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17681 | loss: 0.013349 | lr 6.7624e-05 | norm: 0.1753 | dt: 179.42ms | tok/sec: 91317.92\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17682 | loss: 0.010783 | lr 6.7614e-05 | norm: 0.1732 | dt: 178.89ms | tok/sec: 91587.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17683 | loss: 0.013175 | lr 6.7603e-05 | norm: 0.2061 | dt: 180.70ms | tok/sec: 90668.39\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17684 | loss: 0.013822 | lr 6.7592e-05 | norm: 0.1877 | dt: 179.41ms | tok/sec: 91321.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17685 | loss: 0.014877 | lr 6.7581e-05 | norm: 0.1880 | dt: 179.02ms | tok/sec: 91519.68\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17686 | loss: 0.013087 | lr 6.7570e-05 | norm: 0.1661 | dt: 179.29ms | tok/sec: 91382.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17687 | loss: 0.011669 | lr 6.7559e-05 | norm: 0.1755 | dt: 178.79ms | tok/sec: 91639.65\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17688 | loss: 0.010576 | lr 6.7548e-05 | norm: 0.1370 | dt: 179.27ms | tok/sec: 91392.98\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17689 | loss: 0.009675 | lr 6.7537e-05 | norm: 0.1155 | dt: 179.63ms | tok/sec: 91209.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17690 | loss: 0.013905 | lr 6.7527e-05 | norm: 0.1765 | dt: 179.23ms | tok/sec: 91412.55\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17691 | loss: 0.014400 | lr 6.7516e-05 | norm: 0.1893 | dt: 180.14ms | tok/sec: 90951.95\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17692 | loss: 0.011779 | lr 6.7505e-05 | norm: 0.1914 | dt: 180.07ms | tok/sec: 90988.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17693 | loss: 0.015175 | lr 6.7494e-05 | norm: 0.2200 | dt: 180.06ms | tok/sec: 90989.77\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17694 | loss: 0.016833 | lr 6.7483e-05 | norm: 0.2829 | dt: 179.55ms | tok/sec: 91250.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17695 | loss: 0.011544 | lr 6.7473e-05 | norm: 0.1808 | dt: 180.94ms | tok/sec: 90549.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17696 | loss: 0.011675 | lr 6.7462e-05 | norm: 0.2046 | dt: 180.47ms | tok/sec: 90782.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17697 | loss: 0.014602 | lr 6.7451e-05 | norm: 0.1728 | dt: 180.97ms | tok/sec: 90535.92\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17698 | loss: 0.012755 | lr 6.7440e-05 | norm: 0.1979 | dt: 180.54ms | tok/sec: 90749.21\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17699 | loss: 0.019705 | lr 6.7429e-05 | norm: 0.3091 | dt: 180.33ms | tok/sec: 90855.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17700 | loss: 0.016767 | lr 6.7419e-05 | norm: 0.2605 | dt: 179.85ms | tok/sec: 91097.97\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17701 | loss: 0.015207 | lr 6.7408e-05 | norm: 0.1855 | dt: 183.21ms | tok/sec: 89429.11\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17702 | loss: 0.020196 | lr 6.7397e-05 | norm: 0.2724 | dt: 181.24ms | tok/sec: 90400.98\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17703 | loss: 0.024971 | lr 6.7386e-05 | norm: 0.3229 | dt: 180.07ms | tok/sec: 90984.35\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17704 | loss: 0.021974 | lr 6.7376e-05 | norm: 0.2687 | dt: 179.79ms | tok/sec: 91129.62\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17705 | loss: 0.020386 | lr 6.7365e-05 | norm: 0.2988 | dt: 180.41ms | tok/sec: 90815.41\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17706 | loss: 0.019932 | lr 6.7354e-05 | norm: 0.2290 | dt: 182.80ms | tok/sec: 89627.05\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17707 | loss: 0.018049 | lr 6.7344e-05 | norm: 0.2511 | dt: 180.43ms | tok/sec: 90806.05\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17708 | loss: 0.012241 | lr 6.7333e-05 | norm: 0.1463 | dt: 179.84ms | tok/sec: 91103.76\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17709 | loss: 0.014149 | lr 6.7322e-05 | norm: 0.1732 | dt: 180.30ms | tok/sec: 90872.82\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17710 | loss: 0.011869 | lr 6.7311e-05 | norm: 0.1528 | dt: 185.56ms | tok/sec: 88295.80\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17711 | loss: 0.014413 | lr 6.7301e-05 | norm: 0.1605 | dt: 180.98ms | tok/sec: 90529.24\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17712 | loss: 0.017857 | lr 6.7290e-05 | norm: 0.2034 | dt: 180.95ms | tok/sec: 90542.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17713 | loss: 0.017723 | lr 6.7279e-05 | norm: 0.1955 | dt: 180.38ms | tok/sec: 90830.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17714 | loss: 0.044033 | lr 6.7269e-05 | norm: 0.4032 | dt: 180.36ms | tok/sec: 90841.46\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17715 | loss: 0.069410 | lr 6.7258e-05 | norm: 0.4481 | dt: 179.57ms | tok/sec: 91239.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17716 | loss: 0.053612 | lr 6.7248e-05 | norm: 0.3859 | dt: 180.02ms | tok/sec: 91009.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17717 | loss: 0.055177 | lr 6.7237e-05 | norm: 0.3878 | dt: 179.94ms | tok/sec: 91053.30\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17718 | loss: 0.032410 | lr 6.7226e-05 | norm: 0.3455 | dt: 180.62ms | tok/sec: 90708.12\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17719 | loss: 0.046601 | lr 6.7216e-05 | norm: 0.3940 | dt: 178.92ms | tok/sec: 91570.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17720 | loss: 0.021898 | lr 6.7205e-05 | norm: 0.2198 | dt: 179.31ms | tok/sec: 91374.51\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17721 | loss: 0.018776 | lr 6.7194e-05 | norm: 0.2058 | dt: 179.58ms | tok/sec: 91232.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17722 | loss: 0.014274 | lr 6.7184e-05 | norm: 0.1807 | dt: 179.62ms | tok/sec: 91215.01\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17723 | loss: 0.012472 | lr 6.7173e-05 | norm: 0.1542 | dt: 180.17ms | tok/sec: 90937.15\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17724 | loss: 0.011954 | lr 6.7163e-05 | norm: 0.1383 | dt: 180.23ms | tok/sec: 90904.31\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17725 | loss: 0.011010 | lr 6.7152e-05 | norm: 0.1271 | dt: 179.74ms | tok/sec: 91152.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17726 | loss: 0.008797 | lr 6.7142e-05 | norm: 0.0990 | dt: 181.51ms | tok/sec: 90267.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17727 | loss: 0.011050 | lr 6.7131e-05 | norm: 0.1395 | dt: 180.99ms | tok/sec: 90521.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17728 | loss: 0.012511 | lr 6.7120e-05 | norm: 0.1632 | dt: 179.72ms | tok/sec: 91162.98\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17729 | loss: 0.012795 | lr 6.7110e-05 | norm: 0.1706 | dt: 180.06ms | tok/sec: 90992.90\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17730 | loss: 0.012478 | lr 6.7099e-05 | norm: 0.1832 | dt: 179.42ms | tok/sec: 91317.56\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17731 | loss: 0.010994 | lr 6.7089e-05 | norm: 0.1666 | dt: 178.73ms | tok/sec: 91666.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17732 | loss: 0.013741 | lr 6.7078e-05 | norm: 0.1776 | dt: 179.31ms | tok/sec: 91374.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17733 | loss: 0.011396 | lr 6.7068e-05 | norm: 0.1276 | dt: 179.11ms | tok/sec: 91473.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17734 | loss: 0.010048 | lr 6.7057e-05 | norm: 0.1476 | dt: 179.18ms | tok/sec: 91436.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17735 | loss: 0.014516 | lr 6.7047e-05 | norm: 0.1602 | dt: 178.81ms | tok/sec: 91629.76\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17736 | loss: 0.006448 | lr 6.7036e-05 | norm: 0.0826 | dt: 178.55ms | tok/sec: 91762.14\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17737 | loss: 0.008059 | lr 6.7026e-05 | norm: 0.0888 | dt: 181.55ms | tok/sec: 90245.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17738 | loss: 0.010184 | lr 6.7015e-05 | norm: 0.1095 | dt: 179.34ms | tok/sec: 91355.56\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17739 | loss: 0.009455 | lr 6.7005e-05 | norm: 0.1311 | dt: 179.13ms | tok/sec: 91465.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17740 | loss: 0.014397 | lr 6.6995e-05 | norm: 0.1254 | dt: 188.18ms | tok/sec: 87064.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17741 | loss: 0.014965 | lr 6.6984e-05 | norm: 0.1350 | dt: 178.98ms | tok/sec: 91539.43\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17742 | loss: 0.010528 | lr 6.6974e-05 | norm: 0.1327 | dt: 180.64ms | tok/sec: 90698.07\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17743 | loss: 0.009336 | lr 6.6963e-05 | norm: 0.1051 | dt: 179.33ms | tok/sec: 91364.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17744 | loss: 0.008773 | lr 6.6953e-05 | norm: 0.1021 | dt: 178.49ms | tok/sec: 91792.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17745 | loss: 0.009105 | lr 6.6942e-05 | norm: 0.1132 | dt: 178.62ms | tok/sec: 91723.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17746 | loss: 0.010970 | lr 6.6932e-05 | norm: 0.1138 | dt: 178.31ms | tok/sec: 91887.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17747 | loss: 0.011905 | lr 6.6922e-05 | norm: 0.1519 | dt: 178.68ms | tok/sec: 91695.78\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17748 | loss: 0.008412 | lr 6.6911e-05 | norm: 0.0978 | dt: 178.64ms | tok/sec: 91716.58\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17749 | loss: 0.010124 | lr 6.6901e-05 | norm: 0.1376 | dt: 179.50ms | tok/sec: 91276.80\n",
      "validation loss: 0.1553\n",
      "rank 0 sample 0: Smoking is the major risk factor for heart disease, so this treatment is directed at replacing the<|endoftext|>.<|endoftext|>Q: What are the stages of Thymic Carcin<|endoftext|> ? A: Key Points\n",
      "                 - There is no standard<|endoftext|> system\n",
      "rank 0 sample 1: Smoking is the major risk factor for stroke. One study found that depressed blood pressure medications defectsazole carotene<|endoftext|> foods, would be of their<|endoftext|> fluid.<|endoftext|>, the more risk of stroke and stroke, especially among cigarette smoking and Southeast Asia, use of alcohol, but no firm evidence of using<|endoftext|>ous\n",
      "rank 0 sample 2: Smoking is the major risk factor for stroke. Animal polygluc<|endoftext|> During<|endoftext|> including<|endoftext|>T and Servicesoccipital heart disease, the process begins to produce a<|endoftext|> called ischemic stroke, in which blood moves from the heart to the body's organs. heart disease which reduce the risk of stroke are abnormal\n",
      "rank 0 sample 3: Smoking is the major risk factor for heart valve disease.<|endoftext|> at dental treatment time is the best level of oxygen and for any other people who have had a heart attack.<|endoftext|>Q: What are the symptoms of Hypoplastic left heart syndrome ? A: What are the signs and symptoms of Hypoplastic left heart\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17750 | loss: 0.012100 | lr 6.6890e-05 | norm: 0.1458 | dt: 3718.00ms | tok/sec: 4406.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17751 | loss: 0.011290 | lr 6.6880e-05 | norm: 0.1405 | dt: 194.93ms | tok/sec: 84050.14\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17752 | loss: 0.010770 | lr 6.6870e-05 | norm: 0.1266 | dt: 181.20ms | tok/sec: 90421.43\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17753 | loss: 0.009898 | lr 6.6859e-05 | norm: 0.1177 | dt: 180.65ms | tok/sec: 90695.31\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17754 | loss: 0.010030 | lr 6.6849e-05 | norm: 0.1239 | dt: 188.59ms | tok/sec: 86876.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17755 | loss: 0.006892 | lr 6.6839e-05 | norm: 0.0934 | dt: 182.98ms | tok/sec: 89537.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17756 | loss: 0.007319 | lr 6.6828e-05 | norm: 0.0906 | dt: 189.11ms | tok/sec: 86638.70\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17757 | loss: 0.008848 | lr 6.6818e-05 | norm: 0.1077 | dt: 180.07ms | tok/sec: 90985.31\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17758 | loss: 0.008955 | lr 6.6808e-05 | norm: 0.1181 | dt: 178.79ms | tok/sec: 91640.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17759 | loss: 0.006615 | lr 6.6797e-05 | norm: 0.0938 | dt: 180.76ms | tok/sec: 90639.45\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17760 | loss: 0.005261 | lr 6.6787e-05 | norm: 0.0832 | dt: 179.95ms | tok/sec: 91047.51\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17761 | loss: 0.005312 | lr 6.6777e-05 | norm: 0.0898 | dt: 179.03ms | tok/sec: 91514.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17762 | loss: 0.005266 | lr 6.6767e-05 | norm: 0.0819 | dt: 179.16ms | tok/sec: 91449.65\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17763 | loss: 0.006097 | lr 6.6756e-05 | norm: 0.0931 | dt: 179.52ms | tok/sec: 91267.71\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17764 | loss: 0.006125 | lr 6.6746e-05 | norm: 0.0818 | dt: 178.99ms | tok/sec: 91537.00\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17765 | loss: 0.007564 | lr 6.6736e-05 | norm: 0.0914 | dt: 179.55ms | tok/sec: 91251.72\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17766 | loss: 0.006397 | lr 6.6725e-05 | norm: 0.0952 | dt: 179.59ms | tok/sec: 91229.30\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17767 | loss: 0.004476 | lr 6.6715e-05 | norm: 0.0726 | dt: 183.83ms | tok/sec: 89123.73\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17768 | loss: 0.007544 | lr 6.6705e-05 | norm: 0.1062 | dt: 179.57ms | tok/sec: 91238.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17769 | loss: 0.003428 | lr 6.6695e-05 | norm: 0.0674 | dt: 179.39ms | tok/sec: 91329.33\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17770 | loss: 0.005922 | lr 6.6685e-05 | norm: 0.0756 | dt: 179.36ms | tok/sec: 91348.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17771 | loss: 0.006601 | lr 6.6674e-05 | norm: 0.0812 | dt: 179.00ms | tok/sec: 91529.07\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17772 | loss: 0.004188 | lr 6.6664e-05 | norm: 0.0583 | dt: 179.24ms | tok/sec: 91407.20\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17773 | loss: 0.004522 | lr 6.6654e-05 | norm: 0.0633 | dt: 180.40ms | tok/sec: 90820.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17774 | loss: 0.005536 | lr 6.6644e-05 | norm: 0.0783 | dt: 179.00ms | tok/sec: 91530.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17775 | loss: 0.006111 | lr 6.6634e-05 | norm: 0.0809 | dt: 179.02ms | tok/sec: 91519.07\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17776 | loss: 0.005582 | lr 6.6623e-05 | norm: 0.0770 | dt: 179.05ms | tok/sec: 91503.11\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17777 | loss: 0.006231 | lr 6.6613e-05 | norm: 0.1029 | dt: 179.16ms | tok/sec: 91449.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17778 | loss: 0.005460 | lr 6.6603e-05 | norm: 0.0936 | dt: 183.21ms | tok/sec: 89426.20\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17779 | loss: 0.005171 | lr 6.6593e-05 | norm: 0.0779 | dt: 179.68ms | tok/sec: 91182.46\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17780 | loss: 0.006286 | lr 6.6583e-05 | norm: 0.0880 | dt: 179.09ms | tok/sec: 91482.28\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17781 | loss: 0.006273 | lr 6.6573e-05 | norm: 0.0786 | dt: 178.96ms | tok/sec: 91551.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17782 | loss: 0.005470 | lr 6.6562e-05 | norm: 0.0735 | dt: 179.53ms | tok/sec: 91262.99\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17783 | loss: 0.005465 | lr 6.6552e-05 | norm: 0.0895 | dt: 179.01ms | tok/sec: 91525.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17784 | loss: 0.004791 | lr 6.6542e-05 | norm: 0.0767 | dt: 179.89ms | tok/sec: 91075.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17785 | loss: 0.006530 | lr 6.6532e-05 | norm: 0.0891 | dt: 179.98ms | tok/sec: 91033.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17786 | loss: 0.006008 | lr 6.6522e-05 | norm: 0.0822 | dt: 179.53ms | tok/sec: 91260.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17787 | loss: 0.008335 | lr 6.6512e-05 | norm: 0.0967 | dt: 179.51ms | tok/sec: 91270.74\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17788 | loss: 0.003746 | lr 6.6502e-05 | norm: 0.0706 | dt: 179.65ms | tok/sec: 91198.43\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17789 | loss: 0.005504 | lr 6.6492e-05 | norm: 0.0834 | dt: 180.24ms | tok/sec: 90899.62\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17790 | loss: 0.006011 | lr 6.6482e-05 | norm: 0.0713 | dt: 186.61ms | tok/sec: 87798.65\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17791 | loss: 0.005944 | lr 6.6472e-05 | norm: 0.0754 | dt: 179.36ms | tok/sec: 91346.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17792 | loss: 0.004980 | lr 6.6462e-05 | norm: 0.0774 | dt: 215.09ms | tok/sec: 76171.99\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17793 | loss: 0.005891 | lr 6.6452e-05 | norm: 0.0702 | dt: 180.68ms | tok/sec: 90678.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17794 | loss: 0.004740 | lr 6.6442e-05 | norm: 0.0768 | dt: 183.75ms | tok/sec: 89165.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17795 | loss: 0.004701 | lr 6.6432e-05 | norm: 0.0787 | dt: 179.64ms | tok/sec: 91202.91\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17796 | loss: 0.005436 | lr 6.6421e-05 | norm: 0.0885 | dt: 184.23ms | tok/sec: 88932.27\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17797 | loss: 0.004737 | lr 6.6411e-05 | norm: 0.0589 | dt: 179.78ms | tok/sec: 91134.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17798 | loss: 0.007166 | lr 6.6401e-05 | norm: 0.0813 | dt: 182.60ms | tok/sec: 89724.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17799 | loss: 0.006086 | lr 6.6391e-05 | norm: 0.0696 | dt: 180.02ms | tok/sec: 91011.22\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17800 | loss: 0.006088 | lr 6.6381e-05 | norm: 0.0718 | dt: 181.17ms | tok/sec: 90435.71\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17801 | loss: 0.003740 | lr 6.6371e-05 | norm: 0.0846 | dt: 185.73ms | tok/sec: 88213.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17802 | loss: 0.005934 | lr 6.6362e-05 | norm: 0.0774 | dt: 181.52ms | tok/sec: 90260.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17803 | loss: 0.004268 | lr 6.6352e-05 | norm: 0.0709 | dt: 179.16ms | tok/sec: 91450.99\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17804 | loss: 0.005803 | lr 6.6342e-05 | norm: 0.0753 | dt: 180.10ms | tok/sec: 90972.90\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17805 | loss: 0.006000 | lr 6.6332e-05 | norm: 0.0928 | dt: 179.51ms | tok/sec: 91270.62\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17806 | loss: 0.003391 | lr 6.6322e-05 | norm: 0.0504 | dt: 180.61ms | tok/sec: 90714.23\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17807 | loss: 0.005291 | lr 6.6312e-05 | norm: 0.0760 | dt: 179.21ms | tok/sec: 91421.19\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17808 | loss: 0.003777 | lr 6.6302e-05 | norm: 0.0595 | dt: 181.73ms | tok/sec: 90155.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17809 | loss: 0.005725 | lr 6.6292e-05 | norm: 0.0743 | dt: 184.95ms | tok/sec: 88585.82\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17810 | loss: 0.003851 | lr 6.6282e-05 | norm: 0.0610 | dt: 180.49ms | tok/sec: 90777.26\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17811 | loss: 0.005338 | lr 6.6272e-05 | norm: 0.0766 | dt: 185.86ms | tok/sec: 88152.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17812 | loss: 0.004925 | lr 6.6262e-05 | norm: 0.0627 | dt: 183.51ms | tok/sec: 89280.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17813 | loss: 0.006924 | lr 6.6252e-05 | norm: 0.0717 | dt: 181.22ms | tok/sec: 90408.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17814 | loss: 0.004535 | lr 6.6242e-05 | norm: 0.0541 | dt: 179.64ms | tok/sec: 91203.39\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17815 | loss: 0.004808 | lr 6.6233e-05 | norm: 0.0663 | dt: 178.72ms | tok/sec: 91675.72\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17816 | loss: 0.005741 | lr 6.6223e-05 | norm: 0.0758 | dt: 182.46ms | tok/sec: 89793.82\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17817 | loss: 0.005702 | lr 6.6213e-05 | norm: 0.0742 | dt: 180.84ms | tok/sec: 90598.70\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17818 | loss: 0.005658 | lr 6.6203e-05 | norm: 0.0725 | dt: 181.94ms | tok/sec: 90050.68\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17819 | loss: 0.006985 | lr 6.6193e-05 | norm: 0.0870 | dt: 180.35ms | tok/sec: 90846.99\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17820 | loss: 0.006143 | lr 6.6183e-05 | norm: 0.0766 | dt: 179.10ms | tok/sec: 91481.79\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17821 | loss: 0.005974 | lr 6.6173e-05 | norm: 0.0677 | dt: 184.76ms | tok/sec: 88679.45\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17822 | loss: 0.004133 | lr 6.6164e-05 | norm: 0.0559 | dt: 178.66ms | tok/sec: 91703.00\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17823 | loss: 0.006708 | lr 6.6154e-05 | norm: 0.0868 | dt: 180.76ms | tok/sec: 90639.93\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17824 | loss: 0.018839 | lr 6.6144e-05 | norm: 0.3770 | dt: 179.36ms | tok/sec: 91349.24\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17825 | loss: 0.014279 | lr 6.6134e-05 | norm: 0.2514 | dt: 179.07ms | tok/sec: 91494.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17826 | loss: 0.010253 | lr 6.6124e-05 | norm: 0.2174 | dt: 180.16ms | tok/sec: 90942.33\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17827 | loss: 0.008465 | lr 6.6115e-05 | norm: 0.1122 | dt: 179.41ms | tok/sec: 91323.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17828 | loss: 0.008383 | lr 6.6105e-05 | norm: 0.0989 | dt: 184.64ms | tok/sec: 88733.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17829 | loss: 0.008641 | lr 6.6095e-05 | norm: 0.1050 | dt: 179.10ms | tok/sec: 91479.72\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17830 | loss: 0.008575 | lr 6.6085e-05 | norm: 0.1625 | dt: 184.43ms | tok/sec: 88834.90\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17831 | loss: 0.010670 | lr 6.6076e-05 | norm: 0.1851 | dt: 179.66ms | tok/sec: 91194.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17832 | loss: 0.010988 | lr 6.6066e-05 | norm: 0.2154 | dt: 185.08ms | tok/sec: 88521.80\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17833 | loss: 0.012844 | lr 6.6056e-05 | norm: 0.2494 | dt: 180.14ms | tok/sec: 90953.76\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17834 | loss: 0.012824 | lr 6.6046e-05 | norm: 0.2461 | dt: 180.66ms | tok/sec: 90687.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17835 | loss: 0.012525 | lr 6.6037e-05 | norm: 0.2584 | dt: 180.12ms | tok/sec: 90959.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17836 | loss: 0.009540 | lr 6.6027e-05 | norm: 0.1489 | dt: 180.96ms | tok/sec: 90540.93\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17837 | loss: 0.012170 | lr 6.6017e-05 | norm: 0.1234 | dt: 181.48ms | tok/sec: 90280.55\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17838 | loss: 0.010601 | lr 6.6008e-05 | norm: 0.1293 | dt: 180.60ms | tok/sec: 90718.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17839 | loss: 0.015457 | lr 6.5998e-05 | norm: 0.1817 | dt: 180.32ms | tok/sec: 90861.16\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17840 | loss: 0.008952 | lr 6.5988e-05 | norm: 0.1113 | dt: 182.45ms | tok/sec: 89801.21\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17841 | loss: 0.004772 | lr 6.5979e-05 | norm: 0.0829 | dt: 179.90ms | tok/sec: 91074.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17842 | loss: 0.006257 | lr 6.5969e-05 | norm: 0.0773 | dt: 181.36ms | tok/sec: 90338.35\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17843 | loss: 0.009576 | lr 6.5959e-05 | norm: 0.1103 | dt: 181.21ms | tok/sec: 90416.68\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17844 | loss: 0.006839 | lr 6.5950e-05 | norm: 0.0828 | dt: 181.16ms | tok/sec: 90437.26\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17845 | loss: 0.008647 | lr 6.5940e-05 | norm: 0.0959 | dt: 180.29ms | tok/sec: 90875.94\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17846 | loss: 0.008058 | lr 6.5930e-05 | norm: 0.0903 | dt: 180.16ms | tok/sec: 90938.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17847 | loss: 0.006570 | lr 6.5921e-05 | norm: 0.0758 | dt: 183.83ms | tok/sec: 89127.78\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17848 | loss: 0.012051 | lr 6.5911e-05 | norm: 0.1282 | dt: 182.00ms | tok/sec: 90022.25\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17849 | loss: 0.010371 | lr 6.5901e-05 | norm: 0.1158 | dt: 180.38ms | tok/sec: 90828.61\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17850 | loss: 0.008469 | lr 6.5892e-05 | norm: 0.1053 | dt: 180.26ms | tok/sec: 90890.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17851 | loss: 0.009107 | lr 6.5882e-05 | norm: 0.1251 | dt: 180.51ms | tok/sec: 90766.35\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17852 | loss: 0.006783 | lr 6.5873e-05 | norm: 0.0947 | dt: 180.34ms | tok/sec: 90848.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17853 | loss: 0.009009 | lr 6.5863e-05 | norm: 0.1047 | dt: 182.89ms | tok/sec: 89582.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17854 | loss: 0.007573 | lr 6.5853e-05 | norm: 0.0915 | dt: 181.51ms | tok/sec: 90263.95\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17855 | loss: 0.005766 | lr 6.5844e-05 | norm: 0.0718 | dt: 181.79ms | tok/sec: 90127.21\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17856 | loss: 0.007495 | lr 6.5834e-05 | norm: 0.1037 | dt: 180.54ms | tok/sec: 90748.49\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17857 | loss: 0.005118 | lr 6.5825e-05 | norm: 0.0772 | dt: 179.78ms | tok/sec: 91132.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17858 | loss: 0.007215 | lr 6.5815e-05 | norm: 0.0953 | dt: 179.49ms | tok/sec: 91280.93\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17859 | loss: 0.018959 | lr 6.5806e-05 | norm: 0.1555 | dt: 181.30ms | tok/sec: 90369.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17860 | loss: 0.008636 | lr 6.5796e-05 | norm: 0.1091 | dt: 180.27ms | tok/sec: 90885.07\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17861 | loss: 0.017236 | lr 6.5787e-05 | norm: 0.1738 | dt: 180.53ms | tok/sec: 90755.92\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17862 | loss: 0.007845 | lr 6.5777e-05 | norm: 0.0836 | dt: 184.95ms | tok/sec: 88583.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17863 | loss: 0.007035 | lr 6.5768e-05 | norm: 0.0730 | dt: 181.72ms | tok/sec: 90162.93\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17864 | loss: 0.008689 | lr 6.5758e-05 | norm: 0.0975 | dt: 181.68ms | tok/sec: 90180.56\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17865 | loss: 0.005799 | lr 6.5749e-05 | norm: 0.0776 | dt: 183.32ms | tok/sec: 89371.43\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17866 | loss: 0.011383 | lr 6.5739e-05 | norm: 0.1900 | dt: 179.73ms | tok/sec: 91158.15\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17867 | loss: 0.013895 | lr 6.5730e-05 | norm: 0.2064 | dt: 183.06ms | tok/sec: 89498.30\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17868 | loss: 0.005907 | lr 6.5720e-05 | norm: 0.0851 | dt: 180.00ms | tok/sec: 91020.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17869 | loss: 0.016763 | lr 6.5711e-05 | norm: 0.2310 | dt: 179.06ms | tok/sec: 91497.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17870 | loss: 0.022822 | lr 6.5701e-05 | norm: 0.3228 | dt: 179.49ms | tok/sec: 91282.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17871 | loss: 0.019204 | lr 6.5692e-05 | norm: 0.2728 | dt: 179.08ms | tok/sec: 91491.42\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17872 | loss: 0.013749 | lr 6.5683e-05 | norm: 0.1873 | dt: 179.25ms | tok/sec: 91401.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17873 | loss: 0.012715 | lr 6.5673e-05 | norm: 0.1600 | dt: 180.94ms | tok/sec: 90549.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17874 | loss: 0.009966 | lr 6.5664e-05 | norm: 0.1354 | dt: 179.28ms | tok/sec: 91388.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17875 | loss: 0.010671 | lr 6.5654e-05 | norm: 0.1173 | dt: 181.61ms | tok/sec: 90213.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17876 | loss: 0.010253 | lr 6.5645e-05 | norm: 0.1448 | dt: 180.20ms | tok/sec: 90920.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17877 | loss: 0.012611 | lr 6.5635e-05 | norm: 0.2244 | dt: 179.86ms | tok/sec: 91092.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17878 | loss: 0.013694 | lr 6.5626e-05 | norm: 0.2600 | dt: 181.78ms | tok/sec: 90128.99\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17879 | loss: 0.012427 | lr 6.5617e-05 | norm: 0.1934 | dt: 178.89ms | tok/sec: 91587.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17880 | loss: 0.009782 | lr 6.5607e-05 | norm: 0.1749 | dt: 178.64ms | tok/sec: 91716.46\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17881 | loss: 0.010255 | lr 6.5598e-05 | norm: 0.1665 | dt: 180.10ms | tok/sec: 90972.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17882 | loss: 0.008725 | lr 6.5589e-05 | norm: 0.1223 | dt: 180.48ms | tok/sec: 90779.06\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17883 | loss: 0.004680 | lr 6.5579e-05 | norm: 0.0804 | dt: 183.32ms | tok/sec: 89374.68\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17884 | loss: 0.003287 | lr 6.5570e-05 | norm: 0.0831 | dt: 184.13ms | tok/sec: 88980.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17885 | loss: 0.006054 | lr 6.5561e-05 | norm: 0.0749 | dt: 179.16ms | tok/sec: 91447.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17886 | loss: 0.004295 | lr 6.5551e-05 | norm: 0.0819 | dt: 180.11ms | tok/sec: 90965.92\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17887 | loss: 0.004223 | lr 6.5542e-05 | norm: 0.0842 | dt: 178.61ms | tok/sec: 91729.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17888 | loss: 0.006183 | lr 6.5533e-05 | norm: 0.0921 | dt: 179.00ms | tok/sec: 91532.00\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17889 | loss: 0.005055 | lr 6.5523e-05 | norm: 0.0798 | dt: 179.41ms | tok/sec: 91323.51\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17890 | loss: 0.006630 | lr 6.5514e-05 | norm: 0.1095 | dt: 179.48ms | tok/sec: 91285.29\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17891 | loss: 0.007362 | lr 6.5505e-05 | norm: 0.1000 | dt: 186.80ms | tok/sec: 87709.56\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17892 | loss: 0.009000 | lr 6.5495e-05 | norm: 0.1803 | dt: 180.02ms | tok/sec: 91013.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17893 | loss: 0.008169 | lr 6.5486e-05 | norm: 0.1089 | dt: 177.97ms | tok/sec: 92061.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17894 | loss: 0.006793 | lr 6.5477e-05 | norm: 0.0820 | dt: 178.89ms | tok/sec: 91585.55\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17895 | loss: 0.008396 | lr 6.5468e-05 | norm: 0.1173 | dt: 178.51ms | tok/sec: 91781.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17896 | loss: 0.008383 | lr 6.5458e-05 | norm: 0.1428 | dt: 178.12ms | tok/sec: 91982.12\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17897 | loss: 0.007034 | lr 6.5449e-05 | norm: 0.1140 | dt: 181.84ms | tok/sec: 90102.04\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17898 | loss: 0.006278 | lr 6.5440e-05 | norm: 0.0749 | dt: 179.59ms | tok/sec: 91227.49\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17899 | loss: 0.005519 | lr 6.5431e-05 | norm: 0.0892 | dt: 178.71ms | tok/sec: 91678.16\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17900 | loss: 0.006976 | lr 6.5422e-05 | norm: 0.0723 | dt: 178.88ms | tok/sec: 91590.55\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17901 | loss: 0.006948 | lr 6.5412e-05 | norm: 0.0879 | dt: 178.58ms | tok/sec: 91744.26\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17902 | loss: 0.004868 | lr 6.5403e-05 | norm: 0.0602 | dt: 180.60ms | tok/sec: 90719.26\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17903 | loss: 0.004439 | lr 6.5394e-05 | norm: 0.0667 | dt: 178.62ms | tok/sec: 91725.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17904 | loss: 0.005438 | lr 6.5385e-05 | norm: 0.0855 | dt: 178.72ms | tok/sec: 91675.11\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17905 | loss: 0.004427 | lr 6.5376e-05 | norm: 0.0730 | dt: 178.14ms | tok/sec: 91970.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17906 | loss: 0.004081 | lr 6.5366e-05 | norm: 0.0605 | dt: 178.57ms | tok/sec: 91753.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17907 | loss: 0.006445 | lr 6.5357e-05 | norm: 0.1023 | dt: 178.20ms | tok/sec: 91941.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17908 | loss: 0.004236 | lr 6.5348e-05 | norm: 0.0627 | dt: 180.27ms | tok/sec: 90886.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17909 | loss: 0.005282 | lr 6.5339e-05 | norm: 0.0848 | dt: 180.39ms | tok/sec: 90824.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17910 | loss: 0.003530 | lr 6.5330e-05 | norm: 0.0676 | dt: 179.23ms | tok/sec: 91412.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17911 | loss: 0.004132 | lr 6.5321e-05 | norm: 0.0662 | dt: 180.88ms | tok/sec: 90579.95\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17912 | loss: 0.004613 | lr 6.5312e-05 | norm: 0.0717 | dt: 181.02ms | tok/sec: 90508.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17913 | loss: 0.004761 | lr 6.5302e-05 | norm: 0.0912 | dt: 180.22ms | tok/sec: 90912.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17914 | loss: 0.004984 | lr 6.5293e-05 | norm: 0.0867 | dt: 180.12ms | tok/sec: 90959.78\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17915 | loss: 0.005567 | lr 6.5284e-05 | norm: 0.1074 | dt: 180.19ms | tok/sec: 90927.04\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17916 | loss: 0.004771 | lr 6.5275e-05 | norm: 0.0779 | dt: 180.78ms | tok/sec: 90627.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17917 | loss: 0.004749 | lr 6.5266e-05 | norm: 0.0749 | dt: 179.84ms | tok/sec: 91104.12\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17918 | loss: 0.005587 | lr 6.5257e-05 | norm: 0.0815 | dt: 180.26ms | tok/sec: 90892.05\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17919 | loss: 0.005755 | lr 6.5248e-05 | norm: 0.0836 | dt: 179.84ms | tok/sec: 91105.21\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17920 | loss: 0.006111 | lr 6.5239e-05 | norm: 0.0810 | dt: 182.91ms | tok/sec: 89575.29\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17921 | loss: 0.006212 | lr 6.5230e-05 | norm: 0.0949 | dt: 184.08ms | tok/sec: 89005.30\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17922 | loss: 0.006359 | lr 6.5221e-05 | norm: 0.0904 | dt: 183.84ms | tok/sec: 89123.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17923 | loss: 0.006043 | lr 6.5212e-05 | norm: 0.0911 | dt: 179.10ms | tok/sec: 91478.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17924 | loss: 0.005523 | lr 6.5203e-05 | norm: 0.0907 | dt: 179.32ms | tok/sec: 91365.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17925 | loss: 0.005615 | lr 6.5194e-05 | norm: 0.0776 | dt: 178.91ms | tok/sec: 91575.42\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17926 | loss: 0.005449 | lr 6.5185e-05 | norm: 0.0780 | dt: 179.59ms | tok/sec: 91232.33\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17927 | loss: 0.005342 | lr 6.5176e-05 | norm: 0.0860 | dt: 179.74ms | tok/sec: 91154.76\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17928 | loss: 0.006734 | lr 6.5167e-05 | norm: 0.0929 | dt: 178.87ms | tok/sec: 91598.98\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17929 | loss: 0.005369 | lr 6.5158e-05 | norm: 0.0807 | dt: 180.29ms | tok/sec: 90874.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17930 | loss: 0.005227 | lr 6.5149e-05 | norm: 0.0693 | dt: 179.14ms | tok/sec: 91461.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17931 | loss: 0.004718 | lr 6.5140e-05 | norm: 0.0789 | dt: 178.84ms | tok/sec: 91611.68\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17932 | loss: 0.006328 | lr 6.5131e-05 | norm: 0.0860 | dt: 179.22ms | tok/sec: 91416.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17933 | loss: 0.004756 | lr 6.5122e-05 | norm: 0.0753 | dt: 180.78ms | tok/sec: 90631.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17934 | loss: 0.006999 | lr 6.5113e-05 | norm: 0.0887 | dt: 179.48ms | tok/sec: 91288.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17935 | loss: 0.005294 | lr 6.5104e-05 | norm: 0.0738 | dt: 179.47ms | tok/sec: 91290.99\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17936 | loss: 0.004429 | lr 6.5095e-05 | norm: 0.0648 | dt: 179.27ms | tok/sec: 91394.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17937 | loss: 0.004296 | lr 6.5086e-05 | norm: 0.0729 | dt: 179.89ms | tok/sec: 91080.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17938 | loss: 0.005895 | lr 6.5077e-05 | norm: 0.0888 | dt: 180.75ms | tok/sec: 90646.62\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17939 | loss: 0.007682 | lr 6.5068e-05 | norm: 0.1018 | dt: 181.12ms | tok/sec: 90461.07\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17940 | loss: 0.006263 | lr 6.5059e-05 | norm: 0.0844 | dt: 180.42ms | tok/sec: 90808.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17941 | loss: 0.005124 | lr 6.5050e-05 | norm: 0.0743 | dt: 179.58ms | tok/sec: 91232.82\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17942 | loss: 0.004123 | lr 6.5041e-05 | norm: 0.0678 | dt: 181.27ms | tok/sec: 90384.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17943 | loss: 0.006607 | lr 6.5033e-05 | norm: 0.0868 | dt: 179.79ms | tok/sec: 91127.92\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17944 | loss: 0.004174 | lr 6.5024e-05 | norm: 0.0718 | dt: 181.05ms | tok/sec: 90492.76\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17945 | loss: 0.004710 | lr 6.5015e-05 | norm: 0.0817 | dt: 184.07ms | tok/sec: 89010.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17946 | loss: 0.005913 | lr 6.5006e-05 | norm: 0.0668 | dt: 181.09ms | tok/sec: 90474.77\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17947 | loss: 0.004273 | lr 6.4997e-05 | norm: 0.0593 | dt: 182.50ms | tok/sec: 89776.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17948 | loss: 0.005789 | lr 6.4988e-05 | norm: 0.0832 | dt: 179.84ms | tok/sec: 91101.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17949 | loss: 0.004745 | lr 6.4979e-05 | norm: 0.0760 | dt: 181.64ms | tok/sec: 90197.95\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17950 | loss: 0.005399 | lr 6.4971e-05 | norm: 0.0856 | dt: 179.80ms | tok/sec: 91125.39\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17951 | loss: 0.003809 | lr 6.4962e-05 | norm: 0.0602 | dt: 179.85ms | tok/sec: 91097.12\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17952 | loss: 0.003952 | lr 6.4953e-05 | norm: 0.0494 | dt: 185.87ms | tok/sec: 88149.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17953 | loss: 0.004771 | lr 6.4944e-05 | norm: 0.0785 | dt: 180.01ms | tok/sec: 91015.92\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17954 | loss: 0.005459 | lr 6.4935e-05 | norm: 0.0887 | dt: 179.43ms | tok/sec: 91310.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17955 | loss: 0.004488 | lr 6.4927e-05 | norm: 0.0678 | dt: 179.13ms | tok/sec: 91465.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17956 | loss: 0.006805 | lr 6.4918e-05 | norm: 0.0787 | dt: 180.02ms | tok/sec: 91011.22\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17957 | loss: 0.005806 | lr 6.4909e-05 | norm: 0.0794 | dt: 179.87ms | tok/sec: 91089.39\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17958 | loss: 0.005326 | lr 6.4900e-05 | norm: 0.0717 | dt: 180.87ms | tok/sec: 90584.61\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17959 | loss: 0.004058 | lr 6.4891e-05 | norm: 0.0661 | dt: 180.09ms | tok/sec: 90975.55\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17960 | loss: 0.005798 | lr 6.4883e-05 | norm: 0.0927 | dt: 179.59ms | tok/sec: 91229.91\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17961 | loss: 0.006054 | lr 6.4874e-05 | norm: 0.0905 | dt: 179.26ms | tok/sec: 91395.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17962 | loss: 0.005787 | lr 6.4865e-05 | norm: 0.0792 | dt: 179.94ms | tok/sec: 91053.55\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17963 | loss: 0.003872 | lr 6.4856e-05 | norm: 0.0738 | dt: 179.58ms | tok/sec: 91237.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17964 | loss: 0.006473 | lr 6.4848e-05 | norm: 0.0892 | dt: 179.53ms | tok/sec: 91262.14\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17965 | loss: 0.005192 | lr 6.4839e-05 | norm: 0.0786 | dt: 179.51ms | tok/sec: 91269.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17966 | loss: 0.007293 | lr 6.4830e-05 | norm: 0.0777 | dt: 180.99ms | tok/sec: 90524.35\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17967 | loss: 0.007045 | lr 6.4822e-05 | norm: 0.0871 | dt: 180.75ms | tok/sec: 90644.11\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17968 | loss: 0.004114 | lr 6.4813e-05 | norm: 0.0576 | dt: 178.29ms | tok/sec: 91897.37\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17969 | loss: 0.004174 | lr 6.4804e-05 | norm: 0.0718 | dt: 179.56ms | tok/sec: 91246.99\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17970 | loss: 0.004333 | lr 6.4796e-05 | norm: 0.0666 | dt: 178.83ms | tok/sec: 91618.76\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17971 | loss: 0.003468 | lr 6.4787e-05 | norm: 0.0624 | dt: 178.22ms | tok/sec: 91932.16\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17972 | loss: 0.004535 | lr 6.4778e-05 | norm: 0.0634 | dt: 179.63ms | tok/sec: 91209.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17973 | loss: 0.004077 | lr 6.4770e-05 | norm: 0.0570 | dt: 179.05ms | tok/sec: 91506.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17974 | loss: 0.004716 | lr 6.4761e-05 | norm: 0.0685 | dt: 178.60ms | tok/sec: 91734.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17975 | loss: 0.005775 | lr 6.4752e-05 | norm: 0.0639 | dt: 180.68ms | tok/sec: 90680.95\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17976 | loss: 0.004780 | lr 6.4744e-05 | norm: 0.0579 | dt: 180.02ms | tok/sec: 91010.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17977 | loss: 0.004449 | lr 6.4735e-05 | norm: 0.0462 | dt: 179.72ms | tok/sec: 91164.19\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17978 | loss: 0.004306 | lr 6.4727e-05 | norm: 0.0595 | dt: 182.94ms | tok/sec: 89557.43\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17979 | loss: 0.006109 | lr 6.4718e-05 | norm: 0.0691 | dt: 179.38ms | tok/sec: 91337.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17980 | loss: 0.004394 | lr 6.4709e-05 | norm: 0.0630 | dt: 180.51ms | tok/sec: 90763.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17981 | loss: 0.004349 | lr 6.4701e-05 | norm: 0.0595 | dt: 180.31ms | tok/sec: 90864.16\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17982 | loss: 0.004193 | lr 6.4692e-05 | norm: 0.0685 | dt: 180.24ms | tok/sec: 90898.90\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17983 | loss: 0.006038 | lr 6.4684e-05 | norm: 0.0995 | dt: 181.21ms | tok/sec: 90412.51\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17984 | loss: 0.006364 | lr 6.4675e-05 | norm: 0.0790 | dt: 178.52ms | tok/sec: 91779.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17985 | loss: 0.004533 | lr 6.4666e-05 | norm: 0.0802 | dt: 179.03ms | tok/sec: 91517.25\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17986 | loss: 0.006337 | lr 6.4658e-05 | norm: 0.0815 | dt: 180.30ms | tok/sec: 90870.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17987 | loss: 0.003926 | lr 6.4649e-05 | norm: 0.0571 | dt: 179.19ms | tok/sec: 91432.62\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17988 | loss: 0.003132 | lr 6.4641e-05 | norm: 0.0465 | dt: 179.31ms | tok/sec: 91372.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17989 | loss: 0.005706 | lr 6.4632e-05 | norm: 0.0751 | dt: 181.23ms | tok/sec: 90405.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17990 | loss: 0.005607 | lr 6.4624e-05 | norm: 0.0640 | dt: 179.15ms | tok/sec: 91452.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17991 | loss: 0.004098 | lr 6.4615e-05 | norm: 0.0662 | dt: 179.71ms | tok/sec: 91170.00\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17992 | loss: 0.006646 | lr 6.4607e-05 | norm: 0.0807 | dt: 181.13ms | tok/sec: 90454.28\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17993 | loss: 0.004555 | lr 6.4598e-05 | norm: 0.0605 | dt: 179.90ms | tok/sec: 91072.37\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17994 | loss: 0.006213 | lr 6.4590e-05 | norm: 0.0708 | dt: 181.30ms | tok/sec: 90367.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17995 | loss: 0.007167 | lr 6.4581e-05 | norm: 0.0853 | dt: 181.65ms | tok/sec: 90195.82\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17996 | loss: 0.004701 | lr 6.4573e-05 | norm: 0.0716 | dt: 180.84ms | tok/sec: 90598.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17997 | loss: 0.005079 | lr 6.4564e-05 | norm: 0.0840 | dt: 180.55ms | tok/sec: 90745.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17998 | loss: 0.005295 | lr 6.4556e-05 | norm: 0.0677 | dt: 179.62ms | tok/sec: 91214.29\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 17999 | loss: 0.005384 | lr 6.4547e-05 | norm: 0.0689 | dt: 180.58ms | tok/sec: 90731.84\n",
      "validation loss: 0.1563\n",
      "rank 0 sample 0: Smoking is the major risk factor for<|endoftext|> heart disease in U.S. adults frequently need treatment to lower blood pressure, but it does not delay<|endoftext|>Q: What are the symptoms of<|endoftext|>ros<|endoftext|> ? A: What are the signs and symptoms of<|endoftext|>ros<|endoftext|>? The Human<|endoftext|>otype Ontology provides the following\n",
      "rank 0 sample 1: Smoking is the major risk factor for heart disease, a condition in which blood flow toath relatively low levels of<|endoftext|> and/or<|endoftext|>okal<|endoftext|> is present.<|endoftext|>Q: What are the symptoms of Heart Block ? A: What are the signs and symptoms of Heart Block? The Human<|endoftext|>otype Ontology provides\n",
      "rank 0 sample 2: Smoking is the major risk factor for heart disease, long-term heart disease, and diabetes. L<|endoftext|> changes, fatigue, and hunger appear to be<|endoftext|> in all age groups.<|endoftext|>Q: How to prevent<|endoftext|>' Disease ? A:<|endoftext|> You can take steps to prevent or delay heart disease and stroke. But\n",
      "rank 0 sample 3: Smoking is the major risk factor for heart disease, a heart attack.<|endoftext|>Q: What are the symptoms of Metachromatic leukodystrophy ? A: What are the signs and symptoms of Metachromatic leukodystrophy? The Human<|endoftext|>otype Ontology provides the following list of signs\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18000 | loss: 0.004349 | lr 6.4539e-05 | norm: 0.0660 | dt: 3681.71ms | tok/sec: 4450.11\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18001 | loss: 0.016367 | lr 6.4531e-05 | norm: 0.1581 | dt: 186.82ms | tok/sec: 87698.26\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18002 | loss: 0.010432 | lr 6.4522e-05 | norm: 0.1213 | dt: 181.48ms | tok/sec: 90279.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18003 | loss: 0.014914 | lr 6.4514e-05 | norm: 0.1608 | dt: 179.87ms | tok/sec: 91088.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18004 | loss: 0.011244 | lr 6.4505e-05 | norm: 0.1438 | dt: 180.62ms | tok/sec: 90710.16\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18005 | loss: 0.007885 | lr 6.4497e-05 | norm: 0.1125 | dt: 180.91ms | tok/sec: 90562.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18006 | loss: 0.010534 | lr 6.4489e-05 | norm: 0.1468 | dt: 180.70ms | tok/sec: 90670.06\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18007 | loss: 0.010184 | lr 6.4480e-05 | norm: 0.1445 | dt: 180.95ms | tok/sec: 90543.43\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18008 | loss: 0.012684 | lr 6.4472e-05 | norm: 0.1538 | dt: 182.63ms | tok/sec: 89711.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18009 | loss: 0.011227 | lr 6.4463e-05 | norm: 0.1675 | dt: 179.92ms | tok/sec: 91063.68\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18010 | loss: 0.010582 | lr 6.4455e-05 | norm: 0.1546 | dt: 180.00ms | tok/sec: 91020.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18011 | loss: 0.012316 | lr 6.4447e-05 | norm: 0.1521 | dt: 181.12ms | tok/sec: 90459.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18012 | loss: 0.012015 | lr 6.4438e-05 | norm: 0.1949 | dt: 181.22ms | tok/sec: 90408.35\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18013 | loss: 0.009088 | lr 6.4430e-05 | norm: 0.1356 | dt: 186.55ms | tok/sec: 87825.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18014 | loss: 0.014932 | lr 6.4422e-05 | norm: 0.1912 | dt: 181.20ms | tok/sec: 90421.91\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18015 | loss: 0.010734 | lr 6.4413e-05 | norm: 0.1434 | dt: 182.36ms | tok/sec: 89845.24\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18016 | loss: 0.012987 | lr 6.4405e-05 | norm: 0.1663 | dt: 180.72ms | tok/sec: 90661.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18017 | loss: 0.010338 | lr 6.4397e-05 | norm: 0.1614 | dt: 180.61ms | tok/sec: 90713.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18018 | loss: 0.012559 | lr 6.4388e-05 | norm: 0.2092 | dt: 181.12ms | tok/sec: 90457.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18019 | loss: 0.013565 | lr 6.4380e-05 | norm: 0.2303 | dt: 181.35ms | tok/sec: 90344.76\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18020 | loss: 0.019523 | lr 6.4372e-05 | norm: 0.2360 | dt: 180.49ms | tok/sec: 90773.19\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18021 | loss: 0.018605 | lr 6.4364e-05 | norm: 0.2691 | dt: 180.40ms | tok/sec: 90819.01\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18022 | loss: 0.014280 | lr 6.4355e-05 | norm: 0.1905 | dt: 180.39ms | tok/sec: 90824.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18023 | loss: 0.013704 | lr 6.4347e-05 | norm: 0.1997 | dt: 181.54ms | tok/sec: 90251.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18024 | loss: 0.013440 | lr 6.4339e-05 | norm: 0.1643 | dt: 180.25ms | tok/sec: 90895.05\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18025 | loss: 0.011145 | lr 6.4331e-05 | norm: 0.1378 | dt: 180.02ms | tok/sec: 91012.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18026 | loss: 0.012369 | lr 6.4322e-05 | norm: 0.1177 | dt: 180.13ms | tok/sec: 90957.49\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18027 | loss: 0.011982 | lr 6.4314e-05 | norm: 0.1641 | dt: 191.76ms | tok/sec: 85440.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18028 | loss: 0.012633 | lr 6.4306e-05 | norm: 0.1780 | dt: 183.11ms | tok/sec: 89474.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18029 | loss: 0.014337 | lr 6.4298e-05 | norm: 0.2006 | dt: 188.46ms | tok/sec: 86937.16\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18030 | loss: 0.015313 | lr 6.4289e-05 | norm: 0.2519 | dt: 179.46ms | tok/sec: 91298.51\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18031 | loss: 0.015560 | lr 6.4281e-05 | norm: 0.2353 | dt: 180.67ms | tok/sec: 90682.51\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18032 | loss: 0.017752 | lr 6.4273e-05 | norm: 0.2073 | dt: 191.26ms | tok/sec: 85665.16\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18033 | loss: 0.011232 | lr 6.4265e-05 | norm: 0.1657 | dt: 180.22ms | tok/sec: 90909.12\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18034 | loss: 0.018314 | lr 6.4257e-05 | norm: 0.2227 | dt: 178.91ms | tok/sec: 91577.01\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18035 | loss: 0.016316 | lr 6.4248e-05 | norm: 0.1979 | dt: 188.09ms | tok/sec: 87106.98\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18036 | loss: 0.011637 | lr 6.4240e-05 | norm: 0.1627 | dt: 186.34ms | tok/sec: 87924.92\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18037 | loss: 0.016244 | lr 6.4232e-05 | norm: 0.1896 | dt: 182.17ms | tok/sec: 89936.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18038 | loss: 0.015226 | lr 6.4224e-05 | norm: 0.2002 | dt: 179.55ms | tok/sec: 91252.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18039 | loss: 0.025383 | lr 6.4216e-05 | norm: 0.3322 | dt: 188.36ms | tok/sec: 86982.61\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18040 | loss: 0.017575 | lr 6.4208e-05 | norm: 0.2767 | dt: 183.80ms | tok/sec: 89138.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18041 | loss: 0.021397 | lr 6.4200e-05 | norm: 0.3101 | dt: 179.63ms | tok/sec: 91207.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18042 | loss: 0.018105 | lr 6.4192e-05 | norm: 0.2259 | dt: 193.51ms | tok/sec: 84669.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18043 | loss: 0.018997 | lr 6.4183e-05 | norm: 0.2198 | dt: 192.37ms | tok/sec: 85167.97\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18044 | loss: 0.015635 | lr 6.4175e-05 | norm: 0.2050 | dt: 181.40ms | tok/sec: 90321.60\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18045 | loss: 0.015936 | lr 6.4167e-05 | norm: 0.1770 | dt: 186.38ms | tok/sec: 87905.91\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18046 | loss: 0.013382 | lr 6.4159e-05 | norm: 0.1747 | dt: 191.84ms | tok/sec: 85402.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18047 | loss: 0.016860 | lr 6.4151e-05 | norm: 0.2047 | dt: 184.59ms | tok/sec: 88760.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18048 | loss: 0.011070 | lr 6.4143e-05 | norm: 0.1500 | dt: 180.76ms | tok/sec: 90641.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18049 | loss: 0.016096 | lr 6.4135e-05 | norm: 0.1870 | dt: 192.62ms | tok/sec: 85059.60\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18050 | loss: 0.006560 | lr 6.4127e-05 | norm: 0.0938 | dt: 182.93ms | tok/sec: 89563.62\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18051 | loss: 0.005738 | lr 6.4119e-05 | norm: 0.0948 | dt: 183.56ms | tok/sec: 89256.62\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18052 | loss: 0.005670 | lr 6.4111e-05 | norm: 0.1201 | dt: 186.32ms | tok/sec: 87933.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18053 | loss: 0.006442 | lr 6.4103e-05 | norm: 0.0794 | dt: 180.67ms | tok/sec: 90685.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18054 | loss: 0.004792 | lr 6.4095e-05 | norm: 0.0879 | dt: 181.21ms | tok/sec: 90413.46\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18055 | loss: 0.005316 | lr 6.4087e-05 | norm: 0.0765 | dt: 184.22ms | tok/sec: 88939.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18056 | loss: 0.005352 | lr 6.4079e-05 | norm: 0.0856 | dt: 180.80ms | tok/sec: 90620.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18057 | loss: 0.005584 | lr 6.4071e-05 | norm: 0.0754 | dt: 179.12ms | tok/sec: 91470.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18058 | loss: 0.010012 | lr 6.4063e-05 | norm: 0.1478 | dt: 182.66ms | tok/sec: 89697.12\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18059 | loss: 0.005608 | lr 6.4055e-05 | norm: 0.0886 | dt: 185.78ms | tok/sec: 88189.29\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18060 | loss: 0.005266 | lr 6.4047e-05 | norm: 0.0890 | dt: 179.52ms | tok/sec: 91267.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18061 | loss: 0.006870 | lr 6.4039e-05 | norm: 0.0962 | dt: 179.77ms | tok/sec: 91137.11\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18062 | loss: 0.004236 | lr 6.4031e-05 | norm: 0.0842 | dt: 189.08ms | tok/sec: 86650.28\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18063 | loss: 0.004522 | lr 6.4023e-05 | norm: 0.0821 | dt: 180.64ms | tok/sec: 90698.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18064 | loss: 0.005323 | lr 6.4015e-05 | norm: 0.0786 | dt: 179.98ms | tok/sec: 91033.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18065 | loss: 0.006207 | lr 6.4007e-05 | norm: 0.0852 | dt: 180.05ms | tok/sec: 90996.40\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18066 | loss: 0.005413 | lr 6.3999e-05 | norm: 0.1009 | dt: 187.06ms | tok/sec: 87586.37\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18067 | loss: 0.005261 | lr 6.3991e-05 | norm: 0.0823 | dt: 179.97ms | tok/sec: 91035.45\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18068 | loss: 0.007348 | lr 6.3983e-05 | norm: 0.1236 | dt: 180.36ms | tok/sec: 90842.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18069 | loss: 0.007878 | lr 6.3975e-05 | norm: 0.1075 | dt: 191.57ms | tok/sec: 85526.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18070 | loss: 0.005550 | lr 6.3968e-05 | norm: 0.0795 | dt: 179.92ms | tok/sec: 91061.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18071 | loss: 0.005311 | lr 6.3960e-05 | norm: 0.0818 | dt: 179.71ms | tok/sec: 91169.76\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18072 | loss: 0.005604 | lr 6.3952e-05 | norm: 0.0757 | dt: 188.23ms | tok/sec: 87042.43\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18073 | loss: 0.005967 | lr 6.3944e-05 | norm: 0.0826 | dt: 179.31ms | tok/sec: 91372.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18074 | loss: 0.006533 | lr 6.3936e-05 | norm: 0.0994 | dt: 184.74ms | tok/sec: 88684.71\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18075 | loss: 0.005774 | lr 6.3928e-05 | norm: 0.0798 | dt: 179.06ms | tok/sec: 91498.60\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18076 | loss: 0.004766 | lr 6.3920e-05 | norm: 0.0648 | dt: 179.48ms | tok/sec: 91284.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18077 | loss: 0.006018 | lr 6.3912e-05 | norm: 0.0737 | dt: 179.65ms | tok/sec: 91201.21\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18078 | loss: 0.006405 | lr 6.3905e-05 | norm: 0.0835 | dt: 183.80ms | tok/sec: 89141.19\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18079 | loss: 0.004590 | lr 6.3897e-05 | norm: 0.0657 | dt: 178.93ms | tok/sec: 91568.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18080 | loss: 0.004878 | lr 6.3889e-05 | norm: 0.0646 | dt: 180.15ms | tok/sec: 90947.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18081 | loss: 0.006297 | lr 6.3881e-05 | norm: 0.0696 | dt: 178.74ms | tok/sec: 91663.12\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18082 | loss: 0.006550 | lr 6.3873e-05 | norm: 0.0767 | dt: 178.52ms | tok/sec: 91778.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18083 | loss: 0.006745 | lr 6.3866e-05 | norm: 0.0830 | dt: 179.59ms | tok/sec: 91229.30\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18084 | loss: 0.005948 | lr 6.3858e-05 | norm: 0.0846 | dt: 179.45ms | tok/sec: 91299.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18085 | loss: 0.004749 | lr 6.3850e-05 | norm: 0.0732 | dt: 178.95ms | tok/sec: 91555.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18086 | loss: 0.004415 | lr 6.3842e-05 | norm: 0.0716 | dt: 179.72ms | tok/sec: 91163.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18087 | loss: 0.006529 | lr 6.3834e-05 | norm: 0.0795 | dt: 178.91ms | tok/sec: 91576.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18088 | loss: 0.004296 | lr 6.3827e-05 | norm: 0.0616 | dt: 179.31ms | tok/sec: 91372.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18089 | loss: 0.004551 | lr 6.3819e-05 | norm: 0.0741 | dt: 179.35ms | tok/sec: 91350.82\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18090 | loss: 0.006053 | lr 6.3811e-05 | norm: 0.0714 | dt: 178.86ms | tok/sec: 91601.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18091 | loss: 0.005672 | lr 6.3804e-05 | norm: 0.0685 | dt: 182.97ms | tok/sec: 89544.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18092 | loss: 0.005304 | lr 6.3796e-05 | norm: 0.0667 | dt: 179.42ms | tok/sec: 91315.37\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18093 | loss: 0.003887 | lr 6.3788e-05 | norm: 0.0617 | dt: 179.66ms | tok/sec: 91193.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18094 | loss: 0.005737 | lr 6.3780e-05 | norm: 0.0799 | dt: 179.02ms | tok/sec: 91522.37\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18095 | loss: 0.005219 | lr 6.3773e-05 | norm: 0.0761 | dt: 179.83ms | tok/sec: 91106.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18096 | loss: 0.004849 | lr 6.3765e-05 | norm: 0.0611 | dt: 178.91ms | tok/sec: 91578.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18097 | loss: 0.006192 | lr 6.3757e-05 | norm: 0.0743 | dt: 216.86ms | tok/sec: 75551.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18098 | loss: 0.006221 | lr 6.3750e-05 | norm: 0.0797 | dt: 181.37ms | tok/sec: 90333.12\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18099 | loss: 0.004514 | lr 6.3742e-05 | norm: 0.0641 | dt: 179.49ms | tok/sec: 91282.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18100 | loss: 0.006006 | lr 6.3734e-05 | norm: 0.0757 | dt: 179.03ms | tok/sec: 91513.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18101 | loss: 0.003531 | lr 6.3727e-05 | norm: 0.0975 | dt: 179.88ms | tok/sec: 91081.79\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18102 | loss: 0.003123 | lr 6.3719e-05 | norm: 0.0719 | dt: 179.69ms | tok/sec: 91181.49\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18103 | loss: 0.004848 | lr 6.3711e-05 | norm: 0.0621 | dt: 179.73ms | tok/sec: 91160.20\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18104 | loss: 0.005779 | lr 6.3704e-05 | norm: 0.0828 | dt: 179.19ms | tok/sec: 91434.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18105 | loss: 0.005758 | lr 6.3696e-05 | norm: 0.0743 | dt: 179.59ms | tok/sec: 91231.61\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18106 | loss: 0.007425 | lr 6.3688e-05 | norm: 0.0862 | dt: 179.86ms | tok/sec: 91095.31\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18107 | loss: 0.005642 | lr 6.3681e-05 | norm: 0.0796 | dt: 184.33ms | tok/sec: 88882.00\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18108 | loss: 0.006285 | lr 6.3673e-05 | norm: 0.0754 | dt: 182.97ms | tok/sec: 89543.31\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18109 | loss: 0.005119 | lr 6.3666e-05 | norm: 0.0650 | dt: 184.24ms | tok/sec: 88929.28\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18110 | loss: 0.004763 | lr 6.3658e-05 | norm: 0.0738 | dt: 180.29ms | tok/sec: 90876.90\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18111 | loss: 0.005441 | lr 6.3650e-05 | norm: 0.0787 | dt: 180.27ms | tok/sec: 90885.55\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18112 | loss: 0.003852 | lr 6.3643e-05 | norm: 0.0689 | dt: 179.78ms | tok/sec: 91132.40\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18113 | loss: 0.005603 | lr 6.3635e-05 | norm: 0.0734 | dt: 178.96ms | tok/sec: 91549.68\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18114 | loss: 0.006250 | lr 6.3628e-05 | norm: 0.0899 | dt: 178.86ms | tok/sec: 91600.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18115 | loss: 0.006106 | lr 6.3620e-05 | norm: 0.0879 | dt: 180.26ms | tok/sec: 90888.56\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18116 | loss: 0.008940 | lr 6.3613e-05 | norm: 0.1205 | dt: 179.73ms | tok/sec: 91158.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18117 | loss: 0.005840 | lr 6.3605e-05 | norm: 0.0627 | dt: 180.98ms | tok/sec: 90527.45\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18118 | loss: 0.005574 | lr 6.3598e-05 | norm: 0.0794 | dt: 185.65ms | tok/sec: 88253.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18119 | loss: 0.006225 | lr 6.3590e-05 | norm: 0.0704 | dt: 179.72ms | tok/sec: 91162.26\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18120 | loss: 0.006882 | lr 6.3583e-05 | norm: 0.0989 | dt: 178.98ms | tok/sec: 91540.04\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18121 | loss: 0.005978 | lr 6.3575e-05 | norm: 0.0717 | dt: 178.84ms | tok/sec: 91611.31\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18122 | loss: 0.006305 | lr 6.3568e-05 | norm: 0.0755 | dt: 179.58ms | tok/sec: 91235.24\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18123 | loss: 0.008107 | lr 6.3560e-05 | norm: 0.1045 | dt: 179.52ms | tok/sec: 91263.23\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18124 | loss: 0.005650 | lr 6.3553e-05 | norm: 0.0741 | dt: 182.70ms | tok/sec: 89675.94\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18125 | loss: 0.008602 | lr 6.3545e-05 | norm: 0.1140 | dt: 179.14ms | tok/sec: 91459.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18126 | loss: 0.008986 | lr 6.3538e-05 | norm: 0.1018 | dt: 180.97ms | tok/sec: 90533.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18127 | loss: 0.007726 | lr 6.3530e-05 | norm: 0.1306 | dt: 178.17ms | tok/sec: 91956.40\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18128 | loss: 0.012093 | lr 6.3523e-05 | norm: 0.1201 | dt: 178.95ms | tok/sec: 91555.04\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18129 | loss: 0.013709 | lr 6.3515e-05 | norm: 0.1313 | dt: 179.50ms | tok/sec: 91275.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18130 | loss: 0.013234 | lr 6.3508e-05 | norm: 0.1389 | dt: 179.00ms | tok/sec: 91529.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18131 | loss: 0.011615 | lr 6.3501e-05 | norm: 0.1494 | dt: 180.20ms | tok/sec: 90919.22\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18132 | loss: 0.015473 | lr 6.3493e-05 | norm: 0.1574 | dt: 179.30ms | tok/sec: 91375.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18133 | loss: 0.013360 | lr 6.3486e-05 | norm: 0.1489 | dt: 179.58ms | tok/sec: 91233.91\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18134 | loss: 0.013553 | lr 6.3478e-05 | norm: 0.1316 | dt: 179.09ms | tok/sec: 91483.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18135 | loss: 0.010951 | lr 6.3471e-05 | norm: 0.1331 | dt: 182.94ms | tok/sec: 89561.28\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18136 | loss: 0.013826 | lr 6.3464e-05 | norm: 0.1353 | dt: 179.14ms | tok/sec: 91461.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18137 | loss: 0.011301 | lr 6.3456e-05 | norm: 0.1580 | dt: 178.78ms | tok/sec: 91641.73\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18138 | loss: 0.012043 | lr 6.3449e-05 | norm: 0.1060 | dt: 178.76ms | tok/sec: 91652.24\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18139 | loss: 0.010064 | lr 6.3442e-05 | norm: 0.1047 | dt: 180.07ms | tok/sec: 90989.29\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18140 | loss: 0.019502 | lr 6.3434e-05 | norm: 0.3427 | dt: 178.98ms | tok/sec: 91539.31\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18141 | loss: 0.012228 | lr 6.3427e-05 | norm: 0.1163 | dt: 178.60ms | tok/sec: 91735.93\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18142 | loss: 0.010492 | lr 6.3420e-05 | norm: 0.1012 | dt: 179.06ms | tok/sec: 91501.41\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18143 | loss: 0.011783 | lr 6.3412e-05 | norm: 0.1213 | dt: 179.05ms | tok/sec: 91506.40\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18144 | loss: 0.013181 | lr 6.3405e-05 | norm: 0.1247 | dt: 178.99ms | tok/sec: 91536.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18145 | loss: 0.011733 | lr 6.3398e-05 | norm: 0.1182 | dt: 179.84ms | tok/sec: 91100.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18146 | loss: 0.013825 | lr 6.3390e-05 | norm: 0.1175 | dt: 178.20ms | tok/sec: 91941.51\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18147 | loss: 0.012392 | lr 6.3383e-05 | norm: 0.1173 | dt: 179.00ms | tok/sec: 91531.51\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18148 | loss: 0.013132 | lr 6.3376e-05 | norm: 0.1125 | dt: 179.58ms | tok/sec: 91232.70\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18149 | loss: 0.012849 | lr 6.3368e-05 | norm: 0.1242 | dt: 178.54ms | tok/sec: 91767.41\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18150 | loss: 0.012991 | lr 6.3361e-05 | norm: 0.1358 | dt: 180.06ms | tok/sec: 90989.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18151 | loss: 0.012607 | lr 6.3354e-05 | norm: 0.1245 | dt: 182.32ms | tok/sec: 89863.21\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18152 | loss: 0.014189 | lr 6.3347e-05 | norm: 0.1283 | dt: 181.84ms | tok/sec: 90103.46\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18153 | loss: 0.008872 | lr 6.3339e-05 | norm: 0.1056 | dt: 179.93ms | tok/sec: 91055.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18154 | loss: 0.006628 | lr 6.3332e-05 | norm: 0.0882 | dt: 179.32ms | tok/sec: 91366.61\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18155 | loss: 0.009089 | lr 6.3325e-05 | norm: 0.0855 | dt: 178.85ms | tok/sec: 91607.28\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18156 | loss: 0.010373 | lr 6.3318e-05 | norm: 0.0995 | dt: 178.99ms | tok/sec: 91538.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18157 | loss: 0.011047 | lr 6.3310e-05 | norm: 0.1154 | dt: 183.51ms | tok/sec: 89282.25\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18158 | loss: 0.008073 | lr 6.3303e-05 | norm: 0.0976 | dt: 179.04ms | tok/sec: 91508.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18159 | loss: 0.006136 | lr 6.3296e-05 | norm: 0.0815 | dt: 178.90ms | tok/sec: 91583.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18160 | loss: 0.009822 | lr 6.3289e-05 | norm: 0.1035 | dt: 179.13ms | tok/sec: 91465.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18161 | loss: 0.007164 | lr 6.3282e-05 | norm: 0.0788 | dt: 183.06ms | tok/sec: 89502.14\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18162 | loss: 0.007893 | lr 6.3274e-05 | norm: 0.0830 | dt: 180.60ms | tok/sec: 90719.26\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18163 | loss: 0.007967 | lr 6.3267e-05 | norm: 0.0707 | dt: 178.52ms | tok/sec: 91775.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18164 | loss: 0.007185 | lr 6.3260e-05 | norm: 0.0733 | dt: 179.77ms | tok/sec: 91137.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18165 | loss: 0.009172 | lr 6.3253e-05 | norm: 0.0837 | dt: 178.86ms | tok/sec: 91602.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18166 | loss: 0.014840 | lr 6.3246e-05 | norm: 0.1412 | dt: 179.30ms | tok/sec: 91377.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18167 | loss: 0.007792 | lr 6.3239e-05 | norm: 0.0993 | dt: 180.15ms | tok/sec: 90946.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18168 | loss: 0.008535 | lr 6.3232e-05 | norm: 0.1121 | dt: 179.62ms | tok/sec: 91213.20\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18169 | loss: 0.008515 | lr 6.3224e-05 | norm: 0.0791 | dt: 179.41ms | tok/sec: 91323.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18170 | loss: 0.010775 | lr 6.3217e-05 | norm: 0.0960 | dt: 179.72ms | tok/sec: 91162.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18171 | loss: 0.007252 | lr 6.3210e-05 | norm: 0.0705 | dt: 179.83ms | tok/sec: 91108.23\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18172 | loss: 0.006569 | lr 6.3203e-05 | norm: 0.0750 | dt: 180.28ms | tok/sec: 90880.39\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18173 | loss: 0.011183 | lr 6.3196e-05 | norm: 0.1027 | dt: 182.91ms | tok/sec: 89572.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18174 | loss: 0.008045 | lr 6.3189e-05 | norm: 0.0882 | dt: 180.86ms | tok/sec: 90590.22\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18175 | loss: 0.006215 | lr 6.3182e-05 | norm: 0.0615 | dt: 181.20ms | tok/sec: 90420.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18176 | loss: 0.013418 | lr 6.3175e-05 | norm: 0.1572 | dt: 180.85ms | tok/sec: 90595.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18177 | loss: 0.006365 | lr 6.3168e-05 | norm: 0.0677 | dt: 180.54ms | tok/sec: 90750.65\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18178 | loss: 0.010115 | lr 6.3161e-05 | norm: 0.1575 | dt: 179.76ms | tok/sec: 91145.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18179 | loss: 0.013410 | lr 6.3154e-05 | norm: 0.1984 | dt: 178.19ms | tok/sec: 91944.71\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18180 | loss: 0.012797 | lr 6.3147e-05 | norm: 0.1089 | dt: 178.79ms | tok/sec: 91638.31\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18181 | loss: 0.014901 | lr 6.3140e-05 | norm: 0.1403 | dt: 180.16ms | tok/sec: 90939.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18182 | loss: 0.010852 | lr 6.3133e-05 | norm: 0.1150 | dt: 183.35ms | tok/sec: 89361.31\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18183 | loss: 0.007255 | lr 6.3126e-05 | norm: 0.0803 | dt: 184.92ms | tok/sec: 88600.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18184 | loss: 0.005557 | lr 6.3119e-05 | norm: 0.0725 | dt: 179.16ms | tok/sec: 91448.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18185 | loss: 0.005844 | lr 6.3112e-05 | norm: 0.0682 | dt: 179.30ms | tok/sec: 91376.33\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18186 | loss: 0.012130 | lr 6.3105e-05 | norm: 0.1381 | dt: 178.72ms | tok/sec: 91676.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18187 | loss: 0.007470 | lr 6.3098e-05 | norm: 0.0915 | dt: 180.07ms | tok/sec: 90988.80\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18188 | loss: 0.005557 | lr 6.3091e-05 | norm: 0.0703 | dt: 180.10ms | tok/sec: 90970.98\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18189 | loss: 0.007118 | lr 6.3084e-05 | norm: 0.0895 | dt: 181.47ms | tok/sec: 90284.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18190 | loss: 0.006965 | lr 6.3077e-05 | norm: 0.0732 | dt: 178.46ms | tok/sec: 91808.61\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18191 | loss: 0.006217 | lr 6.3070e-05 | norm: 0.0761 | dt: 180.45ms | tok/sec: 90797.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18192 | loss: 0.005369 | lr 6.3063e-05 | norm: 0.0586 | dt: 180.02ms | tok/sec: 91010.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18193 | loss: 0.006130 | lr 6.3056e-05 | norm: 0.0937 | dt: 180.08ms | tok/sec: 90983.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18194 | loss: 0.006068 | lr 6.3049e-05 | norm: 0.0793 | dt: 180.34ms | tok/sec: 90851.55\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18195 | loss: 0.009551 | lr 6.3042e-05 | norm: 0.1222 | dt: 180.75ms | tok/sec: 90646.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18196 | loss: 0.007248 | lr 6.3035e-05 | norm: 0.0886 | dt: 186.30ms | tok/sec: 87943.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18197 | loss: 0.010207 | lr 6.3028e-05 | norm: 0.1157 | dt: 179.10ms | tok/sec: 91481.43\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18198 | loss: 0.008536 | lr 6.3021e-05 | norm: 0.0907 | dt: 179.35ms | tok/sec: 91351.55\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18199 | loss: 0.009074 | lr 6.3014e-05 | norm: 0.0987 | dt: 181.17ms | tok/sec: 90436.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18200 | loss: 0.006455 | lr 6.3007e-05 | norm: 0.0789 | dt: 182.08ms | tok/sec: 89984.77\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18201 | loss: 0.005515 | lr 6.3001e-05 | norm: 0.0721 | dt: 180.23ms | tok/sec: 90905.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18202 | loss: 0.006573 | lr 6.2994e-05 | norm: 0.0678 | dt: 179.66ms | tok/sec: 91193.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18203 | loss: 0.007211 | lr 6.2987e-05 | norm: 0.0955 | dt: 178.96ms | tok/sec: 91553.58\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18204 | loss: 0.008606 | lr 6.2980e-05 | norm: 0.1106 | dt: 179.17ms | tok/sec: 91442.35\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18205 | loss: 0.006076 | lr 6.2973e-05 | norm: 0.0760 | dt: 179.22ms | tok/sec: 91415.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18206 | loss: 0.008410 | lr 6.2966e-05 | norm: 0.0885 | dt: 179.21ms | tok/sec: 91423.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18207 | loss: 0.006462 | lr 6.2960e-05 | norm: 0.0873 | dt: 179.81ms | tok/sec: 91120.55\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18208 | loss: 0.004994 | lr 6.2953e-05 | norm: 0.0675 | dt: 179.71ms | tok/sec: 91168.43\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18209 | loss: 0.004877 | lr 6.2946e-05 | norm: 0.0784 | dt: 179.70ms | tok/sec: 91175.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18210 | loss: 0.005366 | lr 6.2939e-05 | norm: 0.0721 | dt: 182.80ms | tok/sec: 89629.62\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18211 | loss: 0.003777 | lr 6.2932e-05 | norm: 0.0730 | dt: 179.19ms | tok/sec: 91436.15\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18212 | loss: 0.005628 | lr 6.2926e-05 | norm: 0.0767 | dt: 178.67ms | tok/sec: 91701.16\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18213 | loss: 0.005122 | lr 6.2919e-05 | norm: 0.0784 | dt: 179.95ms | tok/sec: 91047.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18214 | loss: 0.004096 | lr 6.2912e-05 | norm: 0.0794 | dt: 179.01ms | tok/sec: 91523.71\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18215 | loss: 0.005472 | lr 6.2905e-05 | norm: 0.0750 | dt: 178.82ms | tok/sec: 91625.24\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18216 | loss: 0.005655 | lr 6.2898e-05 | norm: 0.0870 | dt: 180.56ms | tok/sec: 90741.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18217 | loss: 0.005931 | lr 6.2892e-05 | norm: 0.0707 | dt: 179.40ms | tok/sec: 91324.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18218 | loss: 0.004739 | lr 6.2885e-05 | norm: 0.0710 | dt: 180.81ms | tok/sec: 90612.20\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18219 | loss: 0.006091 | lr 6.2878e-05 | norm: 0.0898 | dt: 179.85ms | tok/sec: 91097.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18220 | loss: 0.006873 | lr 6.2872e-05 | norm: 0.0798 | dt: 179.14ms | tok/sec: 91456.71\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18221 | loss: 0.004991 | lr 6.2865e-05 | norm: 0.0686 | dt: 180.95ms | tok/sec: 90542.72\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18222 | loss: 0.006596 | lr 6.2858e-05 | norm: 0.0865 | dt: 178.59ms | tok/sec: 91743.40\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18223 | loss: 0.007669 | lr 6.2851e-05 | norm: 0.0900 | dt: 178.51ms | tok/sec: 91782.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18224 | loss: 0.005933 | lr 6.2845e-05 | norm: 0.0798 | dt: 179.86ms | tok/sec: 91093.01\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18225 | loss: 0.007329 | lr 6.2838e-05 | norm: 0.0780 | dt: 178.83ms | tok/sec: 91617.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18226 | loss: 0.005435 | lr 6.2831e-05 | norm: 0.0712 | dt: 179.07ms | tok/sec: 91495.19\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18227 | loss: 0.004779 | lr 6.2825e-05 | norm: 0.0617 | dt: 179.32ms | tok/sec: 91368.31\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18228 | loss: 0.005414 | lr 6.2818e-05 | norm: 0.0770 | dt: 178.81ms | tok/sec: 91625.72\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18229 | loss: 0.005511 | lr 6.2811e-05 | norm: 0.0767 | dt: 179.58ms | tok/sec: 91234.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18230 | loss: 0.004282 | lr 6.2805e-05 | norm: 0.0586 | dt: 180.05ms | tok/sec: 90995.07\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18231 | loss: 0.007117 | lr 6.2798e-05 | norm: 0.0898 | dt: 179.71ms | tok/sec: 91169.27\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18232 | loss: 0.004224 | lr 6.2791e-05 | norm: 0.0681 | dt: 181.25ms | tok/sec: 90394.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18233 | loss: 0.004646 | lr 6.2785e-05 | norm: 0.0575 | dt: 179.02ms | tok/sec: 91522.61\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18234 | loss: 0.006567 | lr 6.2778e-05 | norm: 0.0904 | dt: 179.35ms | tok/sec: 91352.76\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18235 | loss: 0.006226 | lr 6.2772e-05 | norm: 0.0739 | dt: 179.88ms | tok/sec: 91080.94\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18236 | loss: 0.004278 | lr 6.2765e-05 | norm: 0.0698 | dt: 180.43ms | tok/sec: 90804.37\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18237 | loss: 0.005035 | lr 6.2758e-05 | norm: 0.0717 | dt: 180.23ms | tok/sec: 90906.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18238 | loss: 0.005054 | lr 6.2752e-05 | norm: 0.0677 | dt: 183.24ms | tok/sec: 89415.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18239 | loss: 0.006002 | lr 6.2745e-05 | norm: 0.0703 | dt: 183.68ms | tok/sec: 89198.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18240 | loss: 0.002760 | lr 6.2739e-05 | norm: 0.0592 | dt: 180.65ms | tok/sec: 90692.56\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18241 | loss: 0.003738 | lr 6.2732e-05 | norm: 0.0525 | dt: 180.60ms | tok/sec: 90719.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18242 | loss: 0.004698 | lr 6.2726e-05 | norm: 0.0688 | dt: 182.51ms | tok/sec: 89771.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18243 | loss: 0.004357 | lr 6.2719e-05 | norm: 0.0627 | dt: 181.35ms | tok/sec: 90342.27\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18244 | loss: 0.003850 | lr 6.2712e-05 | norm: 0.0651 | dt: 180.71ms | tok/sec: 90662.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18245 | loss: 0.006058 | lr 6.2706e-05 | norm: 0.0767 | dt: 179.66ms | tok/sec: 91193.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18246 | loss: 0.006375 | lr 6.2699e-05 | norm: 0.0947 | dt: 182.57ms | tok/sec: 89740.46\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18247 | loss: 0.008509 | lr 6.2693e-05 | norm: 0.0990 | dt: 180.97ms | tok/sec: 90535.92\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18248 | loss: 0.006771 | lr 6.2686e-05 | norm: 0.0816 | dt: 181.25ms | tok/sec: 90394.79\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18249 | loss: 0.004869 | lr 6.2680e-05 | norm: 0.0722 | dt: 179.56ms | tok/sec: 91246.02\n",
      "validation loss: 0.1491\n",
      "rank 0 sample 0: Smoking is the major risk factor for lung cancer. This is especially true if theowing of the large<|endoftext|> is a<|endoftext|> of explosion. The parent may become case with less than one ble of the other polyps and enter<|endoftext|>. Often, the parent has a child with the condition. Most cases of lung cancer occur\n",
      "rank 0 sample 1: Smoking is the major risk factor for stroke and heart attack, a healthy weight, physical activity, and medications.<|endoftext|>ke is a health risk factor for stroke and heart attack. Treatment for stroke or heart attack ischemic attacks, sometimes prescribed treatments for high blood pressure or high blood pressure that range from high blood pressure\n",
      "rank 0 sample 2: Smoking is the major risk factor for stroke and heart attack, a and<|endoftext|> cardiomy<|endoftext|> (KAR-de-o-mi-OP-ah-thee). The goal of treatment is to<|endoftext|> blood pressure and measure of blood flow to the heart. This risk must be repeated include managing high blood\n",
      "rank 0 sample 3: Smoking is the major risk factor for CHD.<|endoftext|> with this condition receive the use of low levels of<|endoftext|> (<|endoftext|>okal<|endoftext|>) and high levels of fat-<|endoftext|><|endoftext|><|endoftext|>. Some affected individuals develop hypokal<|endoftext|> and related to hypokal<|endoftext|>. These individuals also have increased<|endoftext|> levels of<|endoftext|>\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18250 | loss: 0.006943 | lr 6.2673e-05 | norm: 0.0767 | dt: 3623.80ms | tok/sec: 4521.22\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18251 | loss: 0.005520 | lr 6.2667e-05 | norm: 0.0692 | dt: 180.33ms | tok/sec: 90856.60\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18252 | loss: 0.004625 | lr 6.2660e-05 | norm: 0.0737 | dt: 181.59ms | tok/sec: 90227.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18253 | loss: 0.004229 | lr 6.2654e-05 | norm: 0.0677 | dt: 179.03ms | tok/sec: 91516.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18254 | loss: 0.005635 | lr 6.2648e-05 | norm: 0.0736 | dt: 179.32ms | tok/sec: 91365.15\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18255 | loss: 0.004586 | lr 6.2641e-05 | norm: 0.0590 | dt: 180.47ms | tok/sec: 90786.98\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18256 | loss: 0.004337 | lr 6.2635e-05 | norm: 0.0552 | dt: 178.87ms | tok/sec: 91598.98\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18257 | loss: 0.006444 | lr 6.2628e-05 | norm: 0.0908 | dt: 184.26ms | tok/sec: 88916.39\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18258 | loss: 0.005294 | lr 6.2622e-05 | norm: 0.0662 | dt: 179.38ms | tok/sec: 91337.46\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18259 | loss: 0.004580 | lr 6.2615e-05 | norm: 0.0621 | dt: 178.45ms | tok/sec: 91813.15\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18260 | loss: 0.004070 | lr 6.2609e-05 | norm: 0.0542 | dt: 178.39ms | tok/sec: 91845.42\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18261 | loss: 0.005478 | lr 6.2603e-05 | norm: 0.0629 | dt: 179.34ms | tok/sec: 91354.95\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18262 | loss: 0.004695 | lr 6.2596e-05 | norm: 0.0727 | dt: 179.47ms | tok/sec: 91291.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18263 | loss: 0.004872 | lr 6.2590e-05 | norm: 0.0552 | dt: 178.89ms | tok/sec: 91586.04\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18264 | loss: 0.004636 | lr 6.2583e-05 | norm: 0.0706 | dt: 178.33ms | tok/sec: 91874.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18265 | loss: 0.004291 | lr 6.2577e-05 | norm: 0.0566 | dt: 178.47ms | tok/sec: 91804.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18266 | loss: 0.004611 | lr 6.2571e-05 | norm: 0.0629 | dt: 179.52ms | tok/sec: 91265.65\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18267 | loss: 0.005066 | lr 6.2564e-05 | norm: 0.0573 | dt: 180.06ms | tok/sec: 90990.97\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18268 | loss: 0.004074 | lr 6.2558e-05 | norm: 0.0494 | dt: 180.73ms | tok/sec: 90655.71\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18269 | loss: 0.005440 | lr 6.2552e-05 | norm: 0.0601 | dt: 178.99ms | tok/sec: 91533.46\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18270 | loss: 0.005581 | lr 6.2545e-05 | norm: 0.0885 | dt: 180.62ms | tok/sec: 90711.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18271 | loss: 0.003855 | lr 6.2539e-05 | norm: 0.0662 | dt: 178.20ms | tok/sec: 91940.41\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18272 | loss: 0.005463 | lr 6.2533e-05 | norm: 0.0636 | dt: 179.38ms | tok/sec: 91336.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18273 | loss: 0.005120 | lr 6.2526e-05 | norm: 0.0593 | dt: 178.85ms | tok/sec: 91608.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18274 | loss: 0.004384 | lr 6.2520e-05 | norm: 0.0613 | dt: 179.61ms | tok/sec: 91221.19\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18275 | loss: 0.005919 | lr 6.2514e-05 | norm: 0.0711 | dt: 180.00ms | tok/sec: 91020.62\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18276 | loss: 0.003782 | lr 6.2507e-05 | norm: 0.0515 | dt: 179.62ms | tok/sec: 91212.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18277 | loss: 0.005039 | lr 6.2501e-05 | norm: 0.0555 | dt: 178.53ms | tok/sec: 91769.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18278 | loss: 0.004300 | lr 6.2495e-05 | norm: 0.0541 | dt: 179.09ms | tok/sec: 91485.45\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18279 | loss: 0.006214 | lr 6.2489e-05 | norm: 0.0685 | dt: 186.72ms | tok/sec: 87747.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18280 | loss: 0.003906 | lr 6.2482e-05 | norm: 0.0491 | dt: 184.07ms | tok/sec: 89008.41\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18281 | loss: 0.004562 | lr 6.2476e-05 | norm: 0.0643 | dt: 183.16ms | tok/sec: 89450.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18282 | loss: 0.005684 | lr 6.2470e-05 | norm: 0.0639 | dt: 184.16ms | tok/sec: 88967.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18283 | loss: 0.003702 | lr 6.2464e-05 | norm: 0.0585 | dt: 179.96ms | tok/sec: 91044.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18284 | loss: 0.006517 | lr 6.2457e-05 | norm: 0.0803 | dt: 190.07ms | tok/sec: 86199.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18285 | loss: 0.004394 | lr 6.2451e-05 | norm: 0.0628 | dt: 190.27ms | tok/sec: 86108.37\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18286 | loss: 0.005200 | lr 6.2445e-05 | norm: 0.0633 | dt: 185.87ms | tok/sec: 88149.92\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18287 | loss: 0.006401 | lr 6.2439e-05 | norm: 0.0738 | dt: 185.00ms | tok/sec: 88563.22\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18288 | loss: 0.004380 | lr 6.2433e-05 | norm: 0.0544 | dt: 189.18ms | tok/sec: 86605.94\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18289 | loss: 0.006119 | lr 6.2426e-05 | norm: 0.0719 | dt: 181.20ms | tok/sec: 90419.65\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18290 | loss: 0.004789 | lr 6.2420e-05 | norm: 0.0623 | dt: 184.23ms | tok/sec: 88933.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18291 | loss: 0.004778 | lr 6.2414e-05 | norm: 0.0662 | dt: 191.59ms | tok/sec: 85514.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18292 | loss: 0.005154 | lr 6.2408e-05 | norm: 0.0833 | dt: 185.78ms | tok/sec: 88190.42\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18293 | loss: 0.005732 | lr 6.2402e-05 | norm: 0.0725 | dt: 184.14ms | tok/sec: 88975.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18294 | loss: 0.004007 | lr 6.2396e-05 | norm: 0.0526 | dt: 193.51ms | tok/sec: 84669.31\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18295 | loss: 0.004524 | lr 6.2389e-05 | norm: 0.0568 | dt: 183.84ms | tok/sec: 89120.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18296 | loss: 0.005555 | lr 6.2383e-05 | norm: 0.0718 | dt: 180.85ms | tok/sec: 90596.31\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18297 | loss: 0.005338 | lr 6.2377e-05 | norm: 0.0704 | dt: 188.89ms | tok/sec: 86736.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18298 | loss: 0.006798 | lr 6.2371e-05 | norm: 0.0713 | dt: 182.41ms | tok/sec: 89818.58\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18299 | loss: 0.004392 | lr 6.2365e-05 | norm: 0.0566 | dt: 179.53ms | tok/sec: 91261.41\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18300 | loss: 0.003944 | lr 6.2359e-05 | norm: 0.0511 | dt: 191.18ms | tok/sec: 85699.45\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18301 | loss: 0.005298 | lr 6.2353e-05 | norm: 0.0695 | dt: 180.08ms | tok/sec: 90980.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18302 | loss: 0.004345 | lr 6.2347e-05 | norm: 0.0639 | dt: 181.37ms | tok/sec: 90337.04\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18303 | loss: 0.003716 | lr 6.2341e-05 | norm: 0.0583 | dt: 191.34ms | tok/sec: 85625.45\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18304 | loss: 0.004574 | lr 6.2335e-05 | norm: 0.0696 | dt: 183.54ms | tok/sec: 89267.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18305 | loss: 0.019101 | lr 6.2329e-05 | norm: 0.3238 | dt: 184.47ms | tok/sec: 88816.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18306 | loss: 0.011883 | lr 6.2322e-05 | norm: 0.1855 | dt: 182.18ms | tok/sec: 89931.07\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18307 | loss: 0.011310 | lr 6.2316e-05 | norm: 0.1416 | dt: 193.27ms | tok/sec: 84773.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18308 | loss: 0.008368 | lr 6.2310e-05 | norm: 0.1171 | dt: 187.24ms | tok/sec: 87500.94\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18309 | loss: 0.010754 | lr 6.2304e-05 | norm: 0.1212 | dt: 180.79ms | tok/sec: 90623.91\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18310 | loss: 0.009786 | lr 6.2298e-05 | norm: 0.1476 | dt: 184.87ms | tok/sec: 88626.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18311 | loss: 0.010456 | lr 6.2292e-05 | norm: 0.1348 | dt: 185.12ms | tok/sec: 88503.22\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18312 | loss: 0.011174 | lr 6.2286e-05 | norm: 0.1502 | dt: 181.38ms | tok/sec: 90327.30\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18313 | loss: 0.007496 | lr 6.2280e-05 | norm: 0.1175 | dt: 179.58ms | tok/sec: 91237.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18314 | loss: 0.007355 | lr 6.2274e-05 | norm: 0.1041 | dt: 186.30ms | tok/sec: 87944.16\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18315 | loss: 0.010562 | lr 6.2268e-05 | norm: 0.1369 | dt: 185.73ms | tok/sec: 88214.99\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18316 | loss: 0.010259 | lr 6.2262e-05 | norm: 0.1311 | dt: 180.59ms | tok/sec: 90723.33\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18317 | loss: 0.011576 | lr 6.2256e-05 | norm: 0.1707 | dt: 192.10ms | tok/sec: 85287.51\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18318 | loss: 0.015042 | lr 6.2250e-05 | norm: 0.1993 | dt: 191.40ms | tok/sec: 85599.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18319 | loss: 0.009746 | lr 6.2245e-05 | norm: 0.1412 | dt: 179.80ms | tok/sec: 91124.90\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18320 | loss: 0.008405 | lr 6.2239e-05 | norm: 0.1109 | dt: 188.03ms | tok/sec: 87135.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18321 | loss: 0.007839 | lr 6.2233e-05 | norm: 0.1131 | dt: 185.68ms | tok/sec: 88239.68\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18322 | loss: 0.010056 | lr 6.2227e-05 | norm: 0.1241 | dt: 181.73ms | tok/sec: 90154.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18323 | loss: 0.011267 | lr 6.2221e-05 | norm: 0.1416 | dt: 188.07ms | tok/sec: 87118.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18324 | loss: 0.012265 | lr 6.2215e-05 | norm: 0.1782 | dt: 186.40ms | tok/sec: 87897.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18325 | loss: 0.013752 | lr 6.2209e-05 | norm: 0.2127 | dt: 179.79ms | tok/sec: 91127.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18326 | loss: 0.013833 | lr 6.2203e-05 | norm: 0.2273 | dt: 186.80ms | tok/sec: 87709.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18327 | loss: 0.014816 | lr 6.2197e-05 | norm: 0.2690 | dt: 184.73ms | tok/sec: 88692.15\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18328 | loss: 0.011354 | lr 6.2191e-05 | norm: 0.1870 | dt: 180.87ms | tok/sec: 90585.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18329 | loss: 0.012154 | lr 6.2185e-05 | norm: 0.1516 | dt: 183.98ms | tok/sec: 89052.70\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18330 | loss: 0.010102 | lr 6.2180e-05 | norm: 0.1601 | dt: 191.11ms | tok/sec: 85731.21\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18331 | loss: 0.009632 | lr 6.2174e-05 | norm: 0.1479 | dt: 181.08ms | tok/sec: 90479.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18332 | loss: 0.012481 | lr 6.2168e-05 | norm: 0.1352 | dt: 181.17ms | tok/sec: 90435.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18333 | loss: 0.011270 | lr 6.2162e-05 | norm: 0.1504 | dt: 192.49ms | tok/sec: 85113.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18334 | loss: 0.013172 | lr 6.2156e-05 | norm: 0.1844 | dt: 179.21ms | tok/sec: 91425.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18335 | loss: 0.013598 | lr 6.2150e-05 | norm: 0.2275 | dt: 179.45ms | tok/sec: 91302.15\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18336 | loss: 0.018218 | lr 6.2145e-05 | norm: 0.2574 | dt: 180.03ms | tok/sec: 91008.33\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18337 | loss: 0.016514 | lr 6.2139e-05 | norm: 0.3020 | dt: 179.45ms | tok/sec: 91301.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18338 | loss: 0.026510 | lr 6.2133e-05 | norm: 0.5406 | dt: 179.14ms | tok/sec: 91458.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18339 | loss: 0.016636 | lr 6.2127e-05 | norm: 0.2422 | dt: 178.58ms | tok/sec: 91747.20\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18340 | loss: 0.017086 | lr 6.2121e-05 | norm: 0.2358 | dt: 179.77ms | tok/sec: 91139.65\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18341 | loss: 0.017922 | lr 6.2116e-05 | norm: 0.2166 | dt: 179.76ms | tok/sec: 91142.43\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18342 | loss: 0.020026 | lr 6.2110e-05 | norm: 0.2097 | dt: 179.82ms | tok/sec: 91112.46\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18343 | loss: 0.017980 | lr 6.2104e-05 | norm: 0.2129 | dt: 179.41ms | tok/sec: 91322.90\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18344 | loss: 0.020760 | lr 6.2098e-05 | norm: 0.2840 | dt: 179.58ms | tok/sec: 91236.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18345 | loss: 0.019199 | lr 6.2093e-05 | norm: 0.2907 | dt: 179.38ms | tok/sec: 91338.92\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18346 | loss: 0.021405 | lr 6.2087e-05 | norm: 0.3523 | dt: 181.99ms | tok/sec: 90026.62\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18347 | loss: 0.013896 | lr 6.2081e-05 | norm: 0.2747 | dt: 181.75ms | tok/sec: 90146.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18348 | loss: 0.016781 | lr 6.2075e-05 | norm: 0.2323 | dt: 182.67ms | tok/sec: 89693.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18349 | loss: 0.011841 | lr 6.2070e-05 | norm: 0.1813 | dt: 180.89ms | tok/sec: 90573.62\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18350 | loss: 0.011807 | lr 6.2064e-05 | norm: 0.1700 | dt: 182.92ms | tok/sec: 89569.80\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18351 | loss: 0.018005 | lr 6.2058e-05 | norm: 0.1952 | dt: 182.27ms | tok/sec: 89890.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18352 | loss: 0.015703 | lr 6.2053e-05 | norm: 0.1913 | dt: 182.06ms | tok/sec: 89993.49\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18353 | loss: 0.043690 | lr 6.2047e-05 | norm: 0.5443 | dt: 182.26ms | tok/sec: 89892.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18354 | loss: 0.070208 | lr 6.2041e-05 | norm: 0.8217 | dt: 181.90ms | tok/sec: 90071.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18355 | loss: 0.043628 | lr 6.2036e-05 | norm: 0.2715 | dt: 184.05ms | tok/sec: 89017.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18356 | loss: 0.044273 | lr 6.2030e-05 | norm: 0.2566 | dt: 182.21ms | tok/sec: 89918.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18357 | loss: 0.031403 | lr 6.2024e-05 | norm: 0.2664 | dt: 180.51ms | tok/sec: 90765.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18358 | loss: 0.039316 | lr 6.2019e-05 | norm: 0.4368 | dt: 179.40ms | tok/sec: 91326.42\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18359 | loss: 0.020013 | lr 6.2013e-05 | norm: 0.2695 | dt: 181.95ms | tok/sec: 90047.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18360 | loss: 0.020936 | lr 6.2007e-05 | norm: 0.3096 | dt: 180.30ms | tok/sec: 90871.37\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18361 | loss: 0.017284 | lr 6.2002e-05 | norm: 0.2610 | dt: 180.01ms | tok/sec: 91015.68\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18362 | loss: 0.014998 | lr 6.1996e-05 | norm: 0.2041 | dt: 181.18ms | tok/sec: 90430.24\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18363 | loss: 0.011932 | lr 6.1991e-05 | norm: 0.1680 | dt: 182.12ms | tok/sec: 89961.21\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18364 | loss: 0.010967 | lr 6.1985e-05 | norm: 0.1260 | dt: 178.98ms | tok/sec: 91541.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18365 | loss: 0.010882 | lr 6.1979e-05 | norm: 0.1348 | dt: 181.00ms | tok/sec: 90517.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18366 | loss: 0.009400 | lr 6.1974e-05 | norm: 0.1150 | dt: 180.07ms | tok/sec: 90988.80\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18367 | loss: 0.010780 | lr 6.1968e-05 | norm: 0.1182 | dt: 179.34ms | tok/sec: 91355.80\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18368 | loss: 0.009707 | lr 6.1963e-05 | norm: 0.1329 | dt: 179.77ms | tok/sec: 91140.49\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18369 | loss: 0.009640 | lr 6.1957e-05 | norm: 0.1272 | dt: 179.07ms | tok/sec: 91495.92\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18370 | loss: 0.010388 | lr 6.1952e-05 | norm: 0.1478 | dt: 179.60ms | tok/sec: 91223.01\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18371 | loss: 0.011318 | lr 6.1946e-05 | norm: 0.1428 | dt: 179.89ms | tok/sec: 91076.11\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18372 | loss: 0.010815 | lr 6.1940e-05 | norm: 0.1269 | dt: 179.23ms | tok/sec: 91415.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18373 | loss: 0.010549 | lr 6.1935e-05 | norm: 0.1258 | dt: 178.99ms | tok/sec: 91534.80\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18374 | loss: 0.009834 | lr 6.1929e-05 | norm: 0.1329 | dt: 179.48ms | tok/sec: 91283.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18375 | loss: 0.009481 | lr 6.1924e-05 | norm: 0.1296 | dt: 178.45ms | tok/sec: 91810.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18376 | loss: 0.006458 | lr 6.1918e-05 | norm: 0.0932 | dt: 180.32ms | tok/sec: 90860.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18377 | loss: 0.006939 | lr 6.1913e-05 | norm: 0.0794 | dt: 181.03ms | tok/sec: 90504.91\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18378 | loss: 0.008031 | lr 6.1907e-05 | norm: 0.1061 | dt: 179.47ms | tok/sec: 91293.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18379 | loss: 0.007289 | lr 6.1902e-05 | norm: 0.0855 | dt: 186.01ms | tok/sec: 88079.65\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18380 | loss: 0.007825 | lr 6.1896e-05 | norm: 0.0916 | dt: 179.96ms | tok/sec: 91042.33\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18381 | loss: 0.012197 | lr 6.1891e-05 | norm: 0.1088 | dt: 178.72ms | tok/sec: 91671.80\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18382 | loss: 0.008282 | lr 6.1886e-05 | norm: 0.1215 | dt: 179.82ms | tok/sec: 91114.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18383 | loss: 0.014472 | lr 6.1880e-05 | norm: 0.1450 | dt: 179.56ms | tok/sec: 91244.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18384 | loss: 0.007362 | lr 6.1875e-05 | norm: 0.0888 | dt: 179.20ms | tok/sec: 91427.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18385 | loss: 0.008284 | lr 6.1869e-05 | norm: 0.0942 | dt: 178.86ms | tok/sec: 91600.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18386 | loss: 0.012201 | lr 6.1864e-05 | norm: 0.1125 | dt: 179.70ms | tok/sec: 91173.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18387 | loss: 0.008616 | lr 6.1858e-05 | norm: 0.0932 | dt: 179.87ms | tok/sec: 91085.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18388 | loss: 0.007192 | lr 6.1853e-05 | norm: 0.1032 | dt: 179.20ms | tok/sec: 91430.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18389 | loss: 0.009865 | lr 6.1848e-05 | norm: 0.1143 | dt: 179.71ms | tok/sec: 91167.22\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18390 | loss: 0.006969 | lr 6.1842e-05 | norm: 0.0835 | dt: 179.34ms | tok/sec: 91354.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18391 | loss: 0.007477 | lr 6.1837e-05 | norm: 0.0897 | dt: 178.81ms | tok/sec: 91628.05\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18392 | loss: 0.006294 | lr 6.1831e-05 | norm: 0.0817 | dt: 180.64ms | tok/sec: 90701.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18393 | loss: 0.009391 | lr 6.1826e-05 | norm: 0.0987 | dt: 180.34ms | tok/sec: 90849.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18394 | loss: 0.007546 | lr 6.1821e-05 | norm: 0.0946 | dt: 178.73ms | tok/sec: 91670.95\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18395 | loss: 0.006119 | lr 6.1815e-05 | norm: 0.0781 | dt: 178.72ms | tok/sec: 91672.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18396 | loss: 0.009969 | lr 6.1810e-05 | norm: 0.1122 | dt: 178.70ms | tok/sec: 91683.79\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18397 | loss: 0.006870 | lr 6.1805e-05 | norm: 0.0966 | dt: 178.87ms | tok/sec: 91599.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18398 | loss: 0.006202 | lr 6.1799e-05 | norm: 0.0852 | dt: 179.71ms | tok/sec: 91170.12\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18399 | loss: 0.006633 | lr 6.1794e-05 | norm: 0.0807 | dt: 178.26ms | tok/sec: 91909.05\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18400 | loss: 0.004176 | lr 6.1789e-05 | norm: 0.0651 | dt: 179.49ms | tok/sec: 91280.93\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18401 | loss: 0.004842 | lr 6.1783e-05 | norm: 0.0727 | dt: 178.11ms | tok/sec: 91989.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18402 | loss: 0.004567 | lr 6.1778e-05 | norm: 0.0834 | dt: 178.84ms | tok/sec: 91612.29\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18403 | loss: 0.006895 | lr 6.1773e-05 | norm: 0.0790 | dt: 184.41ms | tok/sec: 88844.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18404 | loss: 0.007164 | lr 6.1768e-05 | norm: 0.0928 | dt: 178.90ms | tok/sec: 91582.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18405 | loss: 0.004772 | lr 6.1762e-05 | norm: 0.0815 | dt: 179.49ms | tok/sec: 91281.41\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18406 | loss: 0.004725 | lr 6.1757e-05 | norm: 0.0669 | dt: 202.63ms | tok/sec: 80856.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18407 | loss: 0.008362 | lr 6.1752e-05 | norm: 0.1068 | dt: 179.49ms | tok/sec: 91282.99\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18408 | loss: 0.003442 | lr 6.1746e-05 | norm: 0.0568 | dt: 179.47ms | tok/sec: 91292.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18409 | loss: 0.003514 | lr 6.1741e-05 | norm: 0.0614 | dt: 180.60ms | tok/sec: 90720.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18410 | loss: 0.006258 | lr 6.1736e-05 | norm: 0.0901 | dt: 179.23ms | tok/sec: 91415.35\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18411 | loss: 0.003565 | lr 6.1731e-05 | norm: 0.0530 | dt: 182.24ms | tok/sec: 89901.07\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18412 | loss: 0.005243 | lr 6.1726e-05 | norm: 0.0754 | dt: 179.65ms | tok/sec: 91201.58\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18413 | loss: 0.004251 | lr 6.1720e-05 | norm: 0.0682 | dt: 181.88ms | tok/sec: 90083.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18414 | loss: 0.005085 | lr 6.1715e-05 | norm: 0.0980 | dt: 180.38ms | tok/sec: 90830.06\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18415 | loss: 0.004829 | lr 6.1710e-05 | norm: 0.0607 | dt: 181.51ms | tok/sec: 90265.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18416 | loss: 0.005889 | lr 6.1705e-05 | norm: 0.1071 | dt: 180.86ms | tok/sec: 90590.94\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18417 | loss: 0.004618 | lr 6.1700e-05 | norm: 0.0676 | dt: 181.96ms | tok/sec: 90040.06\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18418 | loss: 0.004251 | lr 6.1694e-05 | norm: 0.0729 | dt: 182.72ms | tok/sec: 89665.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18419 | loss: 0.004740 | lr 6.1689e-05 | norm: 0.0597 | dt: 182.65ms | tok/sec: 89699.58\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18420 | loss: 0.005074 | lr 6.1684e-05 | norm: 0.0543 | dt: 180.79ms | tok/sec: 90623.55\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18421 | loss: 0.004684 | lr 6.1679e-05 | norm: 0.0660 | dt: 183.34ms | tok/sec: 89363.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18422 | loss: 0.004916 | lr 6.1674e-05 | norm: 0.0890 | dt: 181.21ms | tok/sec: 90412.99\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18423 | loss: 0.005971 | lr 6.1669e-05 | norm: 0.0799 | dt: 181.47ms | tok/sec: 90284.58\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18424 | loss: 0.005033 | lr 6.1664e-05 | norm: 0.0720 | dt: 180.42ms | tok/sec: 90808.45\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18425 | loss: 0.005468 | lr 6.1658e-05 | norm: 0.0672 | dt: 179.58ms | tok/sec: 91232.70\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18426 | loss: 0.005409 | lr 6.1653e-05 | norm: 0.0638 | dt: 179.88ms | tok/sec: 91084.80\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18427 | loss: 0.003877 | lr 6.1648e-05 | norm: 0.0600 | dt: 179.57ms | tok/sec: 91240.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18428 | loss: 0.004810 | lr 6.1643e-05 | norm: 0.0550 | dt: 178.80ms | tok/sec: 91633.30\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18429 | loss: 0.004488 | lr 6.1638e-05 | norm: 0.0609 | dt: 179.84ms | tok/sec: 91102.43\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18430 | loss: 0.004212 | lr 6.1633e-05 | norm: 0.0687 | dt: 180.61ms | tok/sec: 90715.31\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18431 | loss: 0.005632 | lr 6.1628e-05 | norm: 0.0670 | dt: 178.83ms | tok/sec: 91618.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18432 | loss: 0.005706 | lr 6.1623e-05 | norm: 0.0872 | dt: 178.83ms | tok/sec: 91619.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18433 | loss: 0.006691 | lr 6.1618e-05 | norm: 0.0826 | dt: 180.90ms | tok/sec: 90566.94\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18434 | loss: 0.002567 | lr 6.1613e-05 | norm: 0.0413 | dt: 179.55ms | tok/sec: 91247.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18435 | loss: 0.004468 | lr 6.1608e-05 | norm: 0.0569 | dt: 179.52ms | tok/sec: 91266.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18436 | loss: 0.004906 | lr 6.1603e-05 | norm: 0.0679 | dt: 180.32ms | tok/sec: 90861.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18437 | loss: 0.004234 | lr 6.1598e-05 | norm: 0.0686 | dt: 179.11ms | tok/sec: 91474.97\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18438 | loss: 0.005727 | lr 6.1593e-05 | norm: 0.0657 | dt: 181.87ms | tok/sec: 90085.51\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18439 | loss: 0.005462 | lr 6.1588e-05 | norm: 0.0689 | dt: 179.97ms | tok/sec: 91037.26\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18440 | loss: 0.003313 | lr 6.1583e-05 | norm: 0.0699 | dt: 186.17ms | tok/sec: 88005.65\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18441 | loss: 0.005015 | lr 6.1578e-05 | norm: 0.0651 | dt: 180.02ms | tok/sec: 91009.77\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18442 | loss: 0.004362 | lr 6.1573e-05 | norm: 0.0561 | dt: 182.43ms | tok/sec: 89807.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18443 | loss: 0.004752 | lr 6.1568e-05 | norm: 0.0728 | dt: 179.84ms | tok/sec: 91104.49\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18444 | loss: 0.004176 | lr 6.1563e-05 | norm: 0.0621 | dt: 179.08ms | tok/sec: 91489.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18445 | loss: 0.003444 | lr 6.1558e-05 | norm: 0.0542 | dt: 178.87ms | tok/sec: 91596.78\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18446 | loss: 0.004528 | lr 6.1553e-05 | norm: 0.0792 | dt: 184.13ms | tok/sec: 88978.68\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18447 | loss: 0.003869 | lr 6.1548e-05 | norm: 0.0643 | dt: 179.14ms | tok/sec: 91459.39\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18448 | loss: 0.004161 | lr 6.1543e-05 | norm: 0.0529 | dt: 178.76ms | tok/sec: 91653.22\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18449 | loss: 0.002947 | lr 6.1538e-05 | norm: 0.0584 | dt: 180.62ms | tok/sec: 90711.00\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18450 | loss: 0.004193 | lr 6.1533e-05 | norm: 0.0454 | dt: 178.68ms | tok/sec: 91695.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18451 | loss: 0.004111 | lr 6.1528e-05 | norm: 0.0523 | dt: 180.09ms | tok/sec: 90977.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18452 | loss: 0.005773 | lr 6.1523e-05 | norm: 0.0643 | dt: 180.48ms | tok/sec: 90778.70\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18453 | loss: 0.004961 | lr 6.1518e-05 | norm: 0.0654 | dt: 179.81ms | tok/sec: 91120.43\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18454 | loss: 0.004576 | lr 6.1513e-05 | norm: 0.0672 | dt: 180.13ms | tok/sec: 90957.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18455 | loss: 0.005226 | lr 6.1509e-05 | norm: 0.0719 | dt: 180.63ms | tok/sec: 90705.73\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18456 | loss: 0.007301 | lr 6.1504e-05 | norm: 0.0696 | dt: 179.07ms | tok/sec: 91497.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18457 | loss: 0.004537 | lr 6.1499e-05 | norm: 0.0617 | dt: 181.58ms | tok/sec: 90232.06\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18458 | loss: 0.004928 | lr 6.1494e-05 | norm: 0.0676 | dt: 179.39ms | tok/sec: 91332.97\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18459 | loss: 0.004899 | lr 6.1489e-05 | norm: 0.0793 | dt: 179.32ms | tok/sec: 91368.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18460 | loss: 0.006746 | lr 6.1484e-05 | norm: 0.0742 | dt: 179.44ms | tok/sec: 91304.82\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18461 | loss: 0.004400 | lr 6.1479e-05 | norm: 0.0709 | dt: 179.79ms | tok/sec: 91127.68\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18462 | loss: 0.008647 | lr 6.1475e-05 | norm: 0.0918 | dt: 179.48ms | tok/sec: 91286.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18463 | loss: 0.010596 | lr 6.1470e-05 | norm: 0.1408 | dt: 180.64ms | tok/sec: 90699.74\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18464 | loss: 0.013175 | lr 6.1465e-05 | norm: 0.1639 | dt: 178.57ms | tok/sec: 91751.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18465 | loss: 0.009496 | lr 6.1460e-05 | norm: 0.1424 | dt: 179.80ms | tok/sec: 91123.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18466 | loss: 0.009020 | lr 6.1455e-05 | norm: 0.1498 | dt: 179.49ms | tok/sec: 91280.68\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18467 | loss: 0.008745 | lr 6.1451e-05 | norm: 0.1507 | dt: 179.49ms | tok/sec: 91280.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18468 | loss: 0.008704 | lr 6.1446e-05 | norm: 0.1233 | dt: 179.35ms | tok/sec: 91350.21\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18469 | loss: 0.006696 | lr 6.1441e-05 | norm: 0.0878 | dt: 179.29ms | tok/sec: 91383.01\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18470 | loss: 0.007623 | lr 6.1436e-05 | norm: 0.1098 | dt: 178.88ms | tok/sec: 91593.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18471 | loss: 0.008305 | lr 6.1432e-05 | norm: 0.1274 | dt: 179.51ms | tok/sec: 91269.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18472 | loss: 0.009911 | lr 6.1427e-05 | norm: 0.1805 | dt: 178.85ms | tok/sec: 91607.28\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18473 | loss: 0.009116 | lr 6.1422e-05 | norm: 0.1942 | dt: 179.90ms | tok/sec: 91072.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18474 | loss: 0.010225 | lr 6.1417e-05 | norm: 0.2064 | dt: 181.80ms | tok/sec: 90118.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18475 | loss: 0.007600 | lr 6.1413e-05 | norm: 0.1263 | dt: 179.24ms | tok/sec: 91406.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18476 | loss: 0.009922 | lr 6.1408e-05 | norm: 0.1197 | dt: 180.97ms | tok/sec: 90534.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18477 | loss: 0.008199 | lr 6.1403e-05 | norm: 0.1004 | dt: 181.78ms | tok/sec: 90133.24\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18478 | loss: 0.018723 | lr 6.1398e-05 | norm: 0.2549 | dt: 180.88ms | tok/sec: 90578.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18479 | loss: 0.006246 | lr 6.1394e-05 | norm: 0.0799 | dt: 181.47ms | tok/sec: 90284.58\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18480 | loss: 0.004968 | lr 6.1389e-05 | norm: 0.1085 | dt: 181.54ms | tok/sec: 90248.42\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18481 | loss: 0.006934 | lr 6.1384e-05 | norm: 0.0819 | dt: 181.31ms | tok/sec: 90362.46\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18482 | loss: 0.006530 | lr 6.1380e-05 | norm: 0.0923 | dt: 180.50ms | tok/sec: 90769.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18483 | loss: 0.005714 | lr 6.1375e-05 | norm: 0.0760 | dt: 180.24ms | tok/sec: 90901.78\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18484 | loss: 0.005761 | lr 6.1370e-05 | norm: 0.0838 | dt: 182.94ms | tok/sec: 89560.23\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18485 | loss: 0.006753 | lr 6.1366e-05 | norm: 0.0901 | dt: 183.50ms | tok/sec: 89288.51\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18486 | loss: 0.006867 | lr 6.1361e-05 | norm: 0.0778 | dt: 183.62ms | tok/sec: 89225.56\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18487 | loss: 0.009132 | lr 6.1356e-05 | norm: 0.1281 | dt: 180.62ms | tok/sec: 90708.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18488 | loss: 0.008864 | lr 6.1352e-05 | norm: 0.1003 | dt: 178.74ms | tok/sec: 91665.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18489 | loss: 0.007657 | lr 6.1347e-05 | norm: 0.0987 | dt: 181.53ms | tok/sec: 90255.41\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18490 | loss: 0.006754 | lr 6.1343e-05 | norm: 0.0757 | dt: 180.61ms | tok/sec: 90713.15\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18491 | loss: 0.007537 | lr 6.1338e-05 | norm: 0.0916 | dt: 179.57ms | tok/sec: 91239.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18492 | loss: 0.007324 | lr 6.1333e-05 | norm: 0.0841 | dt: 179.29ms | tok/sec: 91382.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18493 | loss: 0.007521 | lr 6.1329e-05 | norm: 0.0880 | dt: 179.72ms | tok/sec: 91162.98\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18494 | loss: 0.006459 | lr 6.1324e-05 | norm: 0.0929 | dt: 179.77ms | tok/sec: 91139.04\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18495 | loss: 0.006653 | lr 6.1320e-05 | norm: 0.1157 | dt: 178.79ms | tok/sec: 91640.26\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18496 | loss: 0.005375 | lr 6.1315e-05 | norm: 0.0648 | dt: 178.95ms | tok/sec: 91556.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18497 | loss: 0.006278 | lr 6.1311e-05 | norm: 0.0880 | dt: 179.72ms | tok/sec: 91166.25\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18498 | loss: 0.021973 | lr 6.1306e-05 | norm: 0.2497 | dt: 179.60ms | tok/sec: 91222.76\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18499 | loss: 0.004868 | lr 6.1302e-05 | norm: 0.0611 | dt: 179.46ms | tok/sec: 91296.45\n",
      "validation loss: 0.1326\n",
      "rank 0 sample 0: Smoking is the major risk factor for heart disease.<|endoftext|> like find syndromes also may be at risk factors those of<|endoftext|>, such as:      -  deep<|endoftext|> thrombosis   -  Heartburn is a risk factor for developing aortic valve disease or<|endoftext|> that is\n",
      "rank 0 sample 1: Smoking is the major risk factor for mostul<|endoftext|>.<|endoftext|> or long-term smoking can also be associated with a number of risk factors. These factors may increase the risk of secondhand smoke, especially in younger than 70.<|endoftext|> with a history of breast cancer in a person who has had no history of the disorder\n",
      "rank 0 sample 2: Smoking is the major risk factor for most cases of<|endoftext|> dystrophy. Other factors include exposure to hip replacement, physical therapy, and certain medications. The risk of<|endoftext|> dystrophy is between ages 10 and 30, but may be high in some cases.  The SLC There are two forms of<|endoftext|> dy\n",
      "rank 0 sample 3: Smoking is the major risk factor for heart disease.<|endoftext|>Q: What are the treatments for Heart Disease ? A: These resources address the diagnosis or management of heart failure:  -<|endoftext|><|endoftext|><|endoftext|>: Cholesterol provides along with a doctors and family doctor stages.  - The goals of treating childhood tend to grow,\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18500 | loss: 0.014549 | lr 6.1297e-05 | norm: 0.1715 | dt: 3640.60ms | tok/sec: 4500.35\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18501 | loss: 0.005754 | lr 6.1292e-05 | norm: 0.0773 | dt: 183.20ms | tok/sec: 89432.14\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18502 | loss: 0.008416 | lr 6.1288e-05 | norm: 0.0841 | dt: 180.28ms | tok/sec: 90878.46\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18503 | loss: 0.008789 | lr 6.1283e-05 | norm: 0.1133 | dt: 179.65ms | tok/sec: 91200.97\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18504 | loss: 0.008027 | lr 6.1279e-05 | norm: 0.0948 | dt: 179.40ms | tok/sec: 91326.78\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18505 | loss: 0.010405 | lr 6.1274e-05 | norm: 0.1258 | dt: 179.10ms | tok/sec: 91479.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18506 | loss: 0.009131 | lr 6.1270e-05 | norm: 0.1504 | dt: 179.26ms | tok/sec: 91400.51\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18507 | loss: 0.005569 | lr 6.1266e-05 | norm: 0.0747 | dt: 179.60ms | tok/sec: 91224.94\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18508 | loss: 0.011607 | lr 6.1261e-05 | norm: 0.1181 | dt: 179.17ms | tok/sec: 91442.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18509 | loss: 0.015246 | lr 6.1257e-05 | norm: 0.1664 | dt: 178.32ms | tok/sec: 91877.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18510 | loss: 0.010729 | lr 6.1252e-05 | norm: 0.1481 | dt: 178.66ms | tok/sec: 91705.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18511 | loss: 0.010407 | lr 6.1248e-05 | norm: 0.1363 | dt: 178.47ms | tok/sec: 91800.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18512 | loss: 0.010888 | lr 6.1243e-05 | norm: 0.1379 | dt: 178.72ms | tok/sec: 91673.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18513 | loss: 0.008739 | lr 6.1239e-05 | norm: 0.1165 | dt: 179.68ms | tok/sec: 91184.27\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18514 | loss: 0.008618 | lr 6.1234e-05 | norm: 0.1112 | dt: 180.42ms | tok/sec: 90811.45\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18515 | loss: 0.006851 | lr 6.1230e-05 | norm: 0.1020 | dt: 183.05ms | tok/sec: 89505.06\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18516 | loss: 0.007930 | lr 6.1226e-05 | norm: 0.1065 | dt: 180.72ms | tok/sec: 90661.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18517 | loss: 0.010677 | lr 6.1221e-05 | norm: 0.1403 | dt: 180.33ms | tok/sec: 90856.72\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18518 | loss: 0.010973 | lr 6.1217e-05 | norm: 0.1211 | dt: 180.95ms | tok/sec: 90544.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18519 | loss: 0.009245 | lr 6.1212e-05 | norm: 0.1508 | dt: 180.92ms | tok/sec: 90560.97\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18520 | loss: 0.008500 | lr 6.1208e-05 | norm: 0.1409 | dt: 179.93ms | tok/sec: 91056.56\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18521 | loss: 0.005929 | lr 6.1204e-05 | norm: 0.0963 | dt: 179.76ms | tok/sec: 91145.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18522 | loss: 0.005287 | lr 6.1199e-05 | norm: 0.0888 | dt: 180.13ms | tok/sec: 90956.65\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18523 | loss: 0.005471 | lr 6.1195e-05 | norm: 0.1092 | dt: 181.34ms | tok/sec: 90348.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18524 | loss: 0.006650 | lr 6.1191e-05 | norm: 0.1051 | dt: 182.89ms | tok/sec: 89584.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18525 | loss: 0.004963 | lr 6.1186e-05 | norm: 0.0826 | dt: 181.42ms | tok/sec: 90310.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18526 | loss: 0.004657 | lr 6.1182e-05 | norm: 0.0821 | dt: 182.19ms | tok/sec: 89928.71\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18527 | loss: 0.006317 | lr 6.1178e-05 | norm: 0.0792 | dt: 178.71ms | tok/sec: 91678.16\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18528 | loss: 0.004151 | lr 6.1173e-05 | norm: 0.0701 | dt: 178.36ms | tok/sec: 91856.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18529 | loss: 0.004365 | lr 6.1169e-05 | norm: 0.0697 | dt: 178.14ms | tok/sec: 91974.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18530 | loss: 0.004825 | lr 6.1165e-05 | norm: 0.0797 | dt: 184.09ms | tok/sec: 88999.19\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18531 | loss: 0.005827 | lr 6.1161e-05 | norm: 0.0829 | dt: 179.17ms | tok/sec: 91445.76\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18532 | loss: 0.007638 | lr 6.1156e-05 | norm: 0.1205 | dt: 178.51ms | tok/sec: 91779.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18533 | loss: 0.005949 | lr 6.1152e-05 | norm: 0.0732 | dt: 178.52ms | tok/sec: 91777.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18534 | loss: 0.005746 | lr 6.1148e-05 | norm: 0.0817 | dt: 178.96ms | tok/sec: 91550.29\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18535 | loss: 0.006099 | lr 6.1144e-05 | norm: 0.1080 | dt: 179.30ms | tok/sec: 91375.72\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18536 | loss: 0.005639 | lr 6.1139e-05 | norm: 0.0868 | dt: 179.63ms | tok/sec: 91211.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18537 | loss: 0.005085 | lr 6.1135e-05 | norm: 0.1053 | dt: 179.03ms | tok/sec: 91513.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18538 | loss: 0.006260 | lr 6.1131e-05 | norm: 0.1466 | dt: 179.58ms | tok/sec: 91235.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18539 | loss: 0.006426 | lr 6.1127e-05 | norm: 0.0984 | dt: 178.88ms | tok/sec: 91592.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18540 | loss: 0.006666 | lr 6.1122e-05 | norm: 0.0778 | dt: 179.94ms | tok/sec: 91051.98\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18541 | loss: 0.005561 | lr 6.1118e-05 | norm: 0.0769 | dt: 179.79ms | tok/sec: 91130.22\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18542 | loss: 0.005934 | lr 6.1114e-05 | norm: 0.0890 | dt: 181.43ms | tok/sec: 90307.01\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18543 | loss: 0.006265 | lr 6.1110e-05 | norm: 0.0984 | dt: 178.90ms | tok/sec: 91583.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18544 | loss: 0.003974 | lr 6.1106e-05 | norm: 0.0558 | dt: 179.62ms | tok/sec: 91212.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18545 | loss: 0.004839 | lr 6.1101e-05 | norm: 0.0766 | dt: 179.07ms | tok/sec: 91496.65\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18546 | loss: 0.006134 | lr 6.1097e-05 | norm: 0.0932 | dt: 181.94ms | tok/sec: 90053.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18547 | loss: 0.005180 | lr 6.1093e-05 | norm: 0.0676 | dt: 184.04ms | tok/sec: 89024.21\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18548 | loss: 0.005536 | lr 6.1089e-05 | norm: 0.0659 | dt: 179.75ms | tok/sec: 91150.77\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18549 | loss: 0.003056 | lr 6.1085e-05 | norm: 0.0568 | dt: 181.99ms | tok/sec: 90029.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18550 | loss: 0.004710 | lr 6.1081e-05 | norm: 0.0722 | dt: 179.86ms | tok/sec: 91093.74\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18551 | loss: 0.004276 | lr 6.1077e-05 | norm: 0.0700 | dt: 182.31ms | tok/sec: 89870.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18552 | loss: 0.004309 | lr 6.1072e-05 | norm: 0.0671 | dt: 181.75ms | tok/sec: 90146.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18553 | loss: 0.003656 | lr 6.1068e-05 | norm: 0.0542 | dt: 180.64ms | tok/sec: 90702.14\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18554 | loss: 0.005590 | lr 6.1064e-05 | norm: 0.0893 | dt: 182.57ms | tok/sec: 89740.93\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18555 | loss: 0.004784 | lr 6.1060e-05 | norm: 0.0784 | dt: 179.70ms | tok/sec: 91175.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18556 | loss: 0.003816 | lr 6.1056e-05 | norm: 0.0555 | dt: 184.64ms | tok/sec: 88733.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18557 | loss: 0.004137 | lr 6.1052e-05 | norm: 0.0687 | dt: 184.74ms | tok/sec: 88684.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18558 | loss: 0.005064 | lr 6.1048e-05 | norm: 0.0838 | dt: 182.98ms | tok/sec: 89537.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18559 | loss: 0.006345 | lr 6.1044e-05 | norm: 0.0786 | dt: 186.33ms | tok/sec: 87928.29\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18560 | loss: 0.004971 | lr 6.1040e-05 | norm: 0.0683 | dt: 178.91ms | tok/sec: 91574.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18561 | loss: 0.005065 | lr 6.1036e-05 | norm: 0.0775 | dt: 183.58ms | tok/sec: 89246.07\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18562 | loss: 0.004374 | lr 6.1032e-05 | norm: 0.0716 | dt: 180.27ms | tok/sec: 90883.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18563 | loss: 0.004969 | lr 6.1028e-05 | norm: 0.0717 | dt: 181.55ms | tok/sec: 90246.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18564 | loss: 0.004239 | lr 6.1024e-05 | norm: 0.0744 | dt: 180.12ms | tok/sec: 90961.95\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18565 | loss: 0.005227 | lr 6.1020e-05 | norm: 0.0682 | dt: 179.15ms | tok/sec: 91453.06\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18566 | loss: 0.003797 | lr 6.1016e-05 | norm: 0.0671 | dt: 186.10ms | tok/sec: 88039.70\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18567 | loss: 0.005594 | lr 6.1012e-05 | norm: 0.0742 | dt: 180.11ms | tok/sec: 90968.45\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18568 | loss: 0.003366 | lr 6.1008e-05 | norm: 0.0637 | dt: 187.91ms | tok/sec: 87189.20\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18569 | loss: 0.005685 | lr 6.1004e-05 | norm: 0.0695 | dt: 181.78ms | tok/sec: 90129.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18570 | loss: 0.005862 | lr 6.1000e-05 | norm: 0.0935 | dt: 186.30ms | tok/sec: 87942.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18571 | loss: 0.005440 | lr 6.0996e-05 | norm: 0.0745 | dt: 180.43ms | tok/sec: 90804.25\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18572 | loss: 0.003069 | lr 6.0992e-05 | norm: 0.0508 | dt: 184.26ms | tok/sec: 88915.93\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18573 | loss: 0.008300 | lr 6.0988e-05 | norm: 0.1004 | dt: 180.33ms | tok/sec: 90855.27\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18574 | loss: 0.004386 | lr 6.0984e-05 | norm: 0.0668 | dt: 181.78ms | tok/sec: 90131.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18575 | loss: 0.004340 | lr 6.0980e-05 | norm: 0.0654 | dt: 185.39ms | tok/sec: 88373.70\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18576 | loss: 0.005041 | lr 6.0976e-05 | norm: 0.0775 | dt: 180.60ms | tok/sec: 90719.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18577 | loss: 0.005293 | lr 6.0972e-05 | norm: 0.0730 | dt: 188.53ms | tok/sec: 86904.40\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18578 | loss: 0.004870 | lr 6.0968e-05 | norm: 0.0765 | dt: 180.47ms | tok/sec: 90787.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18579 | loss: 0.004773 | lr 6.0964e-05 | norm: 0.0671 | dt: 181.50ms | tok/sec: 90268.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18580 | loss: 0.005258 | lr 6.0960e-05 | norm: 0.0849 | dt: 182.52ms | tok/sec: 89764.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18581 | loss: 0.003711 | lr 6.0956e-05 | norm: 0.0688 | dt: 184.87ms | tok/sec: 88623.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18582 | loss: 0.005431 | lr 6.0953e-05 | norm: 0.0908 | dt: 180.96ms | tok/sec: 90540.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18583 | loss: 0.004758 | lr 6.0949e-05 | norm: 0.0759 | dt: 185.00ms | tok/sec: 88564.24\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18584 | loss: 0.002999 | lr 6.0945e-05 | norm: 0.0557 | dt: 182.71ms | tok/sec: 89673.24\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18585 | loss: 0.003436 | lr 6.0941e-05 | norm: 0.0724 | dt: 184.26ms | tok/sec: 88918.12\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18586 | loss: 0.004753 | lr 6.0937e-05 | norm: 0.0705 | dt: 183.21ms | tok/sec: 89427.72\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18587 | loss: 0.004844 | lr 6.0933e-05 | norm: 0.0692 | dt: 180.32ms | tok/sec: 90858.28\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18588 | loss: 0.004412 | lr 6.0929e-05 | norm: 0.0682 | dt: 188.48ms | tok/sec: 86928.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18589 | loss: 0.004552 | lr 6.0926e-05 | norm: 0.0705 | dt: 184.57ms | tok/sec: 88769.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18590 | loss: 0.003336 | lr 6.0922e-05 | norm: 0.0563 | dt: 186.09ms | tok/sec: 88043.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18591 | loss: 0.006308 | lr 6.0918e-05 | norm: 0.0834 | dt: 188.85ms | tok/sec: 86758.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18592 | loss: 0.004277 | lr 6.0914e-05 | norm: 0.0594 | dt: 182.17ms | tok/sec: 89935.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18593 | loss: 0.005680 | lr 6.0910e-05 | norm: 0.0823 | dt: 180.01ms | tok/sec: 91018.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18594 | loss: 0.005195 | lr 6.0907e-05 | norm: 0.0609 | dt: 185.17ms | tok/sec: 88478.72\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18595 | loss: 0.004475 | lr 6.0903e-05 | norm: 0.0705 | dt: 182.51ms | tok/sec: 89769.07\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18596 | loss: 0.005065 | lr 6.0899e-05 | norm: 0.0582 | dt: 179.06ms | tok/sec: 91497.99\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18597 | loss: 0.004913 | lr 6.0895e-05 | norm: 0.0768 | dt: 179.64ms | tok/sec: 91204.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18598 | loss: 0.004405 | lr 6.0892e-05 | norm: 0.0577 | dt: 184.06ms | tok/sec: 89014.41\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18599 | loss: 0.003611 | lr 6.0888e-05 | norm: 0.0592 | dt: 181.47ms | tok/sec: 90286.24\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18600 | loss: 0.003979 | lr 6.0884e-05 | norm: 0.0686 | dt: 182.01ms | tok/sec: 90017.06\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18601 | loss: 0.004573 | lr 6.0880e-05 | norm: 0.0635 | dt: 181.51ms | tok/sec: 90266.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18602 | loss: 0.003002 | lr 6.0877e-05 | norm: 0.0500 | dt: 179.32ms | tok/sec: 91368.19\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18603 | loss: 0.006080 | lr 6.0873e-05 | norm: 0.0773 | dt: 181.19ms | tok/sec: 90425.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18604 | loss: 0.004825 | lr 6.0869e-05 | norm: 0.0821 | dt: 179.45ms | tok/sec: 91299.60\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18605 | loss: 0.003771 | lr 6.0865e-05 | norm: 0.0525 | dt: 183.13ms | tok/sec: 89467.77\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18606 | loss: 0.010052 | lr 6.0862e-05 | norm: 0.1356 | dt: 180.36ms | tok/sec: 90838.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18607 | loss: 0.005090 | lr 6.0858e-05 | norm: 0.0682 | dt: 182.17ms | tok/sec: 89937.42\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18608 | loss: 0.003282 | lr 6.0854e-05 | norm: 0.0621 | dt: 180.55ms | tok/sec: 90744.90\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18609 | loss: 0.003392 | lr 6.0851e-05 | norm: 0.0498 | dt: 182.07ms | tok/sec: 89988.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18610 | loss: 0.003840 | lr 6.0847e-05 | norm: 0.0636 | dt: 180.28ms | tok/sec: 90879.91\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18611 | loss: 0.004142 | lr 6.0843e-05 | norm: 0.0683 | dt: 179.05ms | tok/sec: 91504.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18612 | loss: 0.004922 | lr 6.0840e-05 | norm: 0.0621 | dt: 183.15ms | tok/sec: 89456.82\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18613 | loss: 0.002976 | lr 6.0836e-05 | norm: 0.0590 | dt: 178.31ms | tok/sec: 91886.07\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18614 | loss: 0.005385 | lr 6.0833e-05 | norm: 0.0666 | dt: 178.68ms | tok/sec: 91696.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18615 | loss: 0.004901 | lr 6.0829e-05 | norm: 0.0643 | dt: 180.43ms | tok/sec: 90806.41\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18616 | loss: 0.005514 | lr 6.0825e-05 | norm: 0.0758 | dt: 178.76ms | tok/sec: 91653.95\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18617 | loss: 0.005874 | lr 6.0822e-05 | norm: 0.0753 | dt: 179.40ms | tok/sec: 91325.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18618 | loss: 0.004590 | lr 6.0818e-05 | norm: 0.0606 | dt: 178.63ms | tok/sec: 91719.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18619 | loss: 0.004180 | lr 6.0814e-05 | norm: 0.0663 | dt: 180.92ms | tok/sec: 90557.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18620 | loss: 0.003931 | lr 6.0811e-05 | norm: 0.0522 | dt: 178.48ms | tok/sec: 91798.43\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18621 | loss: 0.006743 | lr 6.0807e-05 | norm: 0.0681 | dt: 179.92ms | tok/sec: 91062.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18622 | loss: 0.004965 | lr 6.0804e-05 | norm: 0.0773 | dt: 179.16ms | tok/sec: 91449.78\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18623 | loss: 0.005219 | lr 6.0800e-05 | norm: 0.0636 | dt: 179.39ms | tok/sec: 91330.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18624 | loss: 0.005586 | lr 6.0797e-05 | norm: 0.0693 | dt: 179.53ms | tok/sec: 91259.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18625 | loss: 0.005004 | lr 6.0793e-05 | norm: 0.0570 | dt: 179.04ms | tok/sec: 91509.20\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18626 | loss: 0.004109 | lr 6.0790e-05 | norm: 0.0705 | dt: 180.11ms | tok/sec: 90966.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18627 | loss: 0.003129 | lr 6.0786e-05 | norm: 0.0509 | dt: 178.05ms | tok/sec: 92021.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18628 | loss: 0.004386 | lr 6.0783e-05 | norm: 0.0661 | dt: 179.05ms | tok/sec: 91507.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18629 | loss: 0.006011 | lr 6.0779e-05 | norm: 0.0748 | dt: 178.03ms | tok/sec: 92028.56\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18630 | loss: 0.003453 | lr 6.0776e-05 | norm: 0.0566 | dt: 178.27ms | tok/sec: 91904.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18631 | loss: 0.005585 | lr 6.0772e-05 | norm: 0.0660 | dt: 180.48ms | tok/sec: 90781.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18632 | loss: 0.003902 | lr 6.0769e-05 | norm: 0.0615 | dt: 179.61ms | tok/sec: 91219.37\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18633 | loss: 0.006395 | lr 6.0765e-05 | norm: 0.0899 | dt: 179.37ms | tok/sec: 91340.14\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18634 | loss: 0.004961 | lr 6.0762e-05 | norm: 0.0703 | dt: 178.63ms | tok/sec: 91720.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18635 | loss: 0.005448 | lr 6.0758e-05 | norm: 0.0738 | dt: 178.64ms | tok/sec: 91713.04\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18636 | loss: 0.004051 | lr 6.0755e-05 | norm: 0.0656 | dt: 183.39ms | tok/sec: 89340.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18637 | loss: 0.004294 | lr 6.0751e-05 | norm: 0.0578 | dt: 180.05ms | tok/sec: 90996.76\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18638 | loss: 0.004499 | lr 6.0748e-05 | norm: 0.0635 | dt: 179.85ms | tok/sec: 91097.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18639 | loss: 0.004392 | lr 6.0744e-05 | norm: 0.0682 | dt: 179.11ms | tok/sec: 91474.24\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18640 | loss: 0.013303 | lr 6.0741e-05 | norm: 0.1484 | dt: 178.82ms | tok/sec: 91623.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18641 | loss: 0.009252 | lr 6.0737e-05 | norm: 0.1337 | dt: 180.41ms | tok/sec: 90813.73\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18642 | loss: 0.010335 | lr 6.0734e-05 | norm: 0.1449 | dt: 179.75ms | tok/sec: 91146.78\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18643 | loss: 0.010617 | lr 6.0731e-05 | norm: 0.1449 | dt: 179.65ms | tok/sec: 91199.40\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18644 | loss: 0.010418 | lr 6.0727e-05 | norm: 0.1606 | dt: 179.24ms | tok/sec: 91409.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18645 | loss: 0.009511 | lr 6.0724e-05 | norm: 0.1592 | dt: 181.50ms | tok/sec: 90268.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18646 | loss: 0.008596 | lr 6.0721e-05 | norm: 0.1236 | dt: 180.95ms | tok/sec: 90544.62\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18647 | loss: 0.015293 | lr 6.0717e-05 | norm: 0.1800 | dt: 179.74ms | tok/sec: 91153.19\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18648 | loss: 0.009143 | lr 6.0714e-05 | norm: 0.1263 | dt: 179.53ms | tok/sec: 91259.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18649 | loss: 0.009462 | lr 6.0710e-05 | norm: 0.1281 | dt: 179.91ms | tok/sec: 91067.42\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18650 | loss: 0.009693 | lr 6.0707e-05 | norm: 0.1200 | dt: 180.03ms | tok/sec: 91007.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18651 | loss: 0.009695 | lr 6.0704e-05 | norm: 0.1545 | dt: 181.01ms | tok/sec: 90516.00\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18652 | loss: 0.009146 | lr 6.0700e-05 | norm: 0.1330 | dt: 185.36ms | tok/sec: 88389.95\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18653 | loss: 0.015286 | lr 6.0697e-05 | norm: 0.1849 | dt: 183.63ms | tok/sec: 89221.05\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18654 | loss: 0.007637 | lr 6.0694e-05 | norm: 0.1097 | dt: 182.66ms | tok/sec: 89696.65\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18655 | loss: 0.008720 | lr 6.0690e-05 | norm: 0.1154 | dt: 182.63ms | tok/sec: 89711.99\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18656 | loss: 0.009908 | lr 6.0687e-05 | norm: 0.1713 | dt: 182.14ms | tok/sec: 89951.20\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18657 | loss: 0.010196 | lr 6.0684e-05 | norm: 0.1900 | dt: 180.17ms | tok/sec: 90936.91\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18658 | loss: 0.009767 | lr 6.0681e-05 | norm: 0.1483 | dt: 180.14ms | tok/sec: 90953.76\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18659 | loss: 0.012097 | lr 6.0677e-05 | norm: 0.1616 | dt: 180.40ms | tok/sec: 90818.05\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18660 | loss: 0.009626 | lr 6.0674e-05 | norm: 0.1466 | dt: 179.61ms | tok/sec: 91222.16\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18661 | loss: 0.012581 | lr 6.0671e-05 | norm: 0.1932 | dt: 179.37ms | tok/sec: 91340.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18662 | loss: 0.010582 | lr 6.0668e-05 | norm: 0.1417 | dt: 178.54ms | tok/sec: 91764.72\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18663 | loss: 0.011323 | lr 6.0664e-05 | norm: 0.1579 | dt: 179.09ms | tok/sec: 91484.23\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18664 | loss: 0.011685 | lr 6.0661e-05 | norm: 0.1607 | dt: 178.33ms | tok/sec: 91876.73\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18665 | loss: 0.015959 | lr 6.0658e-05 | norm: 0.1764 | dt: 179.19ms | tok/sec: 91435.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18666 | loss: 0.014526 | lr 6.0655e-05 | norm: 0.2222 | dt: 179.23ms | tok/sec: 91415.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18667 | loss: 0.013565 | lr 6.0651e-05 | norm: 0.1881 | dt: 178.33ms | tok/sec: 91873.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18668 | loss: 0.012226 | lr 6.0648e-05 | norm: 0.1736 | dt: 179.69ms | tok/sec: 91180.76\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18669 | loss: 0.010547 | lr 6.0645e-05 | norm: 0.1283 | dt: 179.13ms | tok/sec: 91466.21\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18670 | loss: 0.011515 | lr 6.0642e-05 | norm: 0.1537 | dt: 179.86ms | tok/sec: 91094.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18671 | loss: 0.012669 | lr 6.0639e-05 | norm: 0.1919 | dt: 179.17ms | tok/sec: 91443.45\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18672 | loss: 0.011744 | lr 6.0635e-05 | norm: 0.1658 | dt: 178.80ms | tok/sec: 91632.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18673 | loss: 0.016329 | lr 6.0632e-05 | norm: 0.1619 | dt: 180.80ms | tok/sec: 90621.04\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18674 | loss: 0.015295 | lr 6.0629e-05 | norm: 0.2104 | dt: 181.50ms | tok/sec: 90271.30\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18675 | loss: 0.013319 | lr 6.0626e-05 | norm: 0.2210 | dt: 181.85ms | tok/sec: 90095.43\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18676 | loss: 0.016614 | lr 6.0623e-05 | norm: 0.2540 | dt: 179.12ms | tok/sec: 91470.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18677 | loss: 0.015316 | lr 6.0620e-05 | norm: 0.2451 | dt: 178.19ms | tok/sec: 91944.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18678 | loss: 0.021984 | lr 6.0617e-05 | norm: 0.3125 | dt: 179.51ms | tok/sec: 91271.71\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18679 | loss: 0.014324 | lr 6.0613e-05 | norm: 0.2084 | dt: 179.53ms | tok/sec: 91261.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18680 | loss: 0.017419 | lr 6.0610e-05 | norm: 0.2343 | dt: 180.87ms | tok/sec: 90586.04\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18681 | loss: 0.016219 | lr 6.0607e-05 | norm: 0.1871 | dt: 179.69ms | tok/sec: 91177.74\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18682 | loss: 0.017648 | lr 6.0604e-05 | norm: 0.1854 | dt: 178.64ms | tok/sec: 91714.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18683 | loss: 0.013828 | lr 6.0601e-05 | norm: 0.1998 | dt: 178.51ms | tok/sec: 91780.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18684 | loss: 0.015303 | lr 6.0598e-05 | norm: 0.2445 | dt: 179.47ms | tok/sec: 91290.99\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18685 | loss: 0.013943 | lr 6.0595e-05 | norm: 0.2115 | dt: 178.76ms | tok/sec: 91652.24\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18686 | loss: 0.013032 | lr 6.0592e-05 | norm: 0.2203 | dt: 182.07ms | tok/sec: 89989.01\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18687 | loss: 0.011078 | lr 6.0589e-05 | norm: 0.1723 | dt: 179.05ms | tok/sec: 91505.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18688 | loss: 0.013328 | lr 6.0586e-05 | norm: 0.1943 | dt: 179.21ms | tok/sec: 91421.31\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18689 | loss: 0.005559 | lr 6.0583e-05 | norm: 0.0801 | dt: 179.48ms | tok/sec: 91286.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18690 | loss: 0.004620 | lr 6.0580e-05 | norm: 0.0580 | dt: 178.84ms | tok/sec: 91611.56\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18691 | loss: 0.006386 | lr 6.0577e-05 | norm: 0.0950 | dt: 179.22ms | tok/sec: 91419.12\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18692 | loss: 0.007367 | lr 6.0574e-05 | norm: 0.0958 | dt: 178.71ms | tok/sec: 91677.80\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18693 | loss: 0.006216 | lr 6.0571e-05 | norm: 0.0982 | dt: 179.46ms | tok/sec: 91294.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18694 | loss: 0.006941 | lr 6.0568e-05 | norm: 0.0964 | dt: 179.46ms | tok/sec: 91294.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18695 | loss: 0.007215 | lr 6.0565e-05 | norm: 0.1024 | dt: 179.17ms | tok/sec: 91442.60\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18696 | loss: 0.006803 | lr 6.0562e-05 | norm: 0.0975 | dt: 180.24ms | tok/sec: 90898.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18697 | loss: 0.008910 | lr 6.0559e-05 | norm: 0.1076 | dt: 182.96ms | tok/sec: 89551.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18698 | loss: 0.004860 | lr 6.0556e-05 | norm: 0.0716 | dt: 179.91ms | tok/sec: 91068.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18699 | loss: 0.004431 | lr 6.0553e-05 | norm: 0.0586 | dt: 180.28ms | tok/sec: 90880.27\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18700 | loss: 0.005190 | lr 6.0550e-05 | norm: 0.0708 | dt: 179.25ms | tok/sec: 91404.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18701 | loss: 0.004782 | lr 6.0547e-05 | norm: 0.0945 | dt: 179.48ms | tok/sec: 91286.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18702 | loss: 0.005282 | lr 6.0544e-05 | norm: 0.0919 | dt: 180.05ms | tok/sec: 90997.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18703 | loss: 0.004640 | lr 6.0541e-05 | norm: 0.0712 | dt: 179.51ms | tok/sec: 91273.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18704 | loss: 0.004947 | lr 6.0538e-05 | norm: 0.0731 | dt: 181.02ms | tok/sec: 90509.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18705 | loss: 0.005135 | lr 6.0535e-05 | norm: 0.0839 | dt: 180.05ms | tok/sec: 90994.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18706 | loss: 0.004830 | lr 6.0532e-05 | norm: 0.0762 | dt: 179.77ms | tok/sec: 91137.23\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18707 | loss: 0.005656 | lr 6.0529e-05 | norm: 0.0997 | dt: 180.96ms | tok/sec: 90541.40\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18708 | loss: 0.005884 | lr 6.0527e-05 | norm: 0.0865 | dt: 179.84ms | tok/sec: 91105.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18709 | loss: 0.006543 | lr 6.0524e-05 | norm: 0.0865 | dt: 179.12ms | tok/sec: 91471.93\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18710 | loss: 0.004486 | lr 6.0521e-05 | norm: 0.0762 | dt: 180.73ms | tok/sec: 90656.55\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18711 | loss: 0.005345 | lr 6.0518e-05 | norm: 0.0720 | dt: 180.26ms | tok/sec: 90891.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18712 | loss: 0.005781 | lr 6.0515e-05 | norm: 0.0795 | dt: 213.45ms | tok/sec: 76759.24\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18713 | loss: 0.004193 | lr 6.0512e-05 | norm: 0.0706 | dt: 185.54ms | tok/sec: 88303.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18714 | loss: 0.005200 | lr 6.0509e-05 | norm: 0.0732 | dt: 181.30ms | tok/sec: 90369.23\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18715 | loss: 0.005381 | lr 6.0507e-05 | norm: 0.0814 | dt: 184.27ms | tok/sec: 88913.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18716 | loss: 0.004486 | lr 6.0504e-05 | norm: 0.0639 | dt: 179.80ms | tok/sec: 91123.70\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18717 | loss: 0.004534 | lr 6.0501e-05 | norm: 0.0642 | dt: 180.11ms | tok/sec: 90965.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18718 | loss: 0.004322 | lr 6.0498e-05 | norm: 0.0613 | dt: 184.26ms | tok/sec: 88919.15\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18719 | loss: 0.004548 | lr 6.0495e-05 | norm: 0.0687 | dt: 186.55ms | tok/sec: 87825.58\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18720 | loss: 0.004837 | lr 6.0492e-05 | norm: 0.0556 | dt: 185.22ms | tok/sec: 88456.06\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18721 | loss: 0.005566 | lr 6.0490e-05 | norm: 0.0710 | dt: 182.80ms | tok/sec: 89629.15\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18722 | loss: 0.004468 | lr 6.0487e-05 | norm: 0.0556 | dt: 182.76ms | tok/sec: 89648.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18723 | loss: 0.006455 | lr 6.0484e-05 | norm: 0.1180 | dt: 182.30ms | tok/sec: 89872.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18724 | loss: 0.005022 | lr 6.0481e-05 | norm: 0.0784 | dt: 179.78ms | tok/sec: 91135.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18725 | loss: 0.004778 | lr 6.0479e-05 | norm: 0.0653 | dt: 179.32ms | tok/sec: 91368.80\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18726 | loss: 0.004272 | lr 6.0476e-05 | norm: 0.0747 | dt: 179.69ms | tok/sec: 91181.01\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18727 | loss: 0.004073 | lr 6.0473e-05 | norm: 0.0640 | dt: 178.91ms | tok/sec: 91578.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18728 | loss: 0.003829 | lr 6.0470e-05 | norm: 0.0791 | dt: 179.43ms | tok/sec: 91313.80\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18729 | loss: 0.004964 | lr 6.0468e-05 | norm: 0.0653 | dt: 180.38ms | tok/sec: 90832.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18730 | loss: 0.004820 | lr 6.0465e-05 | norm: 0.0669 | dt: 179.12ms | tok/sec: 91468.52\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18731 | loss: 0.004761 | lr 6.0462e-05 | norm: 0.0541 | dt: 179.65ms | tok/sec: 91198.07\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18732 | loss: 0.004136 | lr 6.0460e-05 | norm: 0.0586 | dt: 179.03ms | tok/sec: 91514.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18733 | loss: 0.004244 | lr 6.0457e-05 | norm: 0.0679 | dt: 179.94ms | tok/sec: 91051.62\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18734 | loss: 0.005258 | lr 6.0454e-05 | norm: 0.0647 | dt: 181.71ms | tok/sec: 90165.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18735 | loss: 0.003902 | lr 6.0452e-05 | norm: 0.0603 | dt: 179.24ms | tok/sec: 91408.42\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18736 | loss: 0.005674 | lr 6.0449e-05 | norm: 0.0767 | dt: 179.32ms | tok/sec: 91368.19\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18737 | loss: 0.004107 | lr 6.0446e-05 | norm: 0.0573 | dt: 178.80ms | tok/sec: 91630.61\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18738 | loss: 0.003862 | lr 6.0444e-05 | norm: 0.0456 | dt: 179.03ms | tok/sec: 91514.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18739 | loss: 0.005092 | lr 6.0441e-05 | norm: 0.0801 | dt: 179.11ms | tok/sec: 91475.46\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18740 | loss: 0.003549 | lr 6.0438e-05 | norm: 0.0617 | dt: 179.12ms | tok/sec: 91469.01\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18741 | loss: 0.003257 | lr 6.0436e-05 | norm: 0.0512 | dt: 180.49ms | tok/sec: 90773.78\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18742 | loss: 0.005186 | lr 6.0433e-05 | norm: 0.0672 | dt: 179.73ms | tok/sec: 91156.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18743 | loss: 0.004970 | lr 6.0430e-05 | norm: 0.0680 | dt: 180.73ms | tok/sec: 90654.99\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18744 | loss: 0.005952 | lr 6.0428e-05 | norm: 0.0750 | dt: 181.06ms | tok/sec: 90490.61\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18745 | loss: 0.006299 | lr 6.0425e-05 | norm: 0.0747 | dt: 179.43ms | tok/sec: 91313.92\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18746 | loss: 0.006841 | lr 6.0423e-05 | norm: 0.0891 | dt: 179.63ms | tok/sec: 91209.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18747 | loss: 0.005672 | lr 6.0420e-05 | norm: 0.0793 | dt: 179.00ms | tok/sec: 91528.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18748 | loss: 0.004713 | lr 6.0417e-05 | norm: 0.0739 | dt: 179.01ms | tok/sec: 91527.97\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18749 | loss: 0.005847 | lr 6.0415e-05 | norm: 0.0707 | dt: 180.87ms | tok/sec: 90581.98\n",
      "validation loss: 0.1502\n",
      "rank 0 sample 0: Smoking is the major risk factor for heart disease.<|endoftext|>, the chance of developing heart disease increases as you age.\n",
      "                \n",
      "If you have one or more risk factors, heart disease can be present.<|endoftext|>Q: What are the treatments\n",
      "rank 0 sample 1: Smoking is the major risk factor for multisystem<|endoftext|> disease.<|endoftext|>Q: What are the treatments for multisystem<|endoftext|> disease ? A: How might multisystem<|endoftext|> disease be treated? There is no cure for multisystem<|endoftext|> disease (GSS).  Management has been shown that with current treatments may\n",
      "rank 0 sample 2: Smoking is the major risk factor for multinzel, Only a person can change to prevent or delay theification of a specific region of<|endoftext|> vara.<|endoftext|>Q: What are the symptoms of Pul<|endoftext|> Hypertension ? A: What are the signs and symptoms of Pul<|endoftext|> Hypertension? The Human<|endoftext|>\n",
      "rank 0 sample 3: Smoking is the major risk factor for heart disease.<|endoftext|>Q: What are the symptoms of Corneal dystrophy ? A: What are the signs and symptoms of Corneal dystrophy? The Human<|endoftext|>otype Ontology provides the following list of signs and symptoms for Corneal dystrophy.\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18750 | loss: 0.004905 | lr 6.0412e-05 | norm: 0.0784 | dt: 3651.39ms | tok/sec: 4487.05\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18751 | loss: 0.004876 | lr 6.0410e-05 | norm: 0.0694 | dt: 181.34ms | tok/sec: 90347.97\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18752 | loss: 0.005344 | lr 6.0407e-05 | norm: 0.0680 | dt: 181.31ms | tok/sec: 90364.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18753 | loss: 0.004973 | lr 6.0405e-05 | norm: 0.0698 | dt: 180.44ms | tok/sec: 90798.25\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18754 | loss: 0.005348 | lr 6.0402e-05 | norm: 0.0778 | dt: 179.45ms | tok/sec: 91303.61\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18755 | loss: 0.006868 | lr 6.0400e-05 | norm: 0.0848 | dt: 179.22ms | tok/sec: 91419.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18756 | loss: 0.006714 | lr 6.0397e-05 | norm: 0.0728 | dt: 179.93ms | tok/sec: 91058.25\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18757 | loss: 0.006124 | lr 6.0395e-05 | norm: 0.0854 | dt: 181.85ms | tok/sec: 90097.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18758 | loss: 0.008251 | lr 6.0392e-05 | norm: 0.1276 | dt: 179.96ms | tok/sec: 91043.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18759 | loss: 0.007978 | lr 6.0390e-05 | norm: 0.1142 | dt: 183.09ms | tok/sec: 89485.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18760 | loss: 0.004567 | lr 6.0387e-05 | norm: 0.0442 | dt: 183.06ms | tok/sec: 89499.35\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18761 | loss: 0.006823 | lr 6.0385e-05 | norm: 0.1082 | dt: 180.84ms | tok/sec: 90599.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18762 | loss: 0.006111 | lr 6.0382e-05 | norm: 0.0579 | dt: 183.14ms | tok/sec: 89463.11\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18763 | loss: 0.005996 | lr 6.0380e-05 | norm: 0.0667 | dt: 180.69ms | tok/sec: 90672.22\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18764 | loss: 0.007851 | lr 6.0377e-05 | norm: 0.0990 | dt: 180.33ms | tok/sec: 90856.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18765 | loss: 0.009752 | lr 6.0375e-05 | norm: 0.1092 | dt: 179.03ms | tok/sec: 91514.93\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18766 | loss: 0.005948 | lr 6.0373e-05 | norm: 0.0645 | dt: 179.54ms | tok/sec: 91253.05\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18767 | loss: 0.008298 | lr 6.0370e-05 | norm: 0.0754 | dt: 179.65ms | tok/sec: 91201.46\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18768 | loss: 0.010532 | lr 6.0368e-05 | norm: 0.1112 | dt: 179.70ms | tok/sec: 91176.65\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18769 | loss: 0.009199 | lr 6.0365e-05 | norm: 0.0814 | dt: 178.32ms | tok/sec: 91879.80\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18770 | loss: 0.009309 | lr 6.0363e-05 | norm: 0.1129 | dt: 179.54ms | tok/sec: 91254.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18771 | loss: 0.014706 | lr 6.0360e-05 | norm: 0.1389 | dt: 179.34ms | tok/sec: 91358.23\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18772 | loss: 0.010890 | lr 6.0358e-05 | norm: 0.1341 | dt: 178.95ms | tok/sec: 91558.58\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18773 | loss: 0.014021 | lr 6.0356e-05 | norm: 0.1443 | dt: 179.61ms | tok/sec: 91218.04\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18774 | loss: 0.010162 | lr 6.0353e-05 | norm: 0.1041 | dt: 185.99ms | tok/sec: 88092.29\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18775 | loss: 0.011228 | lr 6.0351e-05 | norm: 0.1225 | dt: 180.46ms | tok/sec: 90792.61\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18776 | loss: 0.010041 | lr 6.0349e-05 | norm: 0.1134 | dt: 179.39ms | tok/sec: 91329.21\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18777 | loss: 0.011075 | lr 6.0346e-05 | norm: 0.1254 | dt: 179.90ms | tok/sec: 91075.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18778 | loss: 0.010119 | lr 6.0344e-05 | norm: 0.1255 | dt: 178.75ms | tok/sec: 91656.40\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18779 | loss: 0.027007 | lr 6.0342e-05 | norm: 0.3202 | dt: 181.76ms | tok/sec: 90141.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18780 | loss: 0.009335 | lr 6.0339e-05 | norm: 0.1185 | dt: 179.07ms | tok/sec: 91496.04\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18781 | loss: 0.011064 | lr 6.0337e-05 | norm: 0.0949 | dt: 179.67ms | tok/sec: 91187.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18782 | loss: 0.011587 | lr 6.0335e-05 | norm: 0.1136 | dt: 179.18ms | tok/sec: 91441.14\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18783 | loss: 0.010960 | lr 6.0332e-05 | norm: 0.1079 | dt: 180.07ms | tok/sec: 90985.43\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18784 | loss: 0.008730 | lr 6.0330e-05 | norm: 0.0924 | dt: 179.12ms | tok/sec: 91468.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18785 | loss: 0.012583 | lr 6.0328e-05 | norm: 0.1307 | dt: 181.09ms | tok/sec: 90476.55\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18786 | loss: 0.012352 | lr 6.0326e-05 | norm: 0.0964 | dt: 179.12ms | tok/sec: 91467.67\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18787 | loss: 0.009748 | lr 6.0323e-05 | norm: 0.1119 | dt: 179.64ms | tok/sec: 91204.00\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18788 | loss: 0.010121 | lr 6.0321e-05 | norm: 0.1107 | dt: 179.01ms | tok/sec: 91526.14\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18789 | loss: 0.011414 | lr 6.0319e-05 | norm: 0.1182 | dt: 179.91ms | tok/sec: 91066.94\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18790 | loss: 0.009753 | lr 6.0317e-05 | norm: 0.0974 | dt: 182.08ms | tok/sec: 89983.00\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18791 | loss: 0.012543 | lr 6.0314e-05 | norm: 0.1102 | dt: 185.22ms | tok/sec: 88454.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18792 | loss: 0.006781 | lr 6.0312e-05 | norm: 0.0757 | dt: 181.33ms | tok/sec: 90352.72\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18793 | loss: 0.007677 | lr 6.0310e-05 | norm: 0.0828 | dt: 185.98ms | tok/sec: 88093.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18794 | loss: 0.008266 | lr 6.0308e-05 | norm: 0.0777 | dt: 183.40ms | tok/sec: 89332.74\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18795 | loss: 0.010179 | lr 6.0305e-05 | norm: 0.1067 | dt: 185.30ms | tok/sec: 88417.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18796 | loss: 0.011429 | lr 6.0303e-05 | norm: 0.0991 | dt: 182.69ms | tok/sec: 89679.80\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18797 | loss: 0.008172 | lr 6.0301e-05 | norm: 0.0963 | dt: 179.47ms | tok/sec: 91290.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18798 | loss: 0.007290 | lr 6.0299e-05 | norm: 0.0706 | dt: 181.87ms | tok/sec: 90086.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18799 | loss: 0.006000 | lr 6.0297e-05 | norm: 0.0640 | dt: 179.04ms | tok/sec: 91509.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18800 | loss: 0.005532 | lr 6.0295e-05 | norm: 0.0586 | dt: 179.51ms | tok/sec: 91270.62\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18801 | loss: 0.008134 | lr 6.0292e-05 | norm: 0.0913 | dt: 187.08ms | tok/sec: 87577.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18802 | loss: 0.007576 | lr 6.0290e-05 | norm: 0.0734 | dt: 182.40ms | tok/sec: 89825.27\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18803 | loss: 0.005933 | lr 6.0288e-05 | norm: 0.0601 | dt: 183.23ms | tok/sec: 89417.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18804 | loss: 0.007352 | lr 6.0286e-05 | norm: 0.0750 | dt: 178.54ms | tok/sec: 91765.70\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18805 | loss: 0.013171 | lr 6.0284e-05 | norm: 0.1319 | dt: 180.63ms | tok/sec: 90702.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18806 | loss: 0.006464 | lr 6.0282e-05 | norm: 0.0805 | dt: 181.03ms | tok/sec: 90506.23\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18807 | loss: 0.007479 | lr 6.0280e-05 | norm: 0.0808 | dt: 181.63ms | tok/sec: 90204.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18808 | loss: 0.006863 | lr 6.0278e-05 | norm: 0.0731 | dt: 182.02ms | tok/sec: 90013.41\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18809 | loss: 0.007225 | lr 6.0275e-05 | norm: 0.0938 | dt: 178.43ms | tok/sec: 91824.43\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18810 | loss: 0.005514 | lr 6.0273e-05 | norm: 0.0569 | dt: 184.71ms | tok/sec: 88702.00\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18811 | loss: 0.005923 | lr 6.0271e-05 | norm: 0.0763 | dt: 179.42ms | tok/sec: 91315.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18812 | loss: 0.009633 | lr 6.0269e-05 | norm: 0.0950 | dt: 187.95ms | tok/sec: 87171.62\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18813 | loss: 0.006662 | lr 6.0267e-05 | norm: 0.0848 | dt: 180.08ms | tok/sec: 90981.46\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18814 | loss: 0.006449 | lr 6.0265e-05 | norm: 0.0654 | dt: 180.85ms | tok/sec: 90592.49\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18815 | loss: 0.010273 | lr 6.0263e-05 | norm: 0.1301 | dt: 178.94ms | tok/sec: 91561.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18816 | loss: 0.007636 | lr 6.0261e-05 | norm: 0.0846 | dt: 182.38ms | tok/sec: 89832.90\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18817 | loss: 0.011487 | lr 6.0259e-05 | norm: 0.1324 | dt: 186.31ms | tok/sec: 87938.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18818 | loss: 0.012291 | lr 6.0257e-05 | norm: 0.1569 | dt: 179.62ms | tok/sec: 91214.29\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18819 | loss: 0.010548 | lr 6.0255e-05 | norm: 0.0966 | dt: 186.55ms | tok/sec: 87825.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18820 | loss: 0.015648 | lr 6.0253e-05 | norm: 0.1509 | dt: 180.99ms | tok/sec: 90525.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18821 | loss: 0.008804 | lr 6.0251e-05 | norm: 0.0878 | dt: 182.53ms | tok/sec: 89759.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18822 | loss: 0.006783 | lr 6.0249e-05 | norm: 0.0729 | dt: 182.28ms | tok/sec: 89883.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18823 | loss: 0.005823 | lr 6.0247e-05 | norm: 0.0823 | dt: 184.47ms | tok/sec: 88816.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18824 | loss: 0.005038 | lr 6.0245e-05 | norm: 0.0550 | dt: 187.77ms | tok/sec: 87253.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18825 | loss: 0.009141 | lr 6.0243e-05 | norm: 0.1022 | dt: 182.21ms | tok/sec: 89917.18\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18826 | loss: 0.004496 | lr 6.0241e-05 | norm: 0.0606 | dt: 184.89ms | tok/sec: 88614.27\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18827 | loss: 0.006076 | lr 6.0239e-05 | norm: 0.0716 | dt: 184.45ms | tok/sec: 88827.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18828 | loss: 0.005472 | lr 6.0237e-05 | norm: 0.0617 | dt: 182.31ms | tok/sec: 89871.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18829 | loss: 0.006615 | lr 6.0235e-05 | norm: 0.0671 | dt: 186.55ms | tok/sec: 87824.23\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18830 | loss: 0.005397 | lr 6.0233e-05 | norm: 0.0798 | dt: 179.12ms | tok/sec: 91469.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18831 | loss: 0.006443 | lr 6.0232e-05 | norm: 0.0720 | dt: 185.21ms | tok/sec: 88461.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18832 | loss: 0.005707 | lr 6.0230e-05 | norm: 0.0840 | dt: 180.91ms | tok/sec: 90565.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18833 | loss: 0.005862 | lr 6.0228e-05 | norm: 0.0812 | dt: 180.58ms | tok/sec: 90732.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18834 | loss: 0.006493 | lr 6.0226e-05 | norm: 0.0645 | dt: 179.24ms | tok/sec: 91410.61\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18835 | loss: 0.005454 | lr 6.0224e-05 | norm: 0.0603 | dt: 185.38ms | tok/sec: 88379.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18836 | loss: 0.006728 | lr 6.0222e-05 | norm: 0.0819 | dt: 183.02ms | tok/sec: 89520.91\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18837 | loss: 0.005579 | lr 6.0220e-05 | norm: 0.0788 | dt: 180.58ms | tok/sec: 90731.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18838 | loss: 0.006954 | lr 6.0218e-05 | norm: 0.0779 | dt: 179.79ms | tok/sec: 91129.25\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18839 | loss: 0.006475 | lr 6.0216e-05 | norm: 0.0572 | dt: 180.42ms | tok/sec: 90808.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18840 | loss: 0.005348 | lr 6.0215e-05 | norm: 0.0740 | dt: 180.25ms | tok/sec: 90898.06\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18841 | loss: 0.005370 | lr 6.0213e-05 | norm: 0.0656 | dt: 180.40ms | tok/sec: 90820.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18842 | loss: 0.006275 | lr 6.0211e-05 | norm: 0.0700 | dt: 179.02ms | tok/sec: 91522.37\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18843 | loss: 0.006443 | lr 6.0209e-05 | norm: 0.0720 | dt: 181.16ms | tok/sec: 90438.93\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18844 | loss: 0.004695 | lr 6.0207e-05 | norm: 0.0769 | dt: 180.33ms | tok/sec: 90855.39\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18845 | loss: 0.005150 | lr 6.0205e-05 | norm: 0.0638 | dt: 179.86ms | tok/sec: 91092.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18846 | loss: 0.005959 | lr 6.0204e-05 | norm: 0.0823 | dt: 181.09ms | tok/sec: 90474.41\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18847 | loss: 0.004118 | lr 6.0202e-05 | norm: 0.0602 | dt: 179.60ms | tok/sec: 91227.12\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18848 | loss: 0.004129 | lr 6.0200e-05 | norm: 0.0565 | dt: 179.66ms | tok/sec: 91196.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18849 | loss: 0.004191 | lr 6.0198e-05 | norm: 0.0623 | dt: 179.88ms | tok/sec: 91081.30\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18850 | loss: 0.006015 | lr 6.0197e-05 | norm: 0.0834 | dt: 179.83ms | tok/sec: 91106.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18851 | loss: 0.005700 | lr 6.0195e-05 | norm: 0.0754 | dt: 180.16ms | tok/sec: 90939.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18852 | loss: 0.005133 | lr 6.0193e-05 | norm: 0.0665 | dt: 181.14ms | tok/sec: 90450.12\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18853 | loss: 0.004377 | lr 6.0191e-05 | norm: 0.0680 | dt: 180.61ms | tok/sec: 90714.35\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18854 | loss: 0.005226 | lr 6.0190e-05 | norm: 0.0726 | dt: 180.77ms | tok/sec: 90632.04\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18855 | loss: 0.005283 | lr 6.0188e-05 | norm: 0.0710 | dt: 181.85ms | tok/sec: 90094.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18856 | loss: 0.005003 | lr 6.0186e-05 | norm: 0.0676 | dt: 180.00ms | tok/sec: 91022.91\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18857 | loss: 0.004145 | lr 6.0184e-05 | norm: 0.0530 | dt: 182.93ms | tok/sec: 89563.15\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18858 | loss: 0.004990 | lr 6.0183e-05 | norm: 0.0797 | dt: 179.70ms | tok/sec: 91172.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18859 | loss: 0.005532 | lr 6.0181e-05 | norm: 0.0680 | dt: 181.26ms | tok/sec: 90388.61\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18860 | loss: 0.005585 | lr 6.0179e-05 | norm: 0.0862 | dt: 179.76ms | tok/sec: 91145.45\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18861 | loss: 0.007477 | lr 6.0178e-05 | norm: 0.0887 | dt: 180.46ms | tok/sec: 90790.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18862 | loss: 0.005587 | lr 6.0176e-05 | norm: 0.0722 | dt: 180.13ms | tok/sec: 90954.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18863 | loss: 0.004479 | lr 6.0174e-05 | norm: 0.0574 | dt: 180.51ms | tok/sec: 90765.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18864 | loss: 0.005778 | lr 6.0173e-05 | norm: 0.0769 | dt: 180.69ms | tok/sec: 90674.25\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18865 | loss: 0.005783 | lr 6.0171e-05 | norm: 0.0764 | dt: 183.71ms | tok/sec: 89182.14\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18866 | loss: 0.004503 | lr 6.0169e-05 | norm: 0.0590 | dt: 181.36ms | tok/sec: 90340.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18867 | loss: 0.002875 | lr 6.0168e-05 | norm: 0.0552 | dt: 179.41ms | tok/sec: 91322.05\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18868 | loss: 0.007597 | lr 6.0166e-05 | norm: 0.0723 | dt: 182.47ms | tok/sec: 89788.65\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18869 | loss: 0.003834 | lr 6.0165e-05 | norm: 0.0641 | dt: 179.67ms | tok/sec: 91191.90\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18870 | loss: 0.004912 | lr 6.0163e-05 | norm: 0.0715 | dt: 179.84ms | tok/sec: 91101.71\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18871 | loss: 0.005734 | lr 6.0161e-05 | norm: 0.0662 | dt: 178.55ms | tok/sec: 91759.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18872 | loss: 0.004922 | lr 6.0160e-05 | norm: 0.0683 | dt: 180.31ms | tok/sec: 90865.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18873 | loss: 0.004700 | lr 6.0158e-05 | norm: 0.0724 | dt: 179.18ms | tok/sec: 91436.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18874 | loss: 0.005454 | lr 6.0157e-05 | norm: 0.0643 | dt: 178.87ms | tok/sec: 91598.00\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18875 | loss: 0.005215 | lr 6.0155e-05 | norm: 0.0606 | dt: 179.01ms | tok/sec: 91527.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18876 | loss: 0.005027 | lr 6.0153e-05 | norm: 0.0628 | dt: 179.39ms | tok/sec: 91330.55\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18877 | loss: 0.005402 | lr 6.0152e-05 | norm: 0.0758 | dt: 178.76ms | tok/sec: 91655.79\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18878 | loss: 0.005781 | lr 6.0150e-05 | norm: 0.0690 | dt: 179.76ms | tok/sec: 91143.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18879 | loss: 0.002954 | lr 6.0149e-05 | norm: 0.0691 | dt: 179.57ms | tok/sec: 91239.72\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18880 | loss: 0.005535 | lr 6.0147e-05 | norm: 0.0710 | dt: 178.82ms | tok/sec: 91620.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18881 | loss: 0.002942 | lr 6.0146e-05 | norm: 0.0588 | dt: 180.54ms | tok/sec: 90751.37\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18882 | loss: 0.003778 | lr 6.0144e-05 | norm: 0.0545 | dt: 180.62ms | tok/sec: 90712.19\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18883 | loss: 0.004568 | lr 6.0143e-05 | norm: 0.0725 | dt: 181.27ms | tok/sec: 90384.33\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18884 | loss: 0.005472 | lr 6.0141e-05 | norm: 0.0790 | dt: 179.52ms | tok/sec: 91266.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18885 | loss: 0.004318 | lr 6.0140e-05 | norm: 0.0557 | dt: 179.90ms | tok/sec: 91075.27\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18886 | loss: 0.006164 | lr 6.0138e-05 | norm: 0.0655 | dt: 181.64ms | tok/sec: 90197.95\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18887 | loss: 0.004431 | lr 6.0137e-05 | norm: 0.0574 | dt: 179.39ms | tok/sec: 91331.15\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18888 | loss: 0.004174 | lr 6.0135e-05 | norm: 0.0755 | dt: 179.78ms | tok/sec: 91133.00\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18889 | loss: 0.004956 | lr 6.0134e-05 | norm: 0.0624 | dt: 182.12ms | tok/sec: 89960.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18890 | loss: 0.004903 | lr 6.0132e-05 | norm: 0.0668 | dt: 182.89ms | tok/sec: 89583.82\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18891 | loss: 0.004091 | lr 6.0131e-05 | norm: 0.0656 | dt: 182.85ms | tok/sec: 89601.22\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18892 | loss: 0.004969 | lr 6.0130e-05 | norm: 0.0847 | dt: 183.19ms | tok/sec: 89435.86\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18893 | loss: 0.005744 | lr 6.0128e-05 | norm: 0.0812 | dt: 180.63ms | tok/sec: 90703.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18894 | loss: 0.004787 | lr 6.0127e-05 | norm: 0.0775 | dt: 180.71ms | tok/sec: 90663.01\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18895 | loss: 0.003986 | lr 6.0125e-05 | norm: 0.0517 | dt: 179.56ms | tok/sec: 91247.72\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18896 | loss: 0.005547 | lr 6.0124e-05 | norm: 0.0725 | dt: 189.13ms | tok/sec: 86627.01\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18897 | loss: 0.008709 | lr 6.0122e-05 | norm: 0.0833 | dt: 180.91ms | tok/sec: 90565.51\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18898 | loss: 0.004730 | lr 6.0121e-05 | norm: 0.0745 | dt: 179.96ms | tok/sec: 91042.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18899 | loss: 0.003390 | lr 6.0120e-05 | norm: 0.0501 | dt: 180.98ms | tok/sec: 90531.26\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18900 | loss: 0.003781 | lr 6.0118e-05 | norm: 0.0612 | dt: 179.21ms | tok/sec: 91425.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18901 | loss: 0.003361 | lr 6.0117e-05 | norm: 0.0572 | dt: 178.61ms | tok/sec: 91732.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18902 | loss: 0.004069 | lr 6.0116e-05 | norm: 0.0477 | dt: 178.60ms | tok/sec: 91736.42\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18903 | loss: 0.003117 | lr 6.0114e-05 | norm: 0.0446 | dt: 178.36ms | tok/sec: 91856.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18904 | loss: 0.004971 | lr 6.0113e-05 | norm: 0.0740 | dt: 178.17ms | tok/sec: 91959.11\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18905 | loss: 0.003631 | lr 6.0112e-05 | norm: 0.0570 | dt: 179.00ms | tok/sec: 91528.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18906 | loss: 0.004122 | lr 6.0110e-05 | norm: 0.0539 | dt: 179.05ms | tok/sec: 91502.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18907 | loss: 0.003349 | lr 6.0109e-05 | norm: 0.0449 | dt: 178.99ms | tok/sec: 91537.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18908 | loss: 0.004326 | lr 6.0108e-05 | norm: 0.0612 | dt: 179.90ms | tok/sec: 91074.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18909 | loss: 0.004477 | lr 6.0106e-05 | norm: 0.0826 | dt: 178.92ms | tok/sec: 91573.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18910 | loss: 0.004123 | lr 6.0105e-05 | norm: 0.0495 | dt: 178.90ms | tok/sec: 91579.57\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18911 | loss: 0.005357 | lr 6.0104e-05 | norm: 0.0682 | dt: 178.27ms | tok/sec: 91904.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18912 | loss: 0.004942 | lr 6.0102e-05 | norm: 0.0579 | dt: 178.27ms | tok/sec: 91905.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18913 | loss: 0.004692 | lr 6.0101e-05 | norm: 0.0594 | dt: 178.08ms | tok/sec: 92002.32\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18914 | loss: 0.005396 | lr 6.0100e-05 | norm: 0.0739 | dt: 180.46ms | tok/sec: 90790.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18915 | loss: 0.003684 | lr 6.0099e-05 | norm: 0.0481 | dt: 178.62ms | tok/sec: 91725.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18916 | loss: 0.004439 | lr 6.0097e-05 | norm: 0.0565 | dt: 181.90ms | tok/sec: 90071.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18917 | loss: 0.004191 | lr 6.0096e-05 | norm: 0.0535 | dt: 178.30ms | tok/sec: 91889.88\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18918 | loss: 0.003707 | lr 6.0095e-05 | norm: 0.0492 | dt: 178.70ms | tok/sec: 91682.45\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18919 | loss: 0.003556 | lr 6.0094e-05 | norm: 0.0508 | dt: 179.21ms | tok/sec: 91422.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18920 | loss: 0.004475 | lr 6.0093e-05 | norm: 0.0598 | dt: 180.49ms | tok/sec: 90774.74\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18921 | loss: 0.004551 | lr 6.0091e-05 | norm: 0.0510 | dt: 178.53ms | tok/sec: 91771.58\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18922 | loss: 0.003262 | lr 6.0090e-05 | norm: 0.0571 | dt: 179.24ms | tok/sec: 91409.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18923 | loss: 0.004838 | lr 6.0089e-05 | norm: 0.0593 | dt: 179.34ms | tok/sec: 91357.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18924 | loss: 0.004658 | lr 6.0088e-05 | norm: 0.0618 | dt: 179.18ms | tok/sec: 91440.28\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18925 | loss: 0.003658 | lr 6.0087e-05 | norm: 0.0537 | dt: 179.40ms | tok/sec: 91327.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18926 | loss: 0.005851 | lr 6.0085e-05 | norm: 0.0657 | dt: 180.42ms | tok/sec: 90810.85\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18927 | loss: 0.004607 | lr 6.0084e-05 | norm: 0.0660 | dt: 180.03ms | tok/sec: 91007.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18928 | loss: 0.004837 | lr 6.0083e-05 | norm: 0.0612 | dt: 179.10ms | tok/sec: 91478.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18929 | loss: 0.005504 | lr 6.0082e-05 | norm: 0.0600 | dt: 179.80ms | tok/sec: 91123.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18930 | loss: 0.004069 | lr 6.0081e-05 | norm: 0.0604 | dt: 181.23ms | tok/sec: 90403.71\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18931 | loss: 0.004407 | lr 6.0080e-05 | norm: 0.0504 | dt: 180.90ms | tok/sec: 90569.68\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18932 | loss: 0.004853 | lr 6.0079e-05 | norm: 0.0523 | dt: 179.77ms | tok/sec: 91136.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18933 | loss: 0.003719 | lr 6.0077e-05 | norm: 0.0567 | dt: 179.78ms | tok/sec: 91135.90\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18934 | loss: 0.004075 | lr 6.0076e-05 | norm: 0.0676 | dt: 179.07ms | tok/sec: 91493.61\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18935 | loss: 0.005457 | lr 6.0075e-05 | norm: 0.0852 | dt: 178.80ms | tok/sec: 91630.73\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18936 | loss: 0.004268 | lr 6.0074e-05 | norm: 0.0612 | dt: 180.15ms | tok/sec: 90944.97\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18937 | loss: 0.005297 | lr 6.0073e-05 | norm: 0.0765 | dt: 178.90ms | tok/sec: 91579.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18938 | loss: 0.004566 | lr 6.0072e-05 | norm: 0.0592 | dt: 179.53ms | tok/sec: 91261.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18939 | loss: 0.003829 | lr 6.0071e-05 | norm: 0.0489 | dt: 178.73ms | tok/sec: 91666.91\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18940 | loss: 0.006930 | lr 6.0070e-05 | norm: 0.0931 | dt: 179.06ms | tok/sec: 91497.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18941 | loss: 0.004873 | lr 6.0069e-05 | norm: 0.0683 | dt: 180.27ms | tok/sec: 90887.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18942 | loss: 0.004505 | lr 6.0068e-05 | norm: 0.0693 | dt: 180.28ms | tok/sec: 90880.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18943 | loss: 0.006120 | lr 6.0067e-05 | norm: 0.0942 | dt: 180.54ms | tok/sec: 90750.65\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18944 | loss: 0.022129 | lr 6.0066e-05 | norm: 0.3437 | dt: 179.86ms | tok/sec: 91092.77\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18945 | loss: 0.016174 | lr 6.0065e-05 | norm: 0.2261 | dt: 178.94ms | tok/sec: 91558.95\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18946 | loss: 0.011630 | lr 6.0064e-05 | norm: 0.1679 | dt: 179.53ms | tok/sec: 91261.29\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18947 | loss: 0.011142 | lr 6.0063e-05 | norm: 0.1470 | dt: 180.41ms | tok/sec: 90815.17\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18948 | loss: 0.011525 | lr 6.0062e-05 | norm: 0.1496 | dt: 180.92ms | tok/sec: 90561.69\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18949 | loss: 0.009718 | lr 6.0061e-05 | norm: 0.1322 | dt: 180.23ms | tok/sec: 90905.51\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18950 | loss: 0.009654 | lr 6.0060e-05 | norm: 0.1340 | dt: 180.72ms | tok/sec: 90659.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18951 | loss: 0.009244 | lr 6.0059e-05 | norm: 0.1448 | dt: 180.98ms | tok/sec: 90531.15\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18952 | loss: 0.008023 | lr 6.0058e-05 | norm: 0.1065 | dt: 180.30ms | tok/sec: 90872.82\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18953 | loss: 0.009169 | lr 6.0057e-05 | norm: 0.1527 | dt: 179.90ms | tok/sec: 91072.25\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18954 | loss: 0.011872 | lr 6.0056e-05 | norm: 0.1908 | dt: 180.73ms | tok/sec: 90652.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18955 | loss: 0.010805 | lr 6.0055e-05 | norm: 0.1571 | dt: 181.29ms | tok/sec: 90374.11\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18956 | loss: 0.011246 | lr 6.0054e-05 | norm: 0.1555 | dt: 181.84ms | tok/sec: 90099.44\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18957 | loss: 0.014266 | lr 6.0053e-05 | norm: 0.1768 | dt: 187.53ms | tok/sec: 87367.78\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18958 | loss: 0.008144 | lr 6.0052e-05 | norm: 0.1202 | dt: 182.22ms | tok/sec: 89914.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18959 | loss: 0.008373 | lr 6.0051e-05 | norm: 0.1195 | dt: 179.07ms | tok/sec: 91492.76\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18960 | loss: 0.007725 | lr 6.0050e-05 | norm: 0.1137 | dt: 179.85ms | tok/sec: 91097.60\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18961 | loss: 0.008775 | lr 6.0050e-05 | norm: 0.0938 | dt: 179.64ms | tok/sec: 91206.66\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18962 | loss: 0.011898 | lr 6.0049e-05 | norm: 0.1501 | dt: 179.62ms | tok/sec: 91214.05\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18963 | loss: 0.011945 | lr 6.0048e-05 | norm: 0.1455 | dt: 178.87ms | tok/sec: 91597.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18964 | loss: 0.012998 | lr 6.0047e-05 | norm: 0.1890 | dt: 179.87ms | tok/sec: 91086.25\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18965 | loss: 0.010061 | lr 6.0046e-05 | norm: 0.1317 | dt: 180.00ms | tok/sec: 91021.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18966 | loss: 0.011630 | lr 6.0045e-05 | norm: 0.1660 | dt: 179.62ms | tok/sec: 91216.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18967 | loss: 0.010201 | lr 6.0044e-05 | norm: 0.1319 | dt: 178.97ms | tok/sec: 91545.90\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18968 | loss: 0.008419 | lr 6.0044e-05 | norm: 0.1232 | dt: 180.63ms | tok/sec: 90703.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18969 | loss: 0.009338 | lr 6.0043e-05 | norm: 0.1205 | dt: 180.11ms | tok/sec: 90968.45\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18970 | loss: 0.009363 | lr 6.0042e-05 | norm: 0.1228 | dt: 179.90ms | tok/sec: 91072.37\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18971 | loss: 0.010920 | lr 6.0041e-05 | norm: 0.1379 | dt: 179.13ms | tok/sec: 91464.75\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18972 | loss: 0.010916 | lr 6.0040e-05 | norm: 0.1568 | dt: 178.75ms | tok/sec: 91659.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18973 | loss: 0.009931 | lr 6.0040e-05 | norm: 0.1313 | dt: 179.65ms | tok/sec: 91200.13\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18974 | loss: 0.011866 | lr 6.0039e-05 | norm: 0.1839 | dt: 179.70ms | tok/sec: 91173.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18975 | loss: 0.013047 | lr 6.0038e-05 | norm: 0.1354 | dt: 179.44ms | tok/sec: 91307.25\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18976 | loss: 0.011171 | lr 6.0037e-05 | norm: 0.1548 | dt: 179.43ms | tok/sec: 91312.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18977 | loss: 0.016064 | lr 6.0036e-05 | norm: 0.1851 | dt: 179.39ms | tok/sec: 91331.27\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18978 | loss: 0.015046 | lr 6.0036e-05 | norm: 0.1661 | dt: 179.71ms | tok/sec: 91169.03\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18979 | loss: 0.013668 | lr 6.0035e-05 | norm: 0.1727 | dt: 179.69ms | tok/sec: 91180.28\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18980 | loss: 0.014974 | lr 6.0034e-05 | norm: 0.2078 | dt: 180.17ms | tok/sec: 90935.59\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18981 | loss: 0.017908 | lr 6.0033e-05 | norm: 0.2748 | dt: 180.51ms | tok/sec: 90765.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18982 | loss: 0.016372 | lr 6.0033e-05 | norm: 0.1681 | dt: 180.40ms | tok/sec: 90818.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18983 | loss: 0.018557 | lr 6.0032e-05 | norm: 0.2905 | dt: 180.95ms | tok/sec: 90545.58\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18984 | loss: 0.015893 | lr 6.0031e-05 | norm: 0.1902 | dt: 182.40ms | tok/sec: 89825.27\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18985 | loss: 0.014915 | lr 6.0031e-05 | norm: 0.1753 | dt: 180.84ms | tok/sec: 90597.51\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18986 | loss: 0.013220 | lr 6.0030e-05 | norm: 0.1773 | dt: 180.22ms | tok/sec: 90912.37\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18987 | loss: 0.018465 | lr 6.0029e-05 | norm: 0.2150 | dt: 179.59ms | tok/sec: 91227.97\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18988 | loss: 0.014057 | lr 6.0029e-05 | norm: 0.2160 | dt: 179.85ms | tok/sec: 91100.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18989 | loss: 0.012914 | lr 6.0028e-05 | norm: 0.2070 | dt: 179.23ms | tok/sec: 91412.79\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18990 | loss: 0.020325 | lr 6.0027e-05 | norm: 0.2656 | dt: 178.94ms | tok/sec: 91560.78\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18991 | loss: 0.019627 | lr 6.0027e-05 | norm: 0.2355 | dt: 178.77ms | tok/sec: 91650.90\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18992 | loss: 0.029298 | lr 6.0026e-05 | norm: 0.2670 | dt: 180.03ms | tok/sec: 91007.12\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18993 | loss: 0.049590 | lr 6.0025e-05 | norm: 0.3492 | dt: 179.02ms | tok/sec: 91521.39\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18994 | loss: 0.036739 | lr 6.0025e-05 | norm: 0.4201 | dt: 179.49ms | tok/sec: 91278.99\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18995 | loss: 0.040267 | lr 6.0024e-05 | norm: 0.4216 | dt: 182.62ms | tok/sec: 89718.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18996 | loss: 0.019760 | lr 6.0023e-05 | norm: 0.2267 | dt: 179.33ms | tok/sec: 91360.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18997 | loss: 0.033649 | lr 6.0023e-05 | norm: 0.3031 | dt: 180.05ms | tok/sec: 90997.96\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18998 | loss: 0.012936 | lr 6.0022e-05 | norm: 0.1438 | dt: 179.22ms | tok/sec: 91417.90\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 18999 | loss: 0.011464 | lr 6.0022e-05 | norm: 0.1318 | dt: 178.92ms | tok/sec: 91569.20\n",
      "validation loss: 0.1714\n",
      "rank 0 sample 0: Smoking is the major risk factor for most types of cancer. Anything that increases your chance of getting a disease is called a risk factor. Having a risk factor does not mean that you will get cancer; not having risk factors doesn't mean that you will not get cancer. Talk with your doctor if you think you may\n",
      "rank 0 sample 1: Smoking is the major risk factor for heart disease.<|endoftext|>Q: What are the symptoms of Heart Rhabdomyosarcoma ? A:<|endoftext|> and symptoms of heart cancer include a<|endoftext|> or pain in the<|endoftext|>.<|endoftext|>ostic tests and procedures may be used to<|endoftext|> and stage heart cancer. The most common\n",
      "rank 0 sample 2: Smoking is the major risk factor for heart disease. Anything that increases your chance of getting a disease is called a risk factor. Having a risk factor does not mean that you will get cancer; not having risk factors doesn't mean that you will not get cancer. Talk with your doctor if you think you may be at\n",
      "rank 0 sample 3: Smoking is the major risk factor for adults bronchitis.1\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t                \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t       \n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19000 | loss: 0.009187 | lr 6.0021e-05 | norm: 0.1212 | dt: 3689.25ms | tok/sec: 4441.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19001 | loss: 0.009645 | lr 6.0020e-05 | norm: 0.1116 | dt: 179.41ms | tok/sec: 91323.38\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19002 | loss: 0.009468 | lr 6.0020e-05 | norm: 0.1323 | dt: 180.86ms | tok/sec: 90590.58\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19003 | loss: 0.008520 | lr 6.0019e-05 | norm: 0.1037 | dt: 183.03ms | tok/sec: 89515.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19004 | loss: 0.009022 | lr 6.0019e-05 | norm: 0.1233 | dt: 185.26ms | tok/sec: 88436.71\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19005 | loss: 0.008735 | lr 6.0018e-05 | norm: 0.1210 | dt: 180.71ms | tok/sec: 90666.36\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19006 | loss: 0.009762 | lr 6.0018e-05 | norm: 0.1434 | dt: 179.15ms | tok/sec: 91454.28\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19007 | loss: 0.009197 | lr 6.0017e-05 | norm: 0.1252 | dt: 179.50ms | tok/sec: 91274.62\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19008 | loss: 0.010269 | lr 6.0017e-05 | norm: 0.1473 | dt: 181.79ms | tok/sec: 90127.92\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19009 | loss: 0.007793 | lr 6.0016e-05 | norm: 0.1205 | dt: 180.33ms | tok/sec: 90856.84\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19010 | loss: 0.010660 | lr 6.0016e-05 | norm: 0.1270 | dt: 179.83ms | tok/sec: 91109.92\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19011 | loss: 0.009845 | lr 6.0015e-05 | norm: 0.1292 | dt: 180.51ms | tok/sec: 90766.95\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19012 | loss: 0.010023 | lr 6.0015e-05 | norm: 0.1300 | dt: 180.72ms | tok/sec: 90662.05\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19013 | loss: 0.007822 | lr 6.0014e-05 | norm: 0.0965 | dt: 179.52ms | tok/sec: 91264.20\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19014 | loss: 0.006202 | lr 6.0014e-05 | norm: 0.0818 | dt: 179.85ms | tok/sec: 91096.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19015 | loss: 0.016720 | lr 6.0013e-05 | norm: 0.1580 | dt: 181.21ms | tok/sec: 90414.30\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19016 | loss: 0.009003 | lr 6.0013e-05 | norm: 0.0826 | dt: 179.65ms | tok/sec: 91200.49\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19017 | loss: 0.011513 | lr 6.0012e-05 | norm: 0.1357 | dt: 180.30ms | tok/sec: 90872.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19018 | loss: 0.008597 | lr 6.0012e-05 | norm: 0.1025 | dt: 185.10ms | tok/sec: 88513.71\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19019 | loss: 0.009845 | lr 6.0012e-05 | norm: 0.1293 | dt: 179.79ms | tok/sec: 91128.89\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19020 | loss: 0.006628 | lr 6.0011e-05 | norm: 0.0757 | dt: 179.49ms | tok/sec: 91278.87\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19021 | loss: 0.008055 | lr 6.0011e-05 | norm: 0.1107 | dt: 178.92ms | tok/sec: 91573.10\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19022 | loss: 0.009645 | lr 6.0010e-05 | norm: 0.1017 | dt: 180.08ms | tok/sec: 90979.53\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19023 | loss: 0.008261 | lr 6.0010e-05 | norm: 0.0965 | dt: 188.76ms | tok/sec: 86797.70\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19024 | loss: 0.006384 | lr 6.0009e-05 | norm: 0.0773 | dt: 180.64ms | tok/sec: 90698.91\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19025 | loss: 0.009138 | lr 6.0009e-05 | norm: 0.0960 | dt: 179.76ms | tok/sec: 91143.15\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19026 | loss: 0.008583 | lr 6.0009e-05 | norm: 0.0995 | dt: 179.82ms | tok/sec: 91114.63\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19027 | loss: 0.008132 | lr 6.0008e-05 | norm: 0.1202 | dt: 179.60ms | tok/sec: 91227.00\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19028 | loss: 0.012245 | lr 6.0008e-05 | norm: 0.1893 | dt: 179.13ms | tok/sec: 91463.16\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19029 | loss: 0.006973 | lr 6.0008e-05 | norm: 0.1002 | dt: 182.86ms | tok/sec: 89599.47\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19030 | loss: 0.006529 | lr 6.0007e-05 | norm: 0.0691 | dt: 178.37ms | tok/sec: 91856.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19031 | loss: 0.008167 | lr 6.0007e-05 | norm: 0.0981 | dt: 178.72ms | tok/sec: 91675.35\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19032 | loss: 0.010013 | lr 6.0007e-05 | norm: 0.1096 | dt: 178.19ms | tok/sec: 91946.93\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19033 | loss: 0.007649 | lr 6.0006e-05 | norm: 0.0928 | dt: 179.05ms | tok/sec: 91507.50\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19034 | loss: 0.006849 | lr 6.0006e-05 | norm: 0.0817 | dt: 178.54ms | tok/sec: 91765.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19035 | loss: 0.007804 | lr 6.0006e-05 | norm: 0.0921 | dt: 178.89ms | tok/sec: 91589.21\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19036 | loss: 0.006345 | lr 6.0005e-05 | norm: 0.0842 | dt: 179.99ms | tok/sec: 91028.70\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19037 | loss: 0.004160 | lr 6.0005e-05 | norm: 0.0608 | dt: 179.55ms | tok/sec: 91248.81\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19038 | loss: 0.004532 | lr 6.0005e-05 | norm: 0.0678 | dt: 184.35ms | tok/sec: 88872.35\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19039 | loss: 0.003185 | lr 6.0005e-05 | norm: 0.0485 | dt: 179.12ms | tok/sec: 91468.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19040 | loss: 0.006394 | lr 6.0004e-05 | norm: 0.0939 | dt: 180.07ms | tok/sec: 90984.95\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19041 | loss: 0.003873 | lr 6.0004e-05 | norm: 0.0517 | dt: 182.07ms | tok/sec: 89986.06\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19042 | loss: 0.005329 | lr 6.0004e-05 | norm: 0.0778 | dt: 181.88ms | tok/sec: 90079.25\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19043 | loss: 0.006471 | lr 6.0004e-05 | norm: 0.0782 | dt: 178.89ms | tok/sec: 91588.72\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19044 | loss: 0.005215 | lr 6.0003e-05 | norm: 0.0807 | dt: 183.09ms | tok/sec: 89485.01\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19045 | loss: 0.004214 | lr 6.0003e-05 | norm: 0.0665 | dt: 181.44ms | tok/sec: 90300.83\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19046 | loss: 0.004849 | lr 6.0003e-05 | norm: 0.0923 | dt: 178.62ms | tok/sec: 91724.54\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19047 | loss: 0.004914 | lr 6.0003e-05 | norm: 0.0741 | dt: 180.52ms | tok/sec: 90757.60\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19048 | loss: 0.004069 | lr 6.0002e-05 | norm: 0.0808 | dt: 179.91ms | tok/sec: 91068.99\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19049 | loss: 0.005918 | lr 6.0002e-05 | norm: 0.0708 | dt: 178.51ms | tok/sec: 91781.26\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19050 | loss: 0.004452 | lr 6.0002e-05 | norm: 0.0793 | dt: 182.11ms | tok/sec: 89968.39\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19051 | loss: 0.003784 | lr 6.0002e-05 | norm: 0.0516 | dt: 180.62ms | tok/sec: 90711.48\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19052 | loss: 0.003873 | lr 6.0002e-05 | norm: 0.0611 | dt: 180.30ms | tok/sec: 90872.82\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19053 | loss: 0.003910 | lr 6.0002e-05 | norm: 0.0598 | dt: 187.65ms | tok/sec: 87312.28\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19054 | loss: 0.004366 | lr 6.0001e-05 | norm: 0.0661 | dt: 181.52ms | tok/sec: 90261.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19055 | loss: 0.004276 | lr 6.0001e-05 | norm: 0.0657 | dt: 183.87ms | tok/sec: 89107.09\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19056 | loss: 0.004177 | lr 6.0001e-05 | norm: 0.0800 | dt: 181.88ms | tok/sec: 90081.02\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19057 | loss: 0.002640 | lr 6.0001e-05 | norm: 0.0472 | dt: 180.91ms | tok/sec: 90566.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19058 | loss: 0.004596 | lr 6.0001e-05 | norm: 0.0547 | dt: 180.80ms | tok/sec: 90618.65\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19059 | loss: 0.004604 | lr 6.0001e-05 | norm: 0.0542 | dt: 180.45ms | tok/sec: 90797.41\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19060 | loss: 0.005792 | lr 6.0001e-05 | norm: 0.0682 | dt: 188.98ms | tok/sec: 86699.25\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19061 | loss: 0.005028 | lr 6.0001e-05 | norm: 0.0809 | dt: 186.35ms | tok/sec: 87921.20\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19062 | loss: 0.004317 | lr 6.0000e-05 | norm: 0.0667 | dt: 180.28ms | tok/sec: 90878.46\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19063 | loss: 0.006811 | lr 6.0000e-05 | norm: 0.0840 | dt: 181.56ms | tok/sec: 90239.05\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19064 | loss: 0.005776 | lr 6.0000e-05 | norm: 0.0764 | dt: 184.19ms | tok/sec: 88951.49\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19065 | loss: 0.005413 | lr 6.0000e-05 | norm: 0.0659 | dt: 179.48ms | tok/sec: 91288.08\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19066 | loss: 0.003155 | lr 6.0000e-05 | norm: 0.0593 | dt: 184.04ms | tok/sec: 89025.24\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19067 | loss: 0.005255 | lr 6.0000e-05 | norm: 0.0678 | dt: 185.36ms | tok/sec: 88390.64\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19068 | loss: 0.004460 | lr 6.0000e-05 | norm: 0.0628 | dt: 180.29ms | tok/sec: 90875.34\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19069 | loss: 0.004765 | lr 6.0000e-05 | norm: 0.0601 | dt: 180.25ms | tok/sec: 90893.97\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19070 | loss: 0.004033 | lr 6.0000e-05 | norm: 0.0578 | dt: 182.02ms | tok/sec: 90011.29\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19071 | loss: 0.004697 | lr 6.0000e-05 | norm: 0.0675 | dt: 179.72ms | tok/sec: 91165.52\n",
      "validation loss: 0.1411\n",
      "rank 0 sample 0: Smoking is the major risk factor for heart disease.<|endoftext|> causes of sudden death in people with heart attacks and low levels ofide, protein, and blood pressure.<|endoftext|>Q: What are the treatments for Heart Disease in Women ? A: Heart attacks in men with lung disease (cardiac) are more likely to develop\n",
      "rank 0 sample 1: Smoking is the major risk factor for lung cancer. Your risk increases with your risk of lung cancer.     <|endoftext|>. As<|endoftext|> is               -  Lower exposure to radon.      -  anti-<|endoftext|> liver\n",
      "rank 0 sample 2: Smoking is the major risk factor for lung cancer.     HIV infection    Being infected with the human immunodeficiency virus (HIV).<|endoftext|> against HIV is a common risk factor for getting HIV<|endoftext|> given in people who are HIV-<|endoftext|>.     Using tobacco or prolonged<|endoftext|>\n",
      "rank 0 sample 3: Smoking is the major risk factor for multinoblastoma. Other factors also increase the risk of blood vessel cell<|endoftext|>. These factors include the long-term use of certain medications called vitamin D-aminoin similar to the past (for example,<|endoftext|>amin, alfotrigine, and phenyl\n",
      "start training the model\n",
      "step 0 of training\n",
      "step 19072 | loss: 0.003769 | lr 6.0000e-05 | norm: 0.0609 | dt: 4731.16ms | tok/sec: 3463.00\n",
      "2024/10/29 17:17:35 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.0+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2024/10/29 17:17:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "!python /content/drive/MyDrive/Medical_LLM/train_gpt2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZuwFyUAvHmT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJ9RarhBvUBX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBE60er6YOG4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2067,
     "status": "ok",
     "timestamp": 1730919532424,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "u8C7YuaHDmm7",
    "outputId": "037c28f7-cac6-4615-a184-c4fa77d154e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
      "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.6)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install flask pyngrok nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2491,
     "status": "ok",
     "timestamp": 1730919530367,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "iG49nTB1EDNF",
    "outputId": "07e870f4-b26b-41a6-8ea7-9577b7832d6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1297,
     "status": "ok",
     "timestamp": 1730919537544,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "lO3FqgXeDmfo",
    "outputId": "405b42d0-21ae-44f2-dec6-4d4e58731efd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
     ]
    }
   ],
   "source": [
    "!ngrok authtoken 2lEXyQpA4Sexnri0id9pzhSZs1U_5bwcKB6BxqWM2FZKAxN7h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDmqHxLdFArw",
    "outputId": "e63e1117-e709-4f56-fe87-073350642007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting application...\n",
      "Current working directory: /content\n",
      "Checking if model file exists: False\n",
      "Loading model...\n",
      "Using device: cpu\n",
      "Loading model from: /content/drive/MyDrive/Medical_LLM/medical_dataset_cache/saved_model.pth\n",
      "/content/drive/MyDrive/Medical_LLM/app.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n",
      "Model loaded successfully!\n",
      "Tokenizer initialized\n",
      "Starting Flask server...\n",
      " * Serving Flask app 'app'\n",
      " * Debug mode: off\n",
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8081\n",
      " * Running on http://172.28.0.12:8081\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python /content/drive/MyDrive/Medical_LLM/app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZGSOc8WFAZk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5GNRZCM7YODK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvYHSTuyYN_m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3937,
     "status": "ok",
     "timestamp": 1730919514638,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "BNLBxCb1YN7o",
    "outputId": "644e12a4-a30a-441a-91ac-6f78db8b447a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.39.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
      "Collecting watchdog<6,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.39.0-py2.py3-none-any.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m134.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
      "Successfully installed pydeck-0.9.1 pyngrok-7.2.1 streamlit-1.39.0 watchdog-5.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "executionInfo": {
     "elapsed": 279,
     "status": "error",
     "timestamp": 1730919519294,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "m31EA8ugYN29",
    "outputId": "924d518a-8008-4fd1-ee25-b9fd77eb247e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ngrok' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9ccdabaddc60>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'8501'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Streamlit app is live at: {public_url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ngrok' is not defined"
     ]
    }
   ],
   "source": [
    "public_url = ngrok.connect(addr='8501')\n",
    "print(f\"Streamlit app is live at: {public_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6sN9OsC5Y4M"
   },
   "outputs": [],
   "source": [
    "!streamlit run app.py &> streamlit.log &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpXHVjfe5dmr"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# Wait for Streamlit to start\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBbHoAKGYNv_"
   },
   "outputs": [],
   "source": [
    "!streamlit run app.py &> /dev/null &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1730232597536,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "vq_fwWeaYNka",
    "outputId": "8cebb10c-1eab-44b5-81b3-d51689b3b27a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streamlit app is live at: NgrokTunnel: \"https://c703-35-245-71-252.ngrok-free.app\" -> \"http://localhost:8501\"\n"
     ]
    }
   ],
   "source": [
    "public_url = ngrok.connect(8501)\n",
    "print(f\"Streamlit app is live at: {public_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2605,
     "status": "ok",
     "timestamp": 1730232912966,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "GFr7F3y14qQl",
    "outputId": "7d471902-08cb-4088-b671-89fe1605d013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting colabcode\n",
      "  Downloading colabcode-0.3.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pyngrok>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from colabcode) (7.2.0)\n",
      "Collecting nest-asyncio==1.4.3 (from colabcode)\n",
      "  Downloading nest_asyncio-1.4.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting uvicorn==0.13.1 (from colabcode)\n",
      "  Downloading uvicorn-0.13.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "\u001b[33mWARNING: Ignoring version 0.13.1 of uvicorn since it has invalid metadata:\n",
      "Requested uvicorn==0.13.1 from https://files.pythonhosted.org/packages/ef/67/546c35e9fffb585ea0608ba3bdcafe17ae402e304367203d0b08d6c23051/uvicorn-0.13.1-py3-none-any.whl (from colabcode) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
      "    python-dotenv (>=0.13.*) ; extra == 'standard'\n",
      "                   ~~~~~~~^\n",
      "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
      "\u001b[0mINFO: pip is looking at multiple versions of colabcode to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting colabcode\n",
      "  Downloading colabcode-0.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting uvicorn==0.13.1 (from colabcode)\n",
      "  Using cached uvicorn-0.13.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "\u001b[33mWARNING: Ignoring version 0.13.1 of uvicorn since it has invalid metadata:\n",
      "Requested uvicorn==0.13.1 from https://files.pythonhosted.org/packages/ef/67/546c35e9fffb585ea0608ba3bdcafe17ae402e304367203d0b08d6c23051/uvicorn-0.13.1-py3-none-any.whl (from colabcode) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
      "    python-dotenv (>=0.13.*) ; extra == 'standard'\n",
      "                   ~~~~~~~^\n",
      "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting colabcode\n",
      "  Downloading colabcode-0.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting uvicorn==0.13.1 (from colabcode)\n",
      "  Using cached uvicorn-0.13.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "\u001b[33mWARNING: Ignoring version 0.13.1 of uvicorn since it has invalid metadata:\n",
      "Requested uvicorn==0.13.1 from https://files.pythonhosted.org/packages/ef/67/546c35e9fffb585ea0608ba3bdcafe17ae402e304367203d0b08d6c23051/uvicorn-0.13.1-py3-none-any.whl (from colabcode) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
      "    python-dotenv (>=0.13.*) ; extra == 'standard'\n",
      "                   ~~~~~~~^\n",
      "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting colabcode\n",
      "  Downloading colabcode-0.1.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok>=5.0.0->colabcode) (6.0.2)\n",
      "Downloading colabcode-0.1.1-py3-none-any.whl (4.6 kB)\n",
      "Installing collected packages: colabcode\n",
      "Successfully installed colabcode-0.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install colabcode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 740,
     "status": "ok",
     "timestamp": 1730235062219,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "u2mMTxF8C4Qy",
    "outputId": "26521d26-9820-42e5-ab17-27d581a6c439"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-29 20:51:04.275 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-29 20:51:04.314 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /content/drive/MyDrive/Medical_LLM/app.py [ARGUMENTS]\n",
      "2024-10-29 20:51:04.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-29 20:51:04.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-29 20:51:04.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "!python /content/drive/MyDrive/Medical_LLM/app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "executionInfo": {
     "elapsed": 415,
     "status": "error",
     "timestamp": 1730844025789,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "3qnax1_FDBKU",
    "outputId": "1b48af7d-87ce-4644-a4d8-31baf8c6162a"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-36b198c83b89>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-36b198c83b89>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    streamlit run /content/drive/MyDrive/Medical_LLM/app.py\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "streamlit run /content/drive/MyDrive/Medical_LLM/app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4458,
     "status": "ok",
     "timestamp": 1730903240933,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "0Vs7gxRy_49L",
    "outputId": "25b41f66-f740-4937-bf4c-41f659b10330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.39.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
      "Requirement already satisfied: watchdog<6,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.0.3)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "\u001b[K\u001b[?25h\n",
      "added 22 packages, and audited 23 packages in 1s\n",
      "\n",
      "3 packages are looking for funding\n",
      "  run `npm fund` for details\n",
      "\n",
      "1 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerability\n",
      "\n",
      "To address all issues (including breaking changes), run:\n",
      "  npm audit fix --force\n",
      "\n",
      "Run `npm audit` for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit\n",
    "!npm install -g localtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7kJahp74qMq"
   },
   "outputs": [],
   "source": [
    "!streamlit run app.py &>/content/logs.txt &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89l6i55q30tF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12040,
     "status": "ok",
     "timestamp": 1730903475680,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "7e2_jDsC4qIq",
    "outputId": "83e56c18-5797-4d14-eb2a-ce7efff3a59f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your url is: https://four-regions-make.loca.lt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!npx localtunnel --port 8501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1730904074250,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "qmqc-oWZ4qB0",
    "outputId": "88cf69ef-3e95-46fe-f943-d7e326a0bf4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password/Enpoint IP for localtunnel is: 34.91.70.44\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUsH0gOc4zCl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iq0pcATE52gf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C27gC4HU52cm"
   },
   "outputs": [],
   "source": [
    "!pip install -q streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4065,
     "status": "ok",
     "timestamp": 1730903787242,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "Vf978Emc52Ym",
    "outputId": "ee002a1b-30b5-46b6-a176-fcd23669dbc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[?25h\n",
      "up to date, audited 23 packages in 508ms\n",
      "\n",
      "3 packages are looking for funding\n",
      "  run `npm fund` for details\n",
      "\n",
      "2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerabilities\n",
      "\n",
      "To address all issues (including breaking changes), run:\n",
      "  npm audit fix --force\n",
      "\n",
      "Run `npm audit` for details.\n"
     ]
    }
   ],
   "source": [
    "!npm install localtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKvYoAyv5-3E"
   },
   "outputs": [],
   "source": [
    "!streamlit run app.py &>/content/logs.txt &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 626,
     "status": "ok",
     "timestamp": 1730903928224,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "n-3Tzd0R6Z61",
    "outputId": "533b0119-5dfe-4310-ba86-d385cfa4c12f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing apptest.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile apptest.py\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "st.write('Hello, *World!* :sunglasses:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57710,
     "status": "ok",
     "timestamp": 1730904327140,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": 0
    },
    "id": "jJL--T195-tq",
    "outputId": "6fe31b05-57e7-446b-841d-a5f8d3a4e35c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your url is: https://cuddly-seals-matter.loca.lt\n",
      "/content/node_modules/localtunnel/bin/lt.js:81\n",
      "    throw err;\n",
      "    ^\n",
      "\n",
      "Error: connection refused: localtunnel.me:15433 (check your firewall settings)\n",
      "    at Socket.<anonymous> \u001b[90m(/content/\u001b[39mnode_modules/\u001b[4mlocaltunnel\u001b[24m/lib/TunnelCluster.js:52:11\u001b[90m)\u001b[39m\n",
      "\u001b[90m    at Socket.emit (node:events:513:28)\u001b[39m\n",
      "\u001b[90m    at emitErrorNT (node:internal/streams/destroy:157:8)\u001b[39m\n",
      "\u001b[90m    at emitErrorCloseNT (node:internal/streams/destroy:122:3)\u001b[39m\n",
      "\u001b[90m    at processTicksAndRejections (node:internal/process/task_queues:83:21)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "!npx localtunnel --port 8501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1n9KacL_5-jc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rG_GqamaA18d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1VXQxcZBA1sO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V77zgvzJA1kS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7SAAfWX8A1dC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7_077z_A1RJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAjgWtKW4p1-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SjUgLqB4ptC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qS9KKjXyuY2y"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "myfile = \"G:\\My Drive\\Medical_LLM\\medical_dataset_cache\"\n",
    "# If file exists, delete it.\n",
    "if os.path.isfile(myfile):\n",
    "    os.remove(myfile)\n",
    "else:\n",
    "    # If it fails, inform the user.\n",
    "    print(\"Error: %s file not found\" % myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 438,
     "status": "ok",
     "timestamp": 1728904679849,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": -60
    },
    "id": "HaPUiNnkvT66",
    "outputId": "99fb6de3-75b5-47f6-eba8-5e4007d0814d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is (are) Hypothalamic dysfunction ?\n",
      "Answer: Hypothalamic dysfunction refers to a cond\n"
     ]
    }
   ],
   "source": [
    "data_path = '/content/drive/MyDrive/Medical_LLM/output_data/Medical_QA_Dataset.txt'\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "dataset = text[:1000]\n",
    "print(dataset[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21218,
     "status": "ok",
     "timestamp": 1728904702545,
     "user": {
      "displayName": "Naeimeh Nour",
      "userId": "06407853353421918609"
     },
     "user_tz": -60
    },
    "id": "uI_QSeX2vHjG",
    "outputId": "704b726d-da6b-41d7-d190-cd7c7e64a17b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "loaded 10638625 tokens\n",
      "1 epoch = 649 batches\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/Medical_LLM/train_gpt2.py\", line 235, in <module>\n",
      "    logits, loss = model(x, y)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/Medical_LLM/train_gpt2.py\", line 121, in forward\n",
      "    x = block(x)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/Medical_LLM/train_gpt2.py\", line 67, in forward\n",
      "    x = x + self.attn(self.ln_1(x))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/content/drive/MyDrive/Medical_LLM/train_gpt2.py\", line 30, in forward\n",
      "    att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 183.06 MiB is free. Process 23584 has 14.57 GiB memory in use. Of the allocated memory 14.41 GiB is allocated by PyTorch, and 32.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "!python /content/drive/MyDrive/Medical_LLM/train_gpt2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OowxvvdTwlNU",
    "outputId": "2d2b6912-5b98-4d7a-9f20-6b791afe44fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Train Loss: 0.002344\n",
      "Min Validation Loss: 0.1365\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# parse and visualize the logfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sz = \"124M\"\n",
    "\n",
    "loss_baseline = {\n",
    "    \"124M\": 3.2924,\n",
    "}[sz]\n",
    "hella2_baseline = { # HellaSwag for GPT-2\n",
    "    \"124M\": 0.294463,\n",
    "    \"350M\": 0.375224,\n",
    "    \"774M\": 0.431986,\n",
    "    \"1558M\": 0.488946,\n",
    "}[sz]\n",
    "hella3_baseline = { # HellaSwag for GPT-3\n",
    "    \"124M\": 0.337,\n",
    "    \"350M\": 0.436,\n",
    "    \"774M\": 0.510,\n",
    "    \"1558M\": 0.547,\n",
    "}[sz]\n",
    "\n",
    "# load the log file\n",
    "with open(\"G:\\My Drive\\Medical_LLM\\medical_dataset_cache\\log\\log.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# parse the individual lines, group by stream (train,val,hella)\n",
    "streams = {}\n",
    "for line in lines:\n",
    "    step, stream, val = line.strip().split()\n",
    "    if stream not in streams:\n",
    "        streams[stream] = {}\n",
    "    streams[stream][int(step)] = float(val)\n",
    "\n",
    "# convert each stream from {step: val} to (steps[], vals[])\n",
    "# so it's easier for plotting\n",
    "streams_xy = {}\n",
    "for k, v in streams.items():\n",
    "    # get all (step, val) items, sort them\n",
    "    xy = sorted(list(v.items()))\n",
    "    # unpack the list of tuples to tuple of lists\n",
    "    streams_xy[k] = list(zip(*xy))\n",
    "\n",
    "# create figure\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Panel 1: losses: both train and val\n",
    "plt.subplot(121)\n",
    "xs, ys = streams_xy[\"train\"] # training loss\n",
    "ys = np.array(ys)\n",
    "plt.plot(xs, ys, label=f'nanogpt ({sz}) train loss')\n",
    "print(\"Min Train Loss:\", min(ys))\n",
    "xs, ys = streams_xy[\"val\"] # validation loss\n",
    "plt.plot(xs, ys, label=f'nanogpt ({sz}) val loss')\n",
    "# horizontal line at GPT-2 baseline\n",
    "if loss_baseline is not None:\n",
    "    plt.axhline(y=loss_baseline, color='r', linestyle='--', label=f\"OpenAI GPT-2 ({sz}) checkpoint val loss\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.yscale('log')\n",
    "plt.ylim(top=4.0)\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "print(\"Min Validation Loss:\", min(ys))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0010aea8a4724193a88934f98808c164": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0297148a4b0a492c834bc3eeec6208cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_223ee77299944edca398704431af9fbc",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0472e1487364460ea9921b63a5ac35ad",
      "value": 1042301
     }
    },
    "0472e1487364460ea9921b63a5ac35ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "07f4cfcd15fc48f09123a50185daac6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0c29373473c04f4d9bc9b1740a707715": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1984d60ed4044f08af91a59e5d0f93b9",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de0836a2fc7a4716a1298d5dfbd80809",
      "value": 1355256
     }
    },
    "1411fe49438c4076b001876637572ddc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d283c332b3304e8184ccaf7ddcdcea6d",
      "placeholder": "​",
      "style": "IPY_MODEL_99ea36b13f20468ab6600deb2ba79308",
      "value": " 1.04M/1.04M [00:00&lt;00:00, 17.2MB/s]"
     }
    },
    "1984d60ed4044f08af91a59e5d0f93b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "215bd024b5784711be6fda92ff6189c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5fdaa63f06849f38a8326faf6c223e1",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2759d4feecd04ae5b8dc4ea3faa02922",
      "value": 456318
     }
    },
    "223ee77299944edca398704431af9fbc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27286e49ff64436094d37a7e75860b9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2759d4feecd04ae5b8dc4ea3faa02922": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "29f3789f5ed54d4f93c9dfbc47cd6978": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_520e1453adb545d89456cf6811828077",
       "IPY_MODEL_0c29373473c04f4d9bc9b1740a707715",
       "IPY_MODEL_9337f2cd834c410b8841bdcb31184ef5"
      ],
      "layout": "IPY_MODEL_dd22711b1a9647fe8e1a7a8f47bf0a4e"
     }
    },
    "35d8f6a5d5d24deba70463e5f3b0d59e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d68cd6dcac441a69795fbf54d534123": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "520e1453adb545d89456cf6811828077": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63bf349390604881a3888f719a3cd3b8",
      "placeholder": "​",
      "style": "IPY_MODEL_9795a91ab3cb47038dc6c01d726847e7",
      "value": "tokenizer.json: 100%"
     }
    },
    "55d2c41870e1425e974ec6d20f04ffe5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b686a76e40a46c58f406f92d0714ba1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63bf349390604881a3888f719a3cd3b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "665f6198e0f64e81a3e2c12b15c8e4be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a4955deac344b328d15b252daa4e5e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8cf98ca329164363aa2784842c1414f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_665f6198e0f64e81a3e2c12b15c8e4be",
      "placeholder": "​",
      "style": "IPY_MODEL_7a4955deac344b328d15b252daa4e5e1",
      "value": " 456k/456k [00:00&lt;00:00, 15.6MB/s]"
     }
    },
    "916d40cef053485c8d15a1960f79ba01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9337f2cd834c410b8841bdcb31184ef5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27286e49ff64436094d37a7e75860b9f",
      "placeholder": "​",
      "style": "IPY_MODEL_07f4cfcd15fc48f09123a50185daac6e",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 18.6MB/s]"
     }
    },
    "94787369b0a34adc9f10222da3c86bcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc7ef5421d3b45f794da62ba739fff80",
      "placeholder": "​",
      "style": "IPY_MODEL_35d8f6a5d5d24deba70463e5f3b0d59e",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "9795a91ab3cb47038dc6c01d726847e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99ea36b13f20468ab6600deb2ba79308": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d4bd4b3eb9e44fc8ff796739525a12b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55d2c41870e1425e974ec6d20f04ffe5",
      "placeholder": "​",
      "style": "IPY_MODEL_bc833a24ced64691886b60483f388350",
      "value": "vocab.json: 100%"
     }
    },
    "a5fdaa63f06849f38a8326faf6c223e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb549ee1da74449284b34c371b152efc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce20f5a3370147a5a371a6a48286c5b1",
      "placeholder": "​",
      "style": "IPY_MODEL_4d68cd6dcac441a69795fbf54d534123",
      "value": "merges.txt: 100%"
     }
    },
    "bc7ef5421d3b45f794da62ba739fff80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc833a24ced64691886b60483f388350": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c08a4f306f724c77b9ecf31b4e84ad64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c3d1acd056be42a4b5db596d8d25e062": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b686a76e40a46c58f406f92d0714ba1",
      "placeholder": "​",
      "style": "IPY_MODEL_ce3d061b31b34cd2b3f12d6bbb8b3d13",
      "value": " 26.0/26.0 [00:00&lt;00:00, 1.12kB/s]"
     }
    },
    "ce20f5a3370147a5a371a6a48286c5b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce3d061b31b34cd2b3f12d6bbb8b3d13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d283c332b3304e8184ccaf7ddcdcea6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7e0d8d65e7546e8851dc2d84709029a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bb549ee1da74449284b34c371b152efc",
       "IPY_MODEL_215bd024b5784711be6fda92ff6189c5",
       "IPY_MODEL_8cf98ca329164363aa2784842c1414f5"
      ],
      "layout": "IPY_MODEL_916d40cef053485c8d15a1960f79ba01"
     }
    },
    "d9d84509a04e4d888c2ecf66510b5c1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd22711b1a9647fe8e1a7a8f47bf0a4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd85d32387284cebbd39b4f53b5b95b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9d84509a04e4d888c2ecf66510b5c1a",
      "max": 26,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c08a4f306f724c77b9ecf31b4e84ad64",
      "value": 26
     }
    },
    "de0836a2fc7a4716a1298d5dfbd80809": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ea8d74d64a8d4b3fa6c9582977c20c72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f80c9cc1f00c48f8b6567455c778c61a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_94787369b0a34adc9f10222da3c86bcc",
       "IPY_MODEL_dd85d32387284cebbd39b4f53b5b95b9",
       "IPY_MODEL_c3d1acd056be42a4b5db596d8d25e062"
      ],
      "layout": "IPY_MODEL_0010aea8a4724193a88934f98808c164"
     }
    },
    "fb43b0ef8dca47bab78a8948f72db8a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d4bd4b3eb9e44fc8ff796739525a12b",
       "IPY_MODEL_0297148a4b0a492c834bc3eeec6208cd",
       "IPY_MODEL_1411fe49438c4076b001876637572ddc"
      ],
      "layout": "IPY_MODEL_ea8d74d64a8d4b3fa6c9582977c20c72"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
